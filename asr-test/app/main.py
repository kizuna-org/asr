import streamlit as st
import torch
import numpy as np
import os
import time
import json
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from model import LightweightASRModel, FastASRModel, CHAR_TO_ID, ID_TO_CHAR
from dataset import AudioPreprocessor, TextPreprocessor, ASRDataset, create_dataloader, SyntheticDataset
from trainer import ASRTrainer, FastTrainer
from utils import (
    AudioRecorder, RealTimeASR, AudioProcessor, ModelManager, 
    PerformanceMonitor, create_sample_audio_data, save_sample_dataset
)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'model' not in st.session_state:
    st.session_state.model = None
if 'trainer' not in st.session_state:
    st.session_state.trainer = None
if 'audio_preprocessor' not in st.session_state:
    st.session_state.audio_preprocessor = None
if 'text_preprocessor' not in st.session_state:
    st.session_state.text_preprocessor = None
if 'performance_monitor' not in st.session_state:
    st.session_state.performance_monitor = PerformanceMonitor()
if 'training_history' not in st.session_state:
    st.session_state.training_history = {'loss': [], 'wer': [], 'epoch': []}

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_type = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
        ["FastASRModel (è¶…è»½é‡)", "LightweightASRModel (è»½é‡)"],
        help="FastASRModelã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™"
    )
    
    # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    device = st.selectbox(
        "ãƒ‡ãƒã‚¤ã‚¹",
        ["cpu", "cuda"] if torch.cuda.is_available() else ["cpu"],
        help="GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯cudaã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.subheader("å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    learning_rate = st.slider("å­¦ç¿’ç‡", 1e-5, 1e-2, 1e-3, format="%.5f")
    batch_size = st.slider("ãƒãƒƒãƒã‚µã‚¤ã‚º", 1, 32, 8)
    max_epochs = st.slider("æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°", 10, 200, 50)
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.subheader("ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    hidden_dim = st.slider("éš ã‚Œå±¤ã‚µã‚¤ã‚º", 32, 256, 64 if model_type.startswith("Fast") else 128)
    num_layers = st.slider("LSTMå±¤æ•°", 1, 4, 1 if model_type.startswith("Fast") else 2)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜", "ğŸ“Š çµæœåˆ†æ"])

with tab1:
    st.header("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ¨ ç‰¹å¾´")
        st.markdown("""
        - **å…‰é€Ÿã§ã»ã¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ä½œ**
        - **è»½é‡CNN + LSTM + CTCã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
        - **Dockerã‚³ãƒ³ãƒ†ãƒŠåŒ–æ¸ˆã¿**
        - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’é€²æ—è¡¨ç¤º**
        - **ãƒã‚¤ã‚¯å…¥åŠ›ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–**
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        if st.session_state.performance_monitor:
            stats = st.session_state.performance_monitor.get_statistics()
            if stats:
                st.metric("å¹³å‡æ¨è«–æ™‚é–“", f"{stats['avg_inference_time']:.4f}s")
                st.metric("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['avg_realtime_ratio']:.2f}x")
                st.metric("ç·æ¨è«–å›æ•°", stats['total_inferences'])
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("PyTorch", torch.__version__)
        st.metric("CUDAåˆ©ç”¨å¯èƒ½", "âœ…" if torch.cuda.is_available() else "âŒ")
    
    with col2:
        if torch.cuda.is_available():
            st.metric("GPU", torch.cuda.get_device_name(0))
            st.metric("GPUãƒ¡ãƒ¢ãƒª", f"{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    with col3:
        st.metric("ãƒ‡ãƒã‚¤ã‚¹", device)
        if st.session_state.model:
            params = sum(p.numel() for p in st.session_state.model.parameters())
            st.metric("ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", f"{params:,}")

with tab2:
    st.header("ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"):
        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­..."):
            # å‰å‡¦ç†å™¨ã®åˆæœŸåŒ–
            st.session_state.audio_preprocessor = AudioPreprocessor()
            st.session_state.text_preprocessor = TextPreprocessor()
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            if model_type.startswith("Fast"):
                st.session_state.model = FastASRModel(
                    hidden_dim=hidden_dim,
                    num_classes=len(CHAR_TO_ID)
                )
            else:
                st.session_state.model = LightweightASRModel(
                    hidden_dim=hidden_dim,
                    num_layers=num_layers,
                    num_classes=len(CHAR_TO_ID)
                )
            
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸï¼")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    st.subheader("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸµ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ"):
            with st.spinner("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆä¸­..."):
                samples = create_sample_audio_data(num_samples=20, duration=3.0)
                save_sample_dataset(samples, "data/raw")
                st.success(f"âœ… {len(samples)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
    
    with col2:
        uploaded_files = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['wav', 'mp3', 'flac', 'm4a'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.write(f"ğŸ“ {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
    
    # å­¦ç¿’å®Ÿè¡Œ
    if st.session_state.model and st.session_state.audio_preprocessor:
        st.subheader("ğŸš€ å­¦ç¿’å®Ÿè¡Œ")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
        data_dir = "data/raw"
        if os.path.exists(data_dir) and os.listdir(data_dir):
            try:
                dataset = ASRDataset(
                    data_dir=data_dir,
                    audio_preprocessor=st.session_state.audio_preprocessor,
                    text_preprocessor=st.session_state.text_preprocessor
                )
                
                if len(dataset) > 0:
                    st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(dataset)}ã‚µãƒ³ãƒ—ãƒ«")
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
                    train_loader = create_dataloader(
                        dataset, 
                        batch_size=batch_size, 
                        shuffle=True
                    )
                    
                    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
                    if model_type.startswith("Fast"):
                        st.session_state.trainer = FastTrainer(
                            model=st.session_state.model,
                            train_loader=train_loader,
                            device=device,
                            learning_rate=learning_rate,
                            max_epochs=max_epochs,
                            model_save_dir="models"
                        )
                    else:
                        st.session_state.trainer = ASRTrainer(
                            model=st.session_state.model,
                            train_loader=train_loader,
                            device=device,
                            learning_rate=learning_rate,
                            max_epochs=max_epochs,
                            model_save_dir="models"
                        )
                    
                    # å­¦ç¿’é–‹å§‹ãƒœã‚¿ãƒ³
                    if st.button("ğŸ¯ å­¦ç¿’é–‹å§‹", type="primary"):
                        st.subheader("ğŸ“ˆ å­¦ç¿’é€²æ—")
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        # å­¦ç¿’å±¥æ­´ã®è¡¨ç¤ºç”¨
                        chart_placeholder = st.empty()
                        
                        # å­¦ç¿’å®Ÿè¡Œ
                        try:
                            history = st.session_state.trainer.train()
                            
                            # å­¦ç¿’å±¥æ­´ã‚’æ›´æ–°
                            st.session_state.training_history = {
                                'loss': history['train_losses'],
                                'wer': history['train_wers'],
                                'epoch': list(range(1, len(history['train_losses']) + 1))
                            }
                            
                            st.success("âœ… å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            
                        except Exception as e:
                            st.error(f"âŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                
                else:
                    st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç©ºã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
            except Exception as e:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        else:
            st.info("â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç©ºã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

with tab3:
    st.header("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜")
    
    if not st.session_state.model:
        st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("ğŸ™ï¸ ãƒã‚¤ã‚¯å…¥åŠ›")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", type="primary"):
                st.session_state.recording = True
                st.session_state.recognized_text = []
                
                # éŒ²éŸ³æ©Ÿã®åˆæœŸåŒ–
                recorder = AudioRecorder()
                recorder.start_recording()
                
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ã®å®Ÿè¡Œ
                realtime_asr = RealTimeASR(
                    model=st.session_state.model,
                    audio_preprocessor=st.session_state.audio_preprocessor,
                    text_preprocessor=st.session_state.text_preprocessor,
                    device=device
                )
                
                # èªè­˜çµæœã®è¡¨ç¤º
                result_placeholder = st.empty()
                
                try:
                    for i in range(10):  # 10å›ã®èªè­˜ã‚’å®Ÿè¡Œ
                        audio_data = recorder.get_audio_data(3.0)  # 3ç§’é–“ã®éŸ³å£°
                        
                        if len(audio_data) > 0:
                            start_time = time.time()
                            text = realtime_asr.recognize_audio(audio_data)
                            inference_time = time.time() - start_time
                            
                            if text.strip():
                                st.session_state.recognized_text.append(text)
                                result_placeholder.write(f"ğŸ¯ èªè­˜çµæœ: **{text}**")
                                
                                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²
                                st.session_state.performance_monitor.record_inference(
                                    inference_time, 3.0
                                )
                        
                        time.sleep(0.1)  # å°‘ã—å¾…æ©Ÿ
                
                finally:
                    recorder.close()
                    st.session_state.recording = False
        
        with col2:
            if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢"):
                st.session_state.recording = False
                st.success("âœ… éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        # èªè­˜çµæœã®å±¥æ­´
        if hasattr(st.session_state, 'recognized_text') and st.session_state.recognized_text:
            st.subheader("ğŸ“ èªè­˜å±¥æ­´")
            for i, text in enumerate(st.session_state.recognized_text):
                st.write(f"{i+1}. {text}")

with tab4:
    st.header("ğŸ“Š çµæœåˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ å­¦ç¿’æ›²ç·š")
        
        if st.session_state.training_history['loss']:
            # å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
            df = pd.DataFrame(st.session_state.training_history)
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('Training Loss', 'Training WER'),
                vertical_spacing=0.1
            )
            
            fig.add_trace(
                go.Scatter(x=df['epoch'], y=df['loss'], name='Loss'),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=df['epoch'], y=df['wer'], name='WER'),
                row=2, col=1
            )
            
            fig.update_layout(height=600, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("â„¹ï¸ å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    with col2:
        st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        
        stats = st.session_state.performance_monitor.get_statistics()
        if stats:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®è¡¨ç¤º
            st.metric("ç·æ¨è«–å›æ•°", stats['total_inferences'])
            st.metric("å¹³å‡æ¨è«–æ™‚é–“", f"{stats['avg_inference_time']:.4f}s")
            st.metric("æ¨è«–æ™‚é–“æ¨™æº–åå·®", f"{stats['std_inference_time']:.4f}s")
            st.metric("å¹³å‡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['avg_realtime_ratio']:.2f}x")
            st.metric("æœ€å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['min_realtime_ratio']:.2f}x")
            st.metric("æœ€å¤§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['max_realtime_ratio']:.2f}x")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°ãƒœã‚¿ãƒ³
            if st.button("ğŸ“Š è©³ç´°çµ±è¨ˆã‚’è¡¨ç¤º"):
                st.session_state.performance_monitor.print_statistics()
        else:
            st.info("â„¹ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
    if st.session_state.model:
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
        
        model_manager = ModelManager()
        
        col1, col2 = st.columns(2)
        
        with col1:
            params = sum(p.numel() for p in st.session_state.model.parameters())
            trainable_params = sum(p.numel() for p in st.session_state.model.parameters() if p.requires_grad)
            model_size_mb = sum(p.numel() * p.element_size() for p in st.session_state.model.parameters()) / (1024 * 1024)
            
            st.metric("ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°", f"{params:,}")
            st.metric("å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°", f"{trainable_params:,}")
            st.metric("ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º", f"{model_size_mb:.2f}MB")
        
        with col2:
            # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§
            saved_models = model_manager.list_models()
            if saved_models:
                st.write("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:")
                for model_file in saved_models:
                    st.write(f"- {model_file}")
            else:
                st.info("â„¹ï¸ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <p>ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  | å…‰é€Ÿã§ã»ã¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ä½œ</p>
    </div>
    """,
    unsafe_allow_html=True
)
