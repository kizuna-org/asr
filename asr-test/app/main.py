import streamlit as st
import gc
import os
import time
import json
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import librosa
import soundfile as sf

# ALSAã‚¨ãƒ©ãƒ¼ã‚’æŠ‘åˆ¶
os.environ['ALSA_PCM_CARD'] = '0'
os.environ['ALSA_PCM_DEVICE'] = '0'
os.environ['ALSA_CONFIG_PATH'] = '/dev/null'
os.environ['ALSA_PCM_NAME'] = 'null'
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['PULSE_SERVER'] = 'unix:/tmp/pulse-socket'
os.environ['PULSE_COOKIE'] = '/tmp/pulse-cookie'
os.environ['AUDIODEV'] = 'null'
os.environ['AUDIODRIVER'] = 'null'

# ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è­¦å‘Šã‚’æŠ‘åˆ¶
import warnings
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

# PyTorchã®åˆæœŸåŒ–ã‚’æœ€é©åŒ–
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

# PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
try:
    import torch
    torch.set_num_threads(1)
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
except ImportError as e:
    st.error(f"PyTorchã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

import numpy as np

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.model import LightweightASRModel, FastASRModel, CHAR_TO_ID, ID_TO_CHAR
from app.dataset import AudioPreprocessor, TextPreprocessor, ASRDataset, create_dataloader, SyntheticDataset
from app.trainer import ASRTrainer, FastTrainer
from app.controlled_trainer import ControlledASRTrainer
from app.ljspeech_dataset import create_ljspeech_dataloader
from app.utils import (
    AudioRecorder, RealTimeASR, AudioProcessor, ModelManager, 
    PerformanceMonitor, create_sample_audio_data, save_sample_dataset
)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå‹•ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
def auto_load_latest_model():
    """æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«èª­ã¿è¾¼ã‚€"""
    try:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
        model_dir = "models"
        if not os.path.exists(model_dir):
            print("ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return False
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        model_files = []
        for file in os.listdir(model_dir):
            if file.endswith('.pth') or file.endswith('.pt'):
                model_path = os.path.join(model_dir, file)
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ™‚åˆ»ã‚’å–å¾—
                creation_time = os.path.getctime(model_path)
                model_files.append((model_path, creation_time))
        
        if not model_files:
            print("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        latest_model = max(model_files, key=lambda x: x[1])[0]
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        model_info_path = latest_model.replace('.pth', '_info.json').replace('.pt', '_info.json')
        if os.path.exists(model_info_path):
            with open(model_info_path, 'r') as f:
                model_info = json.load(f)
        else:
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æ¨æ¸¬
            print("ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æ¨æ¸¬ã—ã¾ã™...")
            device = "cuda" if torch.cuda.is_available() else "cpu"
            try:
                checkpoint = torch.load(latest_model, map_location=device)
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬
                if 'output_layer.weight' in checkpoint['model_state_dict']:
                    output_shape = checkpoint['model_state_dict']['output_layer.weight'].shape
                    if output_shape[1] == 64:  # FastASRModel
                        model_info = {'model_type': 'FastASRModel', 'hidden_dim': 64}
                    elif output_shape[1] == 256:  # LightweightASRModel
                        model_info = {'model_type': 'LightweightASRModel', 'hidden_dim': 128, 'num_layers': 2}
                    else:
                        model_info = {'model_type': 'LightweightASRModel', 'hidden_dim': 128, 'num_layers': 2}
                else:
                    model_info = {'model_type': 'LightweightASRModel', 'hidden_dim': 128, 'num_layers': 2}
            except Exception as e:
                print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                return False
        
        print(f"æ¨æ¸¬ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±: {model_info}")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        if model_info.get('model_type', '').startswith('Fast'):
            model = FastASRModel(
                hidden_dim=model_info.get('hidden_dim', 64),
                num_classes=len(CHAR_TO_ID)
            )
        else:
            model = LightweightASRModel(
                hidden_dim=model_info.get('hidden_dim', 128),
                num_layers=model_info.get('num_layers', 2),
                num_classes=len(CHAR_TO_ID)
            )
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        device = "cuda" if torch.cuda.is_available() else "cpu"
        checkpoint = torch.load(latest_model, map_location=device)
        
        # ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
        try:
            model.load_state_dict(checkpoint['model_state_dict'])
            print("ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            # å­¦ç¿’å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
            if 'train_losses' in checkpoint:
                st.session_state.training_history['loss'] = checkpoint['train_losses']
                print(f"å­¦ç¿’æå¤±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(checkpoint['train_losses'])}ã‚¨ãƒãƒƒã‚¯")
            
            if 'val_losses' in checkpoint:
                st.session_state.training_history['val_loss'] = checkpoint['val_losses']
                print(f"æ¤œè¨¼æå¤±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(checkpoint['val_losses'])}ã‚¨ãƒãƒƒã‚¯")
            
            if 'train_wers' in checkpoint:
                st.session_state.training_history['wer'] = checkpoint['train_wers']
                print(f"å­¦ç¿’WERå±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(checkpoint['train_wers'])}ã‚¨ãƒãƒƒã‚¯")
            
            if 'val_wers' in checkpoint:
                st.session_state.training_history['val_wer'] = checkpoint['val_wers']
                print(f"æ¤œè¨¼WERå±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(checkpoint['val_wers'])}ã‚¨ãƒãƒƒã‚¯")
            
            # ã‚¨ãƒãƒƒã‚¯æƒ…å ±ã‚’è¨­å®š
            if 'epoch' in checkpoint:
                total_epochs = checkpoint['epoch']
                st.session_state.training_history['epoch'] = list(range(1, total_epochs + 1))
                print(f"å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°: {total_epochs}")
            
            # ãƒ™ã‚¹ãƒˆæå¤±ã‚’è¨˜éŒ²
            if 'best_val_loss' in checkpoint:
                st.session_state.training_history['best_val_loss'] = checkpoint['best_val_loss']
                print(f"ãƒ™ã‚¹ãƒˆæ¤œè¨¼æå¤±: {checkpoint['best_val_loss']:.4f}")
            
        except Exception as e:
            print(f"ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            print("æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦åˆæœŸåŒ–ã—ã¾ã™")
            # èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦åˆæœŸåŒ–
            model = model.to(device)
            model.eval()
        
        # å‰å‡¦ç†å™¨ã‚’åˆæœŸåŒ–
        audio_preprocessor = AudioPreprocessor()
        text_preprocessor = TextPreprocessor()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.model = model
        st.session_state.audio_preprocessor = audio_preprocessor
        st.session_state.text_preprocessor = text_preprocessor
        
        print(f"è‡ªå‹•ãƒ­ãƒ¼ãƒ‰å®Œäº†: {os.path.basename(latest_model)}")
        return True
        
    except Exception as e:
        print(f"è‡ªå‹•ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'model' not in st.session_state:
    st.session_state.model = None
if 'trainer' not in st.session_state:
    st.session_state.trainer = None
if 'audio_preprocessor' not in st.session_state:
    st.session_state.audio_preprocessor = None
if 'text_preprocessor' not in st.session_state:
    st.session_state.text_preprocessor = None
if 'performance_monitor' not in st.session_state:
    st.session_state.performance_monitor = PerformanceMonitor()
if 'training_history' not in st.session_state:
    st.session_state.training_history = {'loss': [], 'wer': [], 'epoch': []}
if 'controlled_trainer' not in st.session_state:
    st.session_state.controlled_trainer = None
if 'training_status' not in st.session_state:
    st.session_state.training_status = {}
if 'training_progress' not in st.session_state:
    st.session_state.training_progress = {'current_epoch': 0, 'current_batch': 0, 'total_batches': 0}
if 'dataset_info' not in st.session_state:
    st.session_state.dataset_info = None

# ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã‚’è©¦è¡Œ
if st.session_state.model is None:
    print("ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã‚’è©¦è¡Œã—ã¾ã™...")
    auto_load_result = auto_load_latest_model()
    if not auto_load_result:
        print("è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

# ãƒ¡ãƒ¢ãƒªç®¡ç†
def clear_memory():
    """ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

# å®šæœŸçš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
if 'last_memory_clear' not in st.session_state:
    st.session_state.last_memory_clear = time.time()

# 5åˆ†ã”ã¨ã«ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
if time.time() - st.session_state.last_memory_clear > 300:
    clear_memory()
    st.session_state.last_memory_clear = time.time()

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_type = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
        ["FastASRModel (è¶…è»½é‡)", "LightweightASRModel (è»½é‡)"],
        key="model_type_sidebar",
        help="FastASRModelã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™"
    )
    
    # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    device = st.selectbox(
        "ãƒ‡ãƒã‚¤ã‚¹",
        ["cpu", "cuda"] if torch.cuda.is_available() else ["cpu"],
        key="device_sidebar",
        help="GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯cudaã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.subheader("ğŸ¯ å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    learning_rate = st.slider("å­¦ç¿’ç‡", 1e-5, 1e-2, 1e-3, format="%.5f")
    batch_size = st.slider("ãƒãƒƒãƒã‚µã‚¤ã‚º", 1, 32, 8)
    
    # åœæ­¢ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°ã®è¨­å®š
    st.write("**ğŸ›‘ åœæ­¢æ¡ä»¶**")
    max_epochs = st.number_input(
        "åœæ­¢ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°",
        min_value=1,
        max_value=500,
        value=50,
        step=1,
        help="å­¦ç¿’ã‚’åœæ­¢ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°ã‚’è¨­å®šã—ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰"
    )
    
    # å­¦ç¿’æ™‚é–“ã®æ¨å®šè¡¨ç¤º
    estimated_time_per_epoch = 2.0  # æ¨å®šå€¤ï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«å¿œã˜ã¦èª¿æ•´ï¼‰
    estimated_total_time = max_epochs * estimated_time_per_epoch
    st.info(f"â±ï¸ æ¨å®šå­¦ç¿’æ™‚é–“: ç´„{estimated_total_time:.0f}åˆ†ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šç´„{estimated_time_per_epoch:.0f}åˆ†ï¼‰")
    
    # é«˜åº¦ãªå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    with st.expander("ğŸ”§ é«˜åº¦ãªè¨­å®š"):
        weight_decay = st.slider("Weight Decay", 0.0, 0.01, 0.0001, format="%.4f")
        gradient_clip = st.slider("Gradient Clipping", 0.0, 10.0, 1.0, format="%.1f")
        enable_early_stopping = st.checkbox("Early Stopping ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=False)
        early_stopping_patience = st.slider("Early Stopping Patience", 5, 50, 10, disabled=not enable_early_stopping)
        validation_split = st.slider("Validation Split", 0.1, 0.3, 0.2, format="%.1f")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.subheader("ğŸ§  ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    hidden_dim = st.slider("éš ã‚Œå±¤ã‚µã‚¤ã‚º", 32, 256, 64 if model_type.startswith("Fast") else 128)
    num_layers = st.slider("LSTMå±¤æ•°", 1, 4, 1 if model_type.startswith("Fast") else 2)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
    st.subheader("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š")
    dataset_type = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—",
        ["ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿", "LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿"],
        key="dataset_type_sidebar",
        help="ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    if dataset_type == "ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿":
        custom_data_path = st.text_input(
            "ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹",
            value="data/custom",
            help="ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ“Š å­¦ç¿’é€²æ—", "ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜", "ğŸ“ˆ çµæœåˆ†æ", "ğŸš€ å­¦ç¿’åˆ¶å¾¡"])

with tab1:
    st.header("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ¨ ç‰¹å¾´")
        st.markdown("""
        - **å…‰é€Ÿã§ã»ã¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ä½œ**
        - **è»½é‡CNN + LSTM + CTCã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
        - **Dockerã‚³ãƒ³ãƒ†ãƒŠåŒ–æ¸ˆã¿**
        - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’é€²æ—è¡¨ç¤º**
        - **ãƒã‚¤ã‚¯å…¥åŠ›ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–**
        - **é«˜åº¦ãªå­¦ç¿’åˆ¶å¾¡æ©Ÿèƒ½**
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        if st.session_state.performance_monitor:
            stats = st.session_state.performance_monitor.get_statistics()
            if stats:
                st.metric("å¹³å‡æ¨è«–æ™‚é–“", f"{stats['avg_inference_time']:.4f}s")
                st.metric("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['avg_realtime_ratio']:.2f}x")
                st.metric("ç·æ¨è«–å›æ•°", stats['total_inferences'])
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("PyTorch", torch.__version__)
        st.metric("CUDAåˆ©ç”¨å¯èƒ½", "âœ…" if torch.cuda.is_available() else "âŒ")
    
    with col2:
        if torch.cuda.is_available():
            st.metric("GPU", torch.cuda.get_device_name(0))
            st.metric("GPUãƒ¡ãƒ¢ãƒª", f"{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    with col3:
        st.metric("ãƒ‡ãƒã‚¤ã‚¹", device)
        if st.session_state.model:
            params = sum(p.numel() for p in st.session_state.model.parameters())
            st.metric("ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", f"{params:,}")

with tab2:
    st.header("ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    st.subheader("1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–")
    
    # è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã®çµæœã‚’è¡¨ç¤º
    if st.session_state.model is not None:
        st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
        model_params = sum(p.numel() for p in st.session_state.model.parameters())
        
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
        is_trained = False
        if hasattr(st.session_state.model, 'is_trained'):
            is_trained = st.session_state.model.is_trained()
        
        st.info(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {st.session_state.model.__class__.__name__}, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {model_params:,}")
        
        if is_trained:
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’æ¸ˆã¿ã§ã™")
        else:
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ã¯æœªå­¦ç¿’ã§ã™ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã§åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–", type="primary"):
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­..."):
                try:
                    # å‰å‡¦ç†å™¨ã®åˆæœŸåŒ–
                    st.session_state.audio_preprocessor = AudioPreprocessor()
                    st.session_state.text_preprocessor = TextPreprocessor()
                    
                    # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
                    if model_type.startswith("Fast"):
                        st.session_state.model = FastASRModel(
                            hidden_dim=hidden_dim,
                            num_classes=len(CHAR_TO_ID)
                        )
                    else:
                        st.session_state.model = LightweightASRModel(
                            hidden_dim=hidden_dim,
                            num_layers=num_layers,
                            num_classes=len(CHAR_TO_ID)
                        )
                    
                    st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸï¼")
                    
                    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
                    params = sum(p.numel() for p in st.session_state.model.parameters())
                    st.info(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {params:,}ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                    
                except Exception as e:
                    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    with col2:
        if st.session_state.model:
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–æ¸ˆã¿ã§ã™")
        else:
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    st.subheader("2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ**")
        if st.button("ğŸµ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ"):
            with st.spinner("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆä¸­..."):
                try:
                    samples = create_sample_audio_data(num_samples=50, duration=3.0)
                    save_sample_dataset(samples, "data/raw")
                    st.success(f"âœ… {len(samples)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                    st.session_state.dataset_info = {
                        'type': 'sample',
                        'samples': len(samples),
                        'path': 'data/raw'
                    }
                    st.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¨­å®šã—ã¾ã—ãŸ: {st.session_state.dataset_info}")
                except Exception as e:
                    st.error(f"âŒ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    with col2:
        st.write("**ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**")
        uploaded_files = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['wav', 'mp3', 'flac', 'm4a'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.write(f"ğŸ“ {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.uploaded_files = uploaded_files
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å‡¦ç†ã‚’ã“ã“ã«è¿½åŠ 
            st.session_state.dataset_info = {
                'type': 'custom',
                'samples': len(uploaded_files),
                'path': 'data/custom'
            }
            st.info(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¨­å®šã—ã¾ã—ãŸ: {st.session_state.dataset_info}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    st.write("**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ**")
    dataset_selection = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠ",
        ["ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿", "LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿"],
        key="dataset_selection_tab2",
        help="å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    if dataset_selection == "LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ":
        ljspeech_dir = "/app/datasets/ljspeech/1.1.1"
        if os.path.exists(ljspeech_dir):
            st.success("âœ… LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            st.session_state.dataset_info = {
                'type': 'ljspeech',
                'samples': 'unknown',
                'path': ljspeech_dir
            }
            st.info(f"âœ… LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¨­å®šã—ã¾ã—ãŸ: {st.session_state.dataset_info}")
        else:
            st.error("âŒ LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.info("â„¹ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
            st.session_state.dataset_info = None
    elif dataset_selection == "ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿":
        if not st.session_state.dataset_info or st.session_state.dataset_info['type'] != 'custom':
            st.warning("âš ï¸ ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    else:  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        if not st.session_state.dataset_info or st.session_state.dataset_info['type'] != 'sample':
            st.info("â„¹ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã®è¡¨ç¤º
    if st.session_state.dataset_info and isinstance(st.session_state.dataset_info, dict):
        dataset_type = st.session_state.dataset_info.get('type', '')
        dataset_samples = st.session_state.dataset_info.get('samples', 0)
        dataset_path = st.session_state.dataset_info.get('path', '')
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—", dataset_type.upper())
        with col2:
            st.metric("ã‚µãƒ³ãƒ—ãƒ«æ•°", dataset_samples if dataset_samples != 'unknown' else 'Unknown')
        with col3:
            st.metric("ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹", os.path.basename(dataset_path) if dataset_path else 'N/A')
        
        st.info(f"ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_type} ({dataset_samples}ã‚µãƒ³ãƒ—ãƒ«)")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
        if st.button("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æœ€åˆã®5ã¤ã‚’è¡¨ç¤º", help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™"):
            try:
                dataset_path = st.session_state.dataset_info.get('path', '')
                dataset_type = st.session_state.dataset_info.get('type', '')
                
                if dataset_type == 'sample' and os.path.exists(dataset_path):
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¡¨ç¤º
                    metadata_path = os.path.join(dataset_path, "metadata.json")
                    if os.path.exists(metadata_path):
                        with open(metadata_path, 'r') as f:
                            metadata = json.load(f)
                        
                        st.subheader("ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæœ€åˆã®5ã¤ï¼‰")
                        for i, item in enumerate(metadata[:5]):
                            with st.expander(f"ã‚µãƒ³ãƒ—ãƒ« {i+1}: {item['text']}"):
                                st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆ**: {item['text']}")
                                st.write(f"**éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«**: {item['audio']}")
                                
                                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                                audio_path = os.path.join(dataset_path, item['audio'])
                                if os.path.exists(audio_path):
                                    st.success("âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã™")
                                    
                                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
                                    try:
                                        import librosa
                                        audio, sr = librosa.load(audio_path, sr=None)
                                        st.write(f"**é•·ã•**: {len(audio)/sr:.2f}ç§’")
                                        st.write(f"**ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ**: {sr}Hz")
                                        st.write(f"**ã‚µãƒ³ãƒ—ãƒ«æ•°**: {len(audio):,}")
                                        
                                        # éŸ³å£°æ³¢å½¢ã®è¡¨ç¤º
                                        st.line_chart(audio[:1000])  # æœ€åˆã®1000ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
                                    except Exception as e:
                                        st.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                                else:
                                    st.error("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
                elif dataset_type == 'ljspeech':
                    # LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¡¨ç¤º
                    st.subheader("ğŸ“‹ LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæœ€åˆã®5ã¤ï¼‰")
                    st.info("LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯TFRecordå½¢å¼ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ç›´æ¥çš„ãªå†…å®¹è¡¨ç¤ºã¯åˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                    st.write("**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±**:")
                    st.write(f"- **ãƒ‘ã‚¹**: {dataset_path}")
                    st.write(f"- **å½¢å¼**: TFRecord")
                    st.write(f"- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: ç´„13,100å€‹")
                    
                    # TFRecordãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’è¡¨ç¤º
                    tfrecord_files = []
                    if os.path.exists(dataset_path):
                        for file in os.listdir(dataset_path):
                            if file.endswith('.tfrecord'):
                                tfrecord_files.append(file)
                    
                    if tfrecord_files:
                        st.write("**åˆ©ç”¨å¯èƒ½ãªTFRecordãƒ•ã‚¡ã‚¤ãƒ«**:")
                        for i, file in enumerate(tfrecord_files[:5]):
                            st.write(f"- {file}")
                        if len(tfrecord_files) > 5:
                            st.write(f"- ... ä»– {len(tfrecord_files)-5}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«")
                        
                        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºã‚’è©¦è¡Œ
                        if st.button("ğŸ” ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿è¡¨ç¤º", help="TFRecordãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™"):
                            try:
                                # LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
                                from app.ljspeech_dataset import create_ljspeech_dataloader
                                
                                # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ç”¨ï¼‰
                                sample_loader = create_ljspeech_dataloader(
                                    data_dir=dataset_path,
                                    batch_size=5,
                                    shuffle=False
                                )
                                
                                st.write("**ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®5ã¤ï¼‰**:")
                                for batch_idx, (audio_features, text_ids, audio_lengths, text_lengths) in enumerate(sample_loader):
                                    if batch_idx == 0:  # æœ€åˆã®ãƒãƒƒãƒã®ã¿
                                        for i in range(min(5, len(audio_features))):
                                            with st.expander(f"ã‚µãƒ³ãƒ—ãƒ« {i+1}"):
                                                # ãƒ†ã‚­ã‚¹ãƒˆIDã‚’æ–‡å­—ã«å¤‰æ›
                                                text = st.session_state.text_preprocessor.ids_to_text(text_ids[i].tolist())
                                                st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆ**: {text}")
                                                st.write(f"**éŸ³å£°ç‰¹å¾´é‡ã®å½¢çŠ¶**: {audio_features[i].shape}")
                                                st.write(f"**éŸ³å£°é•·**: {audio_lengths[i].item()}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                                                st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆé•·**: {text_lengths[i].item()}æ–‡å­—")
                                                
                                                # éŸ³å£°ç‰¹å¾´é‡ã®å¯è¦–åŒ–
                                                if audio_features[i].shape[0] > 0:
                                                    # æœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                                                    features_sample = audio_features[i][:10].detach().numpy()
                                                    st.write("**éŸ³å£°ç‰¹å¾´é‡ï¼ˆæœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰**:")
                                                    st.dataframe(features_sample)
                                        break
                                
                            except Exception as e:
                                st.error(f"âŒ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                                st.info("â„¹ï¸ TFRecordãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                
                elif dataset_type == 'custom':
                    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¡¨ç¤º
                    st.subheader("ğŸ“‹ ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæœ€åˆã®5ã¤ï¼‰")
                    st.info("ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°è¡¨ç¤ºã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢å¼ã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ã€‚")
                    
                    if 'uploaded_files' in st.session_state:
                        uploaded_files = st.session_state.uploaded_files
                        for i, file in enumerate(uploaded_files[:5]):
                            with st.expander(f"ãƒ•ã‚¡ã‚¤ãƒ« {i+1}: {file.name}"):
                                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {file.name}")
                                st.write(f"**ã‚µã‚¤ã‚º**: {file.size:,} bytes")
                                st.write(f"**ã‚¿ã‚¤ãƒ—**: {file.type}")
                
                else:
                    st.warning("âš ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    
            except Exception as e:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                import traceback
                st.error(f"è©³ç´°: {traceback.format_exc()}")
    elif st.session_state.dataset_info:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ãŒä¸æ­£ã§ã™")
        st.session_state.dataset_info = None  # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: å­¦ç¿’å®Ÿè¡Œ
    st.subheader("3ï¸âƒ£ å­¦ç¿’å®Ÿè¡Œ")
    
    if not st.session_state.model:
        st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    elif not st.session_state.dataset_info or not isinstance(st.session_state.dataset_info, dict):
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚")
    else:
        # å­¦ç¿’è¨­å®šã®ç¢ºèª
        st.subheader("ğŸ“‹ å­¦ç¿’è¨­å®šã®ç¢ºèª")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å­¦ç¿’ç‡", f"{learning_rate:.5f}")
            st.metric("ãƒãƒƒãƒã‚µã‚¤ã‚º", batch_size)
        
        with col2:
            st.metric("åœæ­¢ã‚¨ãƒãƒƒã‚¯", max_epochs)
            st.metric("éš ã‚Œå±¤ã‚µã‚¤ã‚º", hidden_dim)
        
        with col3:
            st.metric("ãƒ‡ãƒã‚¤ã‚¹", device)
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", st.session_state.dataset_info['type'] if st.session_state.dataset_info else "æœªè¨­å®š")
        
        # å­¦ç¿’æ™‚é–“ã®æ¨å®š
        estimated_time_per_epoch = 2.0
        estimated_total_time = max_epochs * estimated_time_per_epoch
        st.info(f"â±ï¸ æ¨å®šå­¦ç¿’æ™‚é–“: ç´„{estimated_total_time:.0f}åˆ†ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šç´„{estimated_time_per_epoch:.0f}åˆ†ï¼‰")
        
        st.markdown("---")

with tab3:
    st.header("ğŸ“Š å­¦ç¿’é€²æ—")
    
    # è‡ªå‹•æ›´æ–°ã®è¨­å®š
    auto_refresh = st.checkbox("ğŸ”„ è‡ªå‹•æ›´æ–°", value=True, help="å­¦ç¿’é€²æ—ã‚’è‡ªå‹•çš„ã«æ›´æ–°ã—ã¾ã™")
    
    if auto_refresh and st.session_state.controlled_trainer:
        status = st.session_state.controlled_trainer.get_training_status()
        if status["is_training"]:
            # è‡ªå‹•æ›´æ–°ã®ãŸã‚ã®JavaScript
            st.markdown(
                """
                <script>
                    setTimeout(function(){
                        window.location.reload();
                    }, 5000);
                </script>
                """,
                unsafe_allow_html=True
            )
    
    # å­¦ç¿’å±¥æ­´ã®è¡¨ç¤ºï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ™‚ã‚‚å«ã‚€ï¼‰
    has_training_history = False
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å­¦ç¿’å±¥æ­´ã‚’ãƒã‚§ãƒƒã‚¯
    if st.session_state.training_history and any(st.session_state.training_history.values()):
        has_training_history = True
        st.subheader("ğŸ“ˆ ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’å±¥æ­´")
        
        # å­¦ç¿’å±¥æ­´ã®çµ±è¨ˆæƒ…å ±
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.session_state.training_history.get('loss'):
                epochs = len(st.session_state.training_history['loss'])
                st.metric("å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°", epochs)
            else:
                st.metric("å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°", 0)
        
        with col2:
            if st.session_state.training_history.get('best_val_loss'):
                st.metric("ãƒ™ã‚¹ãƒˆæ¤œè¨¼æå¤±", f"{st.session_state.training_history['best_val_loss']:.4f}")
            else:
                st.metric("ãƒ™ã‚¹ãƒˆæ¤œè¨¼æå¤±", "N/A")
        
        with col3:
            if st.session_state.training_history.get('loss'):
                final_loss = st.session_state.training_history['loss'][-1]
                st.metric("æœ€çµ‚å­¦ç¿’æå¤±", f"{final_loss:.4f}")
            else:
                st.metric("æœ€çµ‚å­¦ç¿’æå¤±", "N/A")
        
        with col4:
            if st.session_state.training_history.get('wer'):
                final_wer = st.session_state.training_history['wer'][-1]
                st.metric("æœ€çµ‚å­¦ç¿’WER", f"{final_wer:.4f}")
            else:
                st.metric("æœ€çµ‚å­¦ç¿’WER", "N/A")
        
        # å­¦ç¿’æ›²ç·šã®è¡¨ç¤º
        if st.session_state.training_history.get('loss'):
            st.subheader("ğŸ“Š å­¦ç¿’æ›²ç·š")
            
            # Plotlyã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('Training Loss', 'Validation Loss', 'Training WER', 'Validation WER'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # ã‚¨ãƒãƒƒã‚¯æƒ…å ±
            epochs = st.session_state.training_history.get('epoch', list(range(1, len(st.session_state.training_history['loss']) + 1)))
            
            # æå¤±æ›²ç·š
            fig.add_trace(
                go.Scatter(x=epochs, y=st.session_state.training_history['loss'], name="Train Loss", line=dict(color='blue')),
                row=1, col=1
            )
            if st.session_state.training_history.get('val_loss'):
                fig.add_trace(
                    go.Scatter(x=epochs, y=st.session_state.training_history['val_loss'], name="Val Loss", line=dict(color='red')),
                    row=1, col=2
                )
            
            # WERæ›²ç·š
            if st.session_state.training_history.get('wer'):
                fig.add_trace(
                    go.Scatter(x=epochs, y=st.session_state.training_history['wer'], name="Train WER", line=dict(color='green')),
                    row=2, col=1
                )
            if st.session_state.training_history.get('val_wer'):
                fig.add_trace(
                    go.Scatter(x=epochs, y=st.session_state.training_history['val_wer'], name="Val WER", line=dict(color='orange')),
                    row=2, col=2
                )
            
            # ã‚°ãƒ©ãƒ•ã®è¨­å®š
            fig.update_layout(height=600, showlegend=True)
            fig.update_xaxes(title_text="Epoch")
            fig.update_yaxes(title_text="Loss", row=1, col=1)
            fig.update_yaxes(title_text="Loss", row=1, col=2)
            fig.update_yaxes(title_text="WER", row=2, col=1)
            fig.update_yaxes(title_text="WER", row=2, col=2)
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ç¾åœ¨ã®å­¦ç¿’çŠ¶æ…‹ã®è¡¨ç¤º
    if not st.session_state.controlled_trainer:
        if not has_training_history:
            st.warning("âš ï¸ **ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“**")
            st.info("ğŸ’¡ **è§£æ±ºæ–¹æ³•**:")
            st.info("1. ã€ŒğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ã‚¿ãƒ–ã«ç§»å‹•")
            st.info("2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¾ãŸã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰")
            st.info("3. ã€Œâ–¶ï¸ å­¦ç¿’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–")
            st.info("4. ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚ŒãŸã‚‰ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’é€²æ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
            
            # ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¿ãƒ–ã«ç§»å‹•", type="primary", use_container_width=True):
                st.switch_page("ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        else:
            st.success("âœ… ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’å±¥æ­´ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™")
            st.info("â„¹ï¸ æ–°ã—ã„å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¿ãƒ–ã§ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„")
    else:
        # å­¦ç¿’çŠ¶æ…‹ã®è¡¨ç¤º
        status = st.session_state.controlled_trainer.get_training_status()
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒãƒ¼
        if status["is_training"]:
            progress = (status["current_epoch"] * status["total_batches"] + status["current_batch"]) / (status["max_epochs"] * status["total_batches"])
            st.progress(progress)
            st.write(f"é€²æ—: {progress:.1%}")
            
            # æ¨å®šæ®‹ã‚Šæ™‚é–“
            if status["current_batch"] > 0:
                elapsed_time = time.time() - getattr(st.session_state, 'training_start_time', time.time())
                avg_time_per_batch = elapsed_time / (status["current_epoch"] * status["total_batches"] + status["current_batch"])
                remaining_batches = (status["max_epochs"] * status["total_batches"]) - (status["current_epoch"] * status["total_batches"] + status["current_batch"])
                estimated_remaining_time = remaining_batches * avg_time_per_batch
                
                st.info(f"â±ï¸ æ¨å®šæ®‹ã‚Šæ™‚é–“: {estimated_remaining_time/60:.1f}åˆ†")
        
        # å­¦ç¿’çŠ¶æ…‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å­¦ç¿’ä¸­", "âœ…" if status["is_training"] else "âŒ")
            st.metric("ä¸€æ™‚åœæ­¢", "âœ…" if status["is_paused"] else "âŒ")
        
        with col2:
            st.metric("ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯", f"{status['current_epoch'] + 1}/{status['max_epochs']}")
            st.metric("ç¾åœ¨ã®ãƒãƒƒãƒ", f"{status['current_batch']}/{status['total_batches']}")
        
        with col3:
            st.metric("ãƒ™ã‚¹ãƒˆæå¤±", f"{status['best_val_loss']:.4f}")
            st.metric("ãƒ™ã‚¹ãƒˆã‚¨ãƒãƒƒã‚¯", status["best_epoch"] + 1)
        
        with col4:
            st.metric("å­¦ç¿’ç‡", f"{status['learning_rate']:.5f}")
            st.metric("æ®‹ã‚Šæ™‚é–“", "è¨ˆç®—ä¸­..." if status["is_training"] else "åœæ­¢ä¸­")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’æ›²ç·šï¼ˆç¾åœ¨ã®å­¦ç¿’ä¸­ã®å ´åˆï¼‰
        if status["is_training"] and status["train_losses"]:
            st.subheader("ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’æ›²ç·š")
            
            # Plotlyã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('Training Loss', 'Validation Loss', 'Training WER', 'Validation WER'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # æå¤±æ›²ç·š
            epochs = list(range(1, len(status["train_losses"]) + 1))
            fig.add_trace(
                go.Scatter(x=epochs, y=status["train_losses"], name="Train Loss", line=dict(color='blue')),
                row=1, col=1
            )
            if status["val_losses"]:
                fig.add_trace(
                    go.Scatter(x=epochs, y=status["val_losses"], name="Val Loss", line=dict(color='red')),
                    row=1, col=2
                )
            
            # WERæ›²ç·š
            if status["train_wers"]:
                fig.add_trace(
                    go.Scatter(x=epochs, y=status["train_wers"], name="Train WER", line=dict(color='green')),
                    row=2, col=1
                )
            if status["val_wers"]:
                fig.add_trace(
                    go.Scatter(x=epochs, y=status["val_wers"], name="Val WER", line=dict(color='orange')),
                    row=2, col=2
                )
            
            # ã‚°ãƒ©ãƒ•ã®è¨­å®š
            fig.update_layout(height=600, showlegend=True)
            fig.update_xaxes(title_text="Epoch")
            fig.update_yaxes(title_text="Loss", row=1, col=1)
            fig.update_yaxes(title_text="Loss", row=1, col=2)
            fig.update_yaxes(title_text="WER", row=2, col=1)
            fig.update_yaxes(title_text="WER", row=2, col=2)
            
            st.plotly_chart(fig, use_container_width=True)
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†
        st.subheader("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†")
        
        if not st.session_state.controlled_trainer:
            st.warning("âš ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.info("â„¹ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹ã¨ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç®¡ç†ãŒå¯èƒ½ã«ãªã‚Šã¾ã™")
        else:
            checkpoints = st.session_state.controlled_trainer.get_available_checkpoints()
            
            if checkpoints:
                selected_checkpoint = st.selectbox(
                    "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ",
                    checkpoints,
                    key="checkpoint_select_tab4",
                    help="èª­ã¿è¾¼ã‚€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„"
                )
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“¥ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿", use_container_width=True):
                        checkpoint_path = os.path.join("models", selected_checkpoint)
                        result = st.session_state.controlled_trainer.load_checkpoint(checkpoint_path)
                        st.success(result["message"])
                
                with col2:
                    if st.button("ğŸ’¾ ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜", use_container_width=True):
                        result = st.session_state.controlled_trainer.save_checkpoint()
                        st.success(result["message"])
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§
                st.write("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:")
                for i, checkpoint in enumerate(checkpoints[-5:]):  # æœ€æ–°5å€‹ã‚’è¡¨ç¤º
                    st.write(f"{i+1}. {checkpoint}")
            else:
                st.info("â„¹ï¸ åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")

with tab4:
    st.header("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜")
    
    if not st.session_state.model:
        st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
        if hasattr(st.session_state.model, 'is_trained') and not st.session_state.model.is_trained():
            st.error("âŒ **ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼**")
            st.warning("âš ï¸ ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯åˆæœŸåŒ–ã•ã‚ŒãŸã°ã‹ã‚Šã§ã€å®Ÿéš›ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.info("ğŸ’¡ **è§£æ±ºæ–¹æ³•**:")
            st.info("1. ã€ŒğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ã‚¿ãƒ–ã«ç§»å‹•")
            st.info("2. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯éŒ²éŸ³")
            st.info("3. ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ")
            st.info("4. å­¦ç¿’å®Œäº†å¾Œã«å†åº¦éŸ³å£°èªè­˜ã‚’è©¦ã—ã¦ãã ã•ã„")
            
            # å­¦ç¿’çŠ¶æ…‹ã®è©³ç´°æƒ…å ±
            with st.expander("ğŸ” ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±"):
                params = sum(p.numel() for p in st.session_state.model.parameters())
                st.write(f"**ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—**: {st.session_state.model.__class__.__name__}")
                st.write(f"**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°**: {params:,}")
                st.write(f"**å­¦ç¿’çŠ¶æ…‹**: æœªå­¦ç¿’")
                st.write(f"**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å®Ÿè¡Œ")
        else:
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã§ã™ã€‚éŸ³å£°èªè­˜ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        
        st.subheader("ğŸ™ï¸ ãƒã‚¤ã‚¯å…¥åŠ›")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", type="primary"):
                st.session_state.recording = True
                st.session_state.recognized_text = []
                
                # éŒ²éŸ³æ©Ÿã®åˆæœŸåŒ–
                recorder = AudioRecorder()
                
                # éŒ²éŸ³é–‹å§‹ã‚’è©¦è¡Œ
                if recorder.start_recording():
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ã®å®Ÿè¡Œ
                    realtime_asr = RealTimeASR(
                        model=st.session_state.model,
                        audio_preprocessor=st.session_state.audio_preprocessor,
                        text_preprocessor=st.session_state.text_preprocessor,
                        device=device
                    )
                    
                    # èªè­˜çµæœã®è¡¨ç¤º
                    result_placeholder = st.empty()
                    
                    try:
                        for i in range(10):  # 10å›ã®èªè­˜ã‚’å®Ÿè¡Œ
                            audio_data = recorder.get_audio_data(3.0)  # 3ç§’é–“ã®éŸ³å£°
                            
                            if len(audio_data) > 0:
                                start_time = time.time()
                                text = realtime_asr.recognize_audio(audio_data)
                                inference_time = time.time() - start_time
                                
                                if text.strip():
                                    st.session_state.recognized_text.append(text)
                                    result_placeholder.write(f"ğŸ¯ èªè­˜çµæœ: **{text}**")
                                    
                                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²
                                    st.session_state.performance_monitor.record_inference(
                                        inference_time, 3.0
                                    )
                            
                            time.sleep(0.1)  # å°‘ã—å¾…æ©Ÿ
                    
                    finally:
                        recorder.close()
                        st.session_state.recording = False
                else:
                    st.error("âŒ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    st.info("â„¹ï¸ Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™")
                    st.info("â„¹ï¸ ä»£ã‚ã‚Šã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦èªè­˜ã—ã¦ãã ã•ã„")
                    st.session_state.recording = False
        
        with col2:
            if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢"):
                st.session_state.recording = False
                st.success("âœ… éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»£æ›¿æ‰‹æ®µï¼‰
        st.subheader("ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        st.info("â„¹ï¸ Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦èªè­˜ã—ã¦ãã ã•ã„")
        
        # ãƒ‡ãƒ¢ç”¨éŸ³å£°ç”Ÿæˆ
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸµ ãƒ‡ãƒ¢éŸ³å£°ç”Ÿæˆ", help="ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™"):
                try:
                    from app.utils import create_sample_audio_data
                    samples = create_sample_audio_data(num_samples=1, duration=3.0)
                    audio_data = samples[0][0]  # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
                    
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’è¡¨ç¤º
                    st.info(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿: é•·ã•={len(audio_data)}ã‚µãƒ³ãƒ—ãƒ«, ç¯„å›²=[{audio_data.min():.4f}, {audio_data.max():.4f}]")
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        sf.write(tmp_file.name, audio_data, 16000)
                        temp_path = tmp_file.name
                    
                    # èªè­˜å®Ÿè¡Œ
                    realtime_asr = RealTimeASR(
                        model=st.session_state.model,
                        audio_preprocessor=st.session_state.audio_preprocessor,
                        text_preprocessor=st.session_state.text_preprocessor,
                        device=device
                    )
                    
                    start_time = time.time()
                    text = realtime_asr.recognize_audio(audio_data)
                    inference_time = time.time() - start_time
                    
                    # çµæœè¡¨ç¤º
                    if text.strip():
                        st.success(f"ğŸ¯ èªè­˜çµæœ: **{text}**")
                    else:
                        st.warning("âš ï¸ èªè­˜çµæœãŒç©ºã§ã™ã€‚")
                        st.info("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                        st.code(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿é•·: {len(audio_data)}ã‚µãƒ³ãƒ—ãƒ«")
                        st.code(f"æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’")
                        st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã§ã‚‚ã€éŸ³å£°ã®å“è³ªã‚„å†…å®¹ã«ã‚ˆã£ã¦èªè­˜ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
                    
                    st.info(f"â±ï¸ æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’")
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²
                    st.session_state.performance_monitor.record_inference(
                        inference_time, len(audio_data) / 16000
                    )
                    
                    # å±¥æ­´ã«è¿½åŠ 
                    if not hasattr(st.session_state, 'recognized_text'):
                        st.session_state.recognized_text = []
                    st.session_state.recognized_text.append(text)
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    os.unlink(temp_path)
                    
                except Exception as e:
                    st.error(f"âŒ ãƒ‡ãƒ¢éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                    import traceback
                    st.error(f"è©³ç´°: {traceback.format_exc()}")
        
        with col2:
            st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ‡ãƒ¢éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã§ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã¾ã™")
        
        uploaded_audio = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦èªè­˜",
            type=['wav', 'mp3', 'flac', 'm4a'],
            key="audio_upload_tab4"
        )
        
        if uploaded_audio and st.session_state.model:
            if st.button("ğŸ¯ éŸ³å£°èªè­˜å®Ÿè¡Œ", type="primary"):
                try:
                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        tmp_file.write(uploaded_audio.getvalue())
                        temp_path = tmp_file.name
                    
                    # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
                    audio, sr = librosa.load(temp_path, sr=16000)
                    
                    # èªè­˜å®Ÿè¡Œ
                    realtime_asr = RealTimeASR(
                        model=st.session_state.model,
                        audio_preprocessor=st.session_state.audio_preprocessor,
                        text_preprocessor=st.session_state.text_preprocessor,
                        device=device
                    )
                    
                    start_time = time.time()
                    text = realtime_asr.recognize_audio(audio)
                    inference_time = time.time() - start_time
                    
                    # çµæœè¡¨ç¤º
                    if text.strip():
                        st.success(f"ğŸ¯ èªè­˜çµæœ: **{text}**")
                    else:
                        st.warning("âš ï¸ èªè­˜çµæœãŒç©ºã§ã™ã€‚")
                        st.info("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                        st.code(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_audio.name}")
                        st.code(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿é•·: {len(audio)}ã‚µãƒ³ãƒ—ãƒ«")
                        st.code(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {sr}Hz")
                        st.code(f"æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’")
                        st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: éŸ³å£°ã®å“è³ªã‚„å†…å®¹ã«ã‚ˆã£ã¦èªè­˜ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
                    
                    st.info(f"â±ï¸ æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’")
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²
                    st.session_state.performance_monitor.record_inference(
                        inference_time, len(audio) / sr
                    )
                    
                    # å±¥æ­´ã«è¿½åŠ 
                    if not hasattr(st.session_state, 'recognized_text'):
                        st.session_state.recognized_text = []
                    st.session_state.recognized_text.append(text)
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    os.unlink(temp_path)
                    
                except Exception as e:
                    st.error(f"âŒ éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        
        # èªè­˜çµæœã®å±¥æ­´
        if hasattr(st.session_state, 'recognized_text') and st.session_state.recognized_text:
            st.subheader("ğŸ“ èªè­˜å±¥æ­´")
            for i, text in enumerate(st.session_state.recognized_text):
                st.write(f"{i+1}. {text}")

with tab5:
    st.header("ğŸ“ˆ çµæœåˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ å­¦ç¿’æ›²ç·š")
        
        if st.session_state.training_history['loss']:
            # å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
            df = pd.DataFrame(st.session_state.training_history)
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('Training Loss', 'Training WER'),
                vertical_spacing=0.1
            )
            
            fig.add_trace(
                go.Scatter(x=df['epoch'], y=df['loss'], name='Loss'),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=df['epoch'], y=df['wer'], name='WER'),
                row=2, col=1
            )
            
            fig.update_layout(height=600, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("â„¹ï¸ å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    with col2:
        st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        
        stats = st.session_state.performance_monitor.get_statistics()
        if stats:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®è¡¨ç¤º
            st.metric("ç·æ¨è«–å›æ•°", stats['total_inferences'])
            st.metric("å¹³å‡æ¨è«–æ™‚é–“", f"{stats['avg_inference_time']:.4f}s")
            st.metric("æ¨è«–æ™‚é–“æ¨™æº–åå·®", f"{stats['std_inference_time']:.4f}s")
            st.metric("å¹³å‡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['avg_realtime_ratio']:.2f}x")
            st.metric("æœ€å°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['min_realtime_ratio']:.2f}x")
            st.metric("æœ€å¤§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯”", f"{stats['max_realtime_ratio']:.2f}x")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°ãƒœã‚¿ãƒ³
            if st.button("ğŸ“Š è©³ç´°çµ±è¨ˆã‚’è¡¨ç¤º"):
                st.session_state.performance_monitor.print_statistics()
        else:
            st.info("â„¹ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
    if st.session_state.model:
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
        
        model_manager = ModelManager()
        
        col1, col2 = st.columns(2)
        
        with col1:
            params = sum(p.numel() for p in st.session_state.model.parameters())
            trainable_params = sum(p.numel() for p in st.session_state.model.parameters() if p.requires_grad)
            model_size_mb = sum(p.numel() * p.element_size() for p in st.session_state.model.parameters()) / (1024 * 1024)
            
            st.metric("ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°", f"{params:,}")
            st.metric("å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°", f"{trainable_params:,}")
            st.metric("ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º", f"{model_size_mb:.2f}MB")
        
        with col2:
            # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§
            saved_models = model_manager.list_models()
            if saved_models:
                st.write("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:")
                for model_file in saved_models:
                    st.write(f"- {model_file}")
            else:
                st.info("â„¹ï¸ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab6:
    st.header("ğŸš€ å­¦ç¿’åˆ¶å¾¡")
    
    if not st.session_state.model:
        st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("ğŸ›ï¸ å­¦ç¿’åˆ¶å¾¡ãƒ‘ãƒãƒ«")
        
        # åœæ­¢æ¡ä»¶ã®è¨­å®š
        st.subheader("ğŸ›‘ åœæ­¢æ¡ä»¶ã®è¨­å®š")
        col1, col2 = st.columns(2)
        
        with col1:
            # ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
            if st.session_state.controlled_trainer:
                current_status = st.session_state.controlled_trainer.get_training_status()
                st.info(f"**ç¾åœ¨ã®è¨­å®š**: æœ€å¤§{current_status['max_epochs']}ã‚¨ãƒãƒƒã‚¯")
            
            # æ–°ã—ã„åœæ­¢æ¡ä»¶ã®è¨­å®š
            new_max_epochs = st.number_input(
                "æ–°ã—ã„åœæ­¢ã‚¨ãƒãƒƒã‚¯æ•°",
                min_value=1,
                max_value=500,
                value=50,
                step=1,
                help="å­¦ç¿’ã‚’åœæ­¢ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¤‰æ›´ã—ã¾ã™"
            )
            
            if st.button("ğŸ”„ åœæ­¢æ¡ä»¶ã‚’æ›´æ–°", use_container_width=True):
                if st.session_state.controlled_trainer:
                    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã‚’æ›´æ–°
                    st.session_state.controlled_trainer.max_epochs = new_max_epochs
                    st.success(f"âœ… åœæ­¢æ¡ä»¶ã‚’{new_max_epochs}ã‚¨ãƒãƒƒã‚¯ã«æ›´æ–°ã—ã¾ã—ãŸ")
                else:
                    st.error("âŒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        with col2:
            # å­¦ç¿’æ™‚é–“ã®æ¨å®š
            estimated_time_per_epoch = 2.0
            estimated_total_time = new_max_epochs * estimated_time_per_epoch
            
            st.metric("æ¨å®šå­¦ç¿’æ™‚é–“", f"{estimated_total_time:.0f}åˆ†")
            st.metric("1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Š", f"{estimated_time_per_epoch:.0f}åˆ†")
            
            # ç¾åœ¨ã®å­¦ç¿’çŠ¶æ…‹ã¨ã®æ¯”è¼ƒ
            if st.session_state.controlled_trainer:
                current_status = st.session_state.controlled_trainer.get_training_status()
                remaining_epochs = new_max_epochs - (current_status['current_epoch'] + 1)
                if remaining_epochs > 0:
                    st.info(f"æ®‹ã‚Šã‚¨ãƒãƒƒã‚¯æ•°: {remaining_epochs}")
                    st.info(f"æ®‹ã‚Šæ¨å®šæ™‚é–“: {remaining_epochs * estimated_time_per_epoch:.0f}åˆ†")
        
        st.markdown("---")
        
        # å­¦ç¿’çŠ¶æ…‹ã®è¡¨ç¤º
        if st.session_state.controlled_trainer:
            status = st.session_state.controlled_trainer.get_training_status()
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
            if st.button("ğŸ”„ çŠ¶æ…‹æ›´æ–°"):
                # ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°
                st.markdown(
                    """
                    <script>
                        window.location.reload();
                    </script>
                    """,
                    unsafe_allow_html=True
                )
            
            # å­¦ç¿’çŠ¶æ…‹ã®è©³ç´°è¡¨ç¤º
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "å­¦ç¿’çŠ¶æ…‹", 
                    "ğŸŸ¢ å®Ÿè¡Œä¸­" if status["is_training"] else "ğŸ”´ åœæ­¢ä¸­",
                    delta="ä¸€æ™‚åœæ­¢ä¸­" if status["is_paused"] else ""
                )
            
            with col2:
                st.metric(
                    "ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯", 
                    f"{status['current_epoch'] + 1}/{status['max_epochs']}",
                    delta=f"ãƒãƒƒãƒ {status['current_batch']}"
                )
            
            with col3:
                st.metric(
                    "ãƒ™ã‚¹ãƒˆæå¤±", 
                    f"{status['best_val_loss']:.4f}",
                    delta=f"ã‚¨ãƒãƒƒã‚¯ {status['best_epoch'] + 1}"
                )
            
            with col4:
                progress = (status['current_epoch'] + 1) / status['max_epochs'] * 100
                st.metric(
                    "é€²æ—", 
                    f"{progress:.1f}%",
                    delta=f"æ®‹ã‚Š {status['max_epochs'] - (status['current_epoch'] + 1)} ã‚¨ãƒãƒƒã‚¯"
                )
        
        # å­¦ç¿’åˆ¶å¾¡ãƒœã‚¿ãƒ³
        st.subheader("ğŸ® å­¦ç¿’åˆ¶å¾¡")
        
        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–çŠ¶æ…‹ã‚’è¡¨ç¤º
        if st.session_state.controlled_trainer:
            st.success("âœ… **ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–æ¸ˆã¿ã§ã™**")
            status = st.session_state.controlled_trainer.get_training_status()
            st.info(f"ğŸ“Š **ç¾åœ¨ã®çŠ¶æ…‹**: {'å­¦ç¿’ä¸­' if status['is_training'] else 'åœæ­¢ä¸­'} (ã‚¨ãƒãƒƒã‚¯ {status['current_epoch'] + 1}/{status['max_epochs']})")
        else:
            st.warning("âš ï¸ **ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“**")
            st.info("ğŸ’¡ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: ä¸‹ã®ã€Œâ–¶ï¸ å­¦ç¿’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("â–¶ï¸ å­¦ç¿’é–‹å§‹", type="primary"):
                try:
                    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã®æ¤œè¨¼
                    if not st.session_state.dataset_info or not isinstance(st.session_state.dataset_info, dict):
                        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ãŒä¸æ­£ã§ã™")
                        st.stop()
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
                    if st.session_state.dataset_info['type'] == 'sample':
                        dataset = ASRDataset(
                            data_dir=st.session_state.dataset_info['path'],
                            audio_preprocessor=st.session_state.audio_preprocessor,
                            text_preprocessor=st.session_state.text_preprocessor
                        )
                        train_loader = create_dataloader(dataset, batch_size=batch_size, shuffle=True)
                        st.success(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(dataset)}ã‚µãƒ³ãƒ—ãƒ«")
                    elif st.session_state.dataset_info['type'] == 'ljspeech':
                        ljspeech_dir = "/app/datasets/ljspeech/1.1.1"
                        if os.path.exists(ljspeech_dir):
                            try:
                                train_loader, dataset_info = create_ljspeech_dataloader(
                                    data_dir=ljspeech_dir,
                                    audio_preprocessor=st.session_state.audio_preprocessor,
                                    text_preprocessor=st.session_state.text_preprocessor,
                                    batch_size=batch_size
                                )
                                st.success(f"âœ… LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {dataset_info['total_samples']}ã‚µãƒ³ãƒ—ãƒ«")
                            except ValueError as e:
                                st.error(f"âŒ LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                                st.info("â„¹ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                                st.stop()
                        else:
                            st.error("âŒ LJSpeechãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                            st.info("â„¹ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                            st.stop()
                    elif st.session_state.dataset_info['type'] == 'custom':
                        # ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡¦ç†
                        if isinstance(st.session_state.dataset_info, dict):
                            custom_path = st.session_state.dataset_info.get('path', 'data/custom')
                        else:
                            custom_path = 'data/custom'
                        if os.path.exists(custom_path):
                            dataset = ASRDataset(
                                data_dir=custom_path,
                                audio_preprocessor=st.session_state.audio_preprocessor,
                                text_preprocessor=st.session_state.text_preprocessor
                            )
                            train_loader = create_dataloader(dataset, batch_size=batch_size, shuffle=True)
                            st.success(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(dataset)}ã‚µãƒ³ãƒ—ãƒ«")
                        else:
                            st.error(f"âŒ ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {custom_path}")
                            st.stop()
                    
                    # åˆ¶å¾¡å¯èƒ½ãªãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
                    with st.spinner("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­..."):
                        st.session_state.controlled_trainer = ControlledASRTrainer(
                            model=st.session_state.model,
                            train_loader=train_loader,
                            device=device,
                            learning_rate=learning_rate,
                            max_epochs=max_epochs,
                            model_save_dir="models",
                            weight_decay=weight_decay,
                            gradient_clip=gradient_clip,
                            early_stopping_patience=early_stopping_patience if enable_early_stopping else None,
                            validation_split=validation_split
                        )
                    
                    # å­¦ç¿’é–‹å§‹
                    st.session_state.training_start_time = time.time()
                    result = st.session_state.controlled_trainer.start_training()
                    st.success("âœ… **ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–ã¨å­¦ç¿’é–‹å§‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼**")
                    st.info("ğŸ“Š ã€Œå­¦ç¿’é€²æ—ã€ã‚¿ãƒ–ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ã‚’ç¢ºèªã§ãã¾ã™")
                    st.info("ğŸ® ã€Œå­¦ç¿’åˆ¶å¾¡ã€ã‚¿ãƒ–ã§å­¦ç¿’ã‚’åˆ¶å¾¡ã§ãã¾ã™")
                    
                except Exception as e:
                    import traceback
                    st.error(f"âŒ å­¦ç¿’é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                    st.error(f"è©³ç´°: {traceback.format_exc()}")
                    st.error(f"dataset_info: {st.session_state.dataset_info}")
                    st.error(f"dataset_info type: {type(st.session_state.dataset_info)}")
        
        with col2:
            if st.button("â¸ï¸ ä¸€æ™‚åœæ­¢"):
                if st.session_state.controlled_trainer:
                    result = st.session_state.controlled_trainer.pause_training()
                    st.info(result["message"])
                else:
                    st.warning("âš ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        with col3:
            if st.button("â–¶ï¸ å†é–‹"):
                if st.session_state.controlled_trainer:
                    result = st.session_state.controlled_trainer.resume_training()
                    st.success(result["message"])
                else:
                    st.warning("âš ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        with col4:
            if st.button("â¹ï¸ åœæ­¢"):
                if st.session_state.controlled_trainer:
                    result = st.session_state.controlled_trainer.stop_training()
                    st.warning(result["message"])
                else:
                    st.warning("âš ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <p>ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  | å…‰é€Ÿã§ã»ã¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ä½œ</p>
    </div>
    """,
    unsafe_allow_html=True
)
