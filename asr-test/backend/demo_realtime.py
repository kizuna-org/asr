#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sys
import os
import torch
import torchaudio
import numpy as np
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, '/app')

from app.models.realtime import RealtimeASRModel, RealtimeASRPipeline, create_audio_chunks
from app import config_loader

def generate_test_audio(duration_sec=5.0, sample_rate=16000, frequency=440):
    """ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ã‚’ç”Ÿæˆ"""
    t = torch.linspace(0, duration_sec, int(sample_rate * duration_sec))
    # è¤‡æ•°ã®å‘¨æ³¢æ•°ã‚’æ··ãœã¦ã‚ˆã‚Šè‡ªç„¶ãªéŸ³å£°ã«
    audio = (torch.sin(2 * np.pi * frequency * t) + 
             0.5 * torch.sin(2 * np.pi * frequency * 2 * t) +
             0.3 * torch.sin(2 * np.pi * frequency * 3 * t))
    return audio

def simulate_realtime_processing():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸµ Simulating realtime audio processing...")
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    config = config_loader.load_config()
    realtime_config = config.get('models', {}).get('realtime', {})
    
    if not realtime_config:
        print("âŒ Realtime model config not found")
        return
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
    model = RealtimeASRModel(realtime_config)
    pipeline = RealtimeASRPipeline(model)
    
    # ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’ç”Ÿæˆï¼ˆ10ç§’é–“ï¼‰
    test_audio = generate_test_audio(duration_sec=10.0)
    sample_rate = 16000
    chunk_size_ms = 100
    chunk_samples = int(sample_rate * chunk_size_ms / 1000)
    
    print(f"ğŸ“Š Audio: {test_audio.shape[0]} samples ({test_audio.shape[0]/sample_rate:.1f}s)")
    print(f"ğŸ“Š Chunk size: {chunk_samples} samples ({chunk_size_ms}ms)")
    print(f"ğŸ“Š Total chunks: {test_audio.shape[0] // chunk_samples}")
    print()
    
    # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    accumulated_text = ""
    chunk_count = 0
    
    for i in range(0, test_audio.shape[0], chunk_samples):
        chunk = test_audio[i:i+chunk_samples]
        
        if chunk.shape[0] < chunk_samples:
            # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ãŒçŸ­ã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            padding = torch.zeros(chunk_samples - chunk.shape[0])
            chunk = torch.cat([chunk, padding])
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        start_time = time.time()
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
        chunk_text = pipeline.process_audio_chunk(chunk)
        
        processing_time = time.time() - start_time
        
        if chunk_text:
            accumulated_text += chunk_text
        
        chunk_count += 1
        
        # é€²æ—è¡¨ç¤º
        progress = (i + chunk_samples) / test_audio.shape[0] * 100
        print(f"\rğŸ”„ Chunk {chunk_count:3d} | "
              f"Progress: {progress:5.1f}% | "
              f"Processing: {processing_time*1000:4.1f}ms | "
              f"Text: '{accumulated_text}'", end="", flush=True)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿã‚’å‡ºã™ãŸã‚ã«å°‘ã—å¾…æ©Ÿ
        time.sleep(0.05)  # 50mså¾…æ©Ÿ
    
    print(f"\n\nâœ… Processing completed!")
    print(f"ğŸ“ Final accumulated text: '{accumulated_text}'")
    print(f"ğŸ“Š Total chunks processed: {chunk_count}")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
    pipeline.reset()
    print("ğŸ”„ Pipeline reset completed")

def demo_model_components():
    """ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ‡ãƒ¢"""
    print("ğŸ”§ Demonstrating model components...")
    
    config = config_loader.load_config()
    realtime_config = config.get('models', {}).get('realtime', {})
    
    if not realtime_config:
        print("âŒ Realtime model config not found")
        return
    
    model = RealtimeASRModel(realtime_config)
    
    # ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’ç”Ÿæˆ
    test_audio = generate_test_audio(duration_sec=1.0)
    
    print(f"ğŸ“Š Input audio shape: {test_audio.shape}")
    
    # ç‰¹å¾´æŠ½å‡ºã®ãƒ‡ãƒ¢
    features = model.extract_features(test_audio)
    print(f"ğŸ“Š Extracted features shape: {features.shape}")
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ãƒ‡ãƒ¢
    encoder_output, hidden_state = model.encoder(features)
    print(f"ğŸ“Š Encoder output shape: {encoder_output.shape}")
    print(f"ğŸ“Š Hidden state shape: {hidden_state.shape}")
    
    # ãƒ‡ã‚³ãƒ¼ãƒ€ã®ãƒ‡ãƒ¢
    log_probs = model.decoder(encoder_output)
    print(f"ğŸ“Š Decoder output shape: {log_probs.shape}")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¢
    detected_chars = model.decoder.decode_realtime(log_probs[0])
    print(f"ğŸ“Š Detected characters: {detected_chars}")
    
    # å¾Œå‡¦ç†ã®ãƒ‡ãƒ¢
    final_text = model._post_process_ctc_output(detected_chars)
    print(f"ğŸ“Š Final text: '{final_text}'")

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢é–¢æ•°"""
    print("ğŸš€ RealtimeASRModel Demo")
    print("=" * 50)
    
    try:
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ‡ãƒ¢
        demo_model_components()
        print("\n" + "=" * 50)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        simulate_realtime_processing()
        
        print("\nğŸ‰ Demo completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
