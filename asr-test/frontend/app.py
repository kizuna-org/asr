import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import requests
import json
from typing import Dict, Any
import traceback
import os
import logging
import sys
from datetime import datetime
import warnings

# æ©Ÿèƒ½ãƒãƒªã‚·ãƒ¼è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', message='.*æ©Ÿèƒ½ãƒãƒªã‚·ãƒ¼.*')
warnings.filterwarnings('ignore', message='.*Permissions-Policy.*')
warnings.filterwarnings('ignore', message='.*Feature-Policy.*')

# --- ãƒ­ã‚°è¨­å®š ---
class StructuredFormatter(logging.Formatter):
    """æ§‹é€ åŒ–ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰"""

    def format(self, record):
        log_entry = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }

        # ä¾‹å¤–æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if record.exc_info:
            log_entry["exception"] = self.formatException(record.exc_info)

        # è¿½åŠ ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if hasattr(record, 'extra_fields'):
            log_entry.update(record.extra_fields)

        return json.dumps(log_entry, ensure_ascii=False)

def setup_frontend_logging():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–"""
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®è¨­å®š
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(StructuredFormatter())
    root_logger.addHandler(console_handler)

    # ç‰¹å®šã®ãƒ­ã‚¬ãƒ¼ã®ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger("ui-rt").setLevel(logging.INFO)
    logging.getLogger("audio_puller").setLevel(logging.INFO)

# ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–
setup_frontend_logging()

# --- è¨­å®š ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰URLã‚’å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆ
BACKEND_HOST = os.getenv("BACKEND_HOST", "localhost")
BACKEND_PORT = os.getenv("BACKEND_PORT", "58081")
BACKEND_URL = f"http://{BACKEND_HOST}:{BACKEND_PORT}/api"

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
HTTP_PROXY = os.getenv("HTTP_PROXY")
HTTPS_PROXY = os.getenv("HTTPS_PROXY")
NO_PROXY = os.getenv("NO_PROXY", "localhost,127.0.0.1,asr-api")

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’è¾æ›¸å½¢å¼ã§æº–å‚™
proxies = {}
if HTTP_PROXY:
    proxies["http"] = HTTP_PROXY
if HTTPS_PROXY:
    proxies["https"] = HTTPS_PROXY

# NO_PROXYã®å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def should_use_proxy(url):
    """URLãŒãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not proxies:
        return False

    no_proxy_hosts = [host.strip() for host in NO_PROXY.split(",")]
    for host in no_proxy_hosts:
        if host in url:
            return False
    return True

# --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– ---
def init_session_state():
    defaults = {
        "logs": ["ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¸ã‚ˆã†ã“ãï¼"],
        "progress_df": pd.DataFrame(columns=["epoch", "step", "loss"]).astype({"epoch": int, "step": int, "loss": float}),
        "validation_df": pd.DataFrame(columns=["epoch", "val_loss"]).astype({"epoch": int, "val_loss": float}),
        "lr_df": pd.DataFrame(columns=["step", "learning_rate"]).astype({"step": int, "learning_rate": float}),
        "is_training": False,
        "available_models": [],
        "available_datasets": [],
        "current_progress": 0,
        "progress_text": "å¾…æ©Ÿä¸­",
        "current_epoch": 0,
        "current_step": 0,
        "total_epochs": 0,
        "total_steps": 0,
        "last_progress_update": 0,
        "initial_load": False,
        "last_rerun_time": 0,
        "consecutive_errors": 0,
        "max_consecutive_errors": 3
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- æ¨è«–APIå‘¼ã³å‡ºã— ---
def run_inference(file_bytes: bytes, filename: str, model_name: str) -> Dict[str, Any]:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã€çµæœã¨3ç¨®é¡ã®æ™‚é–“(ms)ã‚’è¿”ã™"""
    try:
        import time
        st.session_state.logs.append(f"ğŸ§ª æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/inference")
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        files = {
            "file": (filename, file_bytes, "application/octet-stream"),
        }
        params = {"model_name": model_name} if model_name else None
        start_time = time.perf_counter()
        response = requests.post(
            f"{BACKEND_URL}/inference",
            files=files,
            params=params,
            timeout=120,
            proxies=request_proxies,
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000.0
        response.raise_for_status()
        data = response.json()
        transcription = data.get("transcription", "")

        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰3ç¨®é¡ã®æ™‚é–“ã‚’å–å¾—
        first_token_time_ms = data.get("first_token_time_ms")
        inference_time_ms = data.get("inference_time_ms")
        total_time_ms = data.get("total_time_ms")

        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒæ™‚é–“ã‚’è¿”ã—ã¦ã„ãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if first_token_time_ms is None:
            first_token_time_ms = elapsed_ms * 0.1  # ä»®ã®å€¤
        if inference_time_ms is None:
            inference_time_ms = elapsed_ms * 0.8  # ä»®ã®å€¤
        if total_time_ms is None:
            total_time_ms = elapsed_ms

        st.session_state.logs.append(f"âœ… æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸ")
        st.session_state.logs.append(f"   ğŸ“Š æ™‚é–“è¨ˆæ¸¬çµæœ:")
        st.session_state.logs.append(f"   - æœ€åˆã®å‡ºåŠ›ã¾ã§: {first_token_time_ms:.0f} ms")
        st.session_state.logs.append(f"   - æ¨è«–æ™‚é–“: {inference_time_ms:.0f} ms")
        st.session_state.logs.append(f"   - ç·æ™‚é–“: {total_time_ms:.0f} ms")

        return {
            "transcription": transcription,
            "first_token_time_ms": first_token_time_ms,
            "inference_time_ms": inference_time_ms,
            "total_time_ms": total_time_ms
        }
    except requests.exceptions.RequestException as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e, getattr(e, "response", None))
        return {"transcription": "", "first_token_time_ms": None, "inference_time_ms": None, "total_time_ms": None}
    except Exception as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e)
        return {"transcription": "", "first_token_time_ms": None, "inference_time_ms": None, "total_time_ms": None}

# --- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°é–¢æ•° ---
def log_detailed_error(operation: str, error: Exception, response=None):
    """è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    error_msg = f"âŒ {operation} ã‚¨ãƒ©ãƒ¼:"

    # åŸºæœ¬ã‚¨ãƒ©ãƒ¼æƒ…å ±
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(error).__name__}"
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(error)}"

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æƒ…å ±ãŒã‚ã‚‹å ´åˆ
    if response is not None:
        error_msg += f"\n   - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}"
        error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {dict(response.headers)}"
        try:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: {response.text}"
        except:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: èª­ã¿å–ã‚Šä¸å¯"

    # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è©³ç´°
    if isinstance(error, requests.exceptions.ConnectionError):
        error_msg += f"\n   - æ¥ç¶šå…ˆ: {BACKEND_URL}"
        error_msg += f"\n   - æ¥ç¶šã‚¨ãƒ©ãƒ¼è©³ç´°: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“"
        error_msg += f"\n   - ç¢ºèªäº‹é …:"
        error_msg += f"\n     * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * Dockerã‚³ãƒ³ãƒ†ãƒŠãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šãŒæ­£ã—ã„ã‹"
    elif isinstance(error, requests.exceptions.Timeout):
        error_msg += f"\n   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè©³ç´°: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
    elif isinstance(error, requests.exceptions.HTTPError):
        error_msg += f"\n   - HTTPã‚¨ãƒ©ãƒ¼è©³ç´°: HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼"

    # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆé–‹ç™ºç”¨ï¼‰
    error_msg += f"\n   - ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}"

    st.session_state.logs.append(error_msg)

# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIé€šä¿¡ ---
def get_config():
    """è¨­å®šæƒ…å ±ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” è¨­å®šæƒ…å ±ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/config")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/config", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            config = response.json()
            st.session_state.available_models = config.get("available_models", [])
            st.session_state.available_datasets = config.get("available_datasets", [])
            st.session_state.logs.append("âœ… è¨­å®šæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        else:
            log_detailed_error("è¨­å®šå–å¾—", Exception(f"HTTP {response.status_code}"), response)

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.Timeout as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.RequestException as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except Exception as e:
        log_detailed_error("è¨­å®šå–å¾—", e)

def get_status():
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/status")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/status", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            status = response.json()
            st.session_state.is_training = status.get("is_training", False)
            st.session_state.logs.append("âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸ")
            # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.consecutive_errors = 0
        else:
            log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", Exception(f"HTTP {response.status_code}"), response)
            st.session_state.consecutive_errors += 1

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.Timeout as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.RequestException as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except Exception as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1

def start_training(model_name: str, dataset_name: str, epochs: int, batch_size: int, lightweight: bool = False, limit_samples: int = 0, resume_from_checkpoint: bool = True, specific_checkpoint: str = None):
    """å­¦ç¿’ã‚’é–‹å§‹"""
    try:
        params = {
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": epochs,
            "batch_size": batch_size,
            "resume_from_checkpoint": resume_from_checkpoint
        }
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰/ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™ã®ä»˜ä¸
        if lightweight:
            params["lightweight"] = True
        if isinstance(limit_samples, int) and limit_samples > 0:
            params["limit_samples"] = int(limit_samples)
        if specific_checkpoint:
            params["specific_checkpoint"] = specific_checkpoint

        st.session_state.logs.append(f"ğŸš€ å­¦ç¿’é–‹å§‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/start")
        if resume_from_checkpoint:
            if specific_checkpoint:
                st.session_state.logs.append(f"ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: {specific_checkpoint}")
            else:
                st.session_state.logs.append("ğŸ“‚ æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹")
        else:
            st.session_state.logs.append("ğŸ†• æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/start", json=params, timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = True
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ä¿å­˜
            if resume_from_checkpoint:
                if specific_checkpoint:
                    st.session_state.resume_info = f"Epoch {specific_checkpoint.split('-epoch-')[1].replace('.pt', '')}"
                else:
                    st.session_state.resume_info = "æœ€æ–°"
            else:
                st.session_state.resume_info = "æ–°è¦"
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’é–‹å§‹", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False

def resume_training(model_name: str, dataset_name: str, epochs: int, batch_size: int, specific_checkpoint: str = None, lightweight: bool = False, limit_samples: int = 0):
    """å­¦ç¿’ã‚’å†é–‹"""
    try:
        params = {
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": epochs,
            "batch_size": batch_size
        }
        if specific_checkpoint:
            params["specific_checkpoint"] = specific_checkpoint
        if lightweight:
            params["lightweight"] = True
        if isinstance(limit_samples, int) and limit_samples > 0:
            params["limit_samples"] = int(limit_samples)

        st.session_state.logs.append(f"ğŸ”„ å­¦ç¿’å†é–‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/resume")
        if specific_checkpoint:
            st.session_state.logs.append(f"ğŸ“‚ æŒ‡å®šã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: {specific_checkpoint}")
        else:
            st.session_state.logs.append("ğŸ“‚ æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/resume", json=params, timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = True
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ä¿å­˜
            if specific_checkpoint:
                st.session_state.resume_info = f"Epoch {specific_checkpoint.split('-epoch-')[1].replace('.pt', '')}"
            else:
                st.session_state.resume_info = "æœ€æ–°"
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’å†é–‹ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’å†é–‹", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False

def stop_training():
    """å­¦ç¿’ã‚’åœæ­¢"""
    try:
        st.session_state.logs.append(f"ğŸ›‘ å­¦ç¿’åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/stop")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/stop", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = False
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
            if "resume_info" in st.session_state:
                del st.session_state.resume_info
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’åœæ­¢", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False

def get_datasets():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/datasets", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            return response.json().get("datasets", [])
        else:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {response.status_code}")
            return []
    except requests.exceptions.ConnectionError:
        st.error("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []
    except requests.exceptions.Timeout:
        st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        return []
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def download_dataset(dataset_name: str):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        st.session_state.logs.append(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {dataset_name}")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/dataset/download", json={"dataset_name": dataset_name}, timeout=300, proxies=request_proxies)

        if response.status_code == 200:
            result = response.json()
            st.session_state.logs.append(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")

            # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°ã«è¿½åŠ 
            if "stdout" in result and result["stdout"]:
                st.session_state.logs.append(f"ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©³ç´°:\n{result['stdout']}")
            if "stderr" in result and result["stderr"]:
                st.session_state.logs.append(f"âš ï¸ è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{result['stderr']}")

            return True
        else:
            # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
            try:
                error_detail = response.json()
                if "detail" in error_detail:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{error_detail['detail']}")
                else:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {response.text}")
            except:
                st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")

            log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except Exception as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False

# --- é€²æ—å–å¾—é–¢æ•° ---
def get_training_progress():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰å­¦ç¿’é€²æ—ã‚’å–å¾—"""
    try:
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/progress", timeout=5, proxies=request_proxies)

        if response.status_code == 200:
            progress_data = response.json()
            return progress_data
        elif response.status_code == 404:
            # 404ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§
            st.session_state.logs.append(f"âš ï¸ é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {response.status_code}")
            return None
        else:
            st.session_state.logs.append(f"âš ï¸ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
            return None
    except requests.exceptions.ConnectionError as e:
        # ä¸€æ™‚çš„ãªæ¥ç¶šã‚¨ãƒ©ãƒ¼ã§ã¯å­¦ç¿’çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„
        st.session_state.logs.append(f"âŒ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except requests.exceptions.Timeout as e:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ãŒã€å­¦ç¿’çŠ¶æ…‹ã¯ç¶­æŒ
        st.session_state.logs.append(f"â° é€²æ—å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")
        return None
    except Exception as e:
        st.session_state.logs.append(f"âŒ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_progress_from_backend():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€²æ—ã‚’å–å¾—ã—ã¦æ›´æ–°"""
    # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯é€²æ—æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if st.session_state.consecutive_errors >= st.session_state.max_consecutive_errors:
        st.session_state.logs.append("âš ï¸ é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹ãŸã‚ã€é€²æ—æ›´æ–°ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã™")
        return False

    progress_data = get_training_progress()
    # ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
    import time
    st.session_state["last_poll_at"] = time.time()
    if progress_data:
        # é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        if "current_epoch" in progress_data and "current_step" in progress_data:
            st.session_state.current_epoch = progress_data.get("current_epoch", 0)
            st.session_state.current_step = progress_data.get("current_step", 0)
            st.session_state.total_epochs = progress_data.get("total_epochs", 0)
            st.session_state.total_steps = progress_data.get("total_steps", 0)
            st.session_state.current_progress = progress_data.get("progress", 0)
            st.session_state.progress_text = f"Epoch {progress_data['current_epoch']}/{progress_data.get('total_epochs', '?')}, Step {progress_data['current_step']}/{progress_data.get('total_steps', '?')}"

        # ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_loss" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.progress_df.empty:
                last_step = st.session_state.progress_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                        "epoch": progress_data.get("current_epoch", 0),
                        "step": current_step,
                        "loss": progress_data["current_loss"]
                    }
            else:
                st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                    "epoch": progress_data.get("current_epoch", 0),
                    "step": current_step,
                    "loss": progress_data["current_loss"]
                }

        # å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_learning_rate" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.lr_df.empty:
                last_step = st.session_state.lr_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                        "step": current_step,
                        "learning_rate": progress_data["current_learning_rate"]
                    }
            else:
                st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                    "step": current_step,
                    "learning_rate": progress_data["current_learning_rate"]
                }

        # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
        if "latest_logs" in progress_data:
            for log in progress_data["latest_logs"]:
                if log not in st.session_state.logs:
                    st.session_state.logs.append(log)

        # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.consecutive_errors = 0
        return True
    else:
        st.session_state.consecutive_errors += 1
        return False

# --- ãƒ¢ãƒ‡ãƒ«ç®¡ç†æ©Ÿèƒ½ ---
def get_checkpoints(model_name: str = None, dataset_name: str = None):
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—"""
    try:
        params = {}
        if model_name:
            params["model_name"] = model_name
        if dataset_name:
            params["dataset_name"] = dataset_name

        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/checkpoints", params=params, timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            return response.json().get("checkpoints", [])
        else:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {response.status_code}")
            return []
    except requests.exceptions.ConnectionError:
        st.error("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []
    except requests.exceptions.Timeout:
        st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        return []
    except Exception as e:
        st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def get_models():
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/models", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            return response.json().get("models", [])
        else:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {response.status_code}")
            return []
    except requests.exceptions.ConnectionError:
        st.error("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []
    except requests.exceptions.Timeout:
        st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        return []
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def delete_model(model_name):
    """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.delete(f"{BACKEND_URL}/models/{model_name}", timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            return True, "ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚"
        else:
            error_detail = response.json().get("detail", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return False, f"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_detail}"
    except requests.exceptions.ConnectionError:
        return False, "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚"
    except requests.exceptions.Timeout:
        return False, "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def delete_models_bulk(model_names):
    """æŒ‡å®šã•ã‚ŒãŸè¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬å‰Šé™¤"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.delete(f"{BACKEND_URL}/models", json=model_names, timeout=60, proxies=request_proxies)

        if response.status_code == 200:
            result = response.json()
            deleted_count = len(result.get("deleted", []))
            failed_count = len(result.get("failed", []))
            if failed_count == 0:
                return True, f"{deleted_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚"
            else:
                return True, f"{deleted_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚{failed_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
        else:
            error_detail = response.json().get("detail", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return False, f"ä¸€æ‹¬å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_detail}"
    except requests.exceptions.ConnectionError:
        return False, "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚"
    except requests.exceptions.Timeout:
        return False, "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"ä¸€æ‹¬å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def download_models_bulk(model_names):
    """æŒ‡å®šã•ã‚ŒãŸè¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åã‚’é€ä¿¡ï¼ˆFastAPIã®List[str]å½¢å¼ï¼‰
        params = {"model_names": model_names}
        response = requests.get(f"{BACKEND_URL}/models/bulk-download", params=params, timeout=300, proxies=request_proxies, stream=True)

        if response.status_code == 200:
            return True, response
        else:
            error_detail = response.json().get("detail", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return False, f"ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_detail}"
    except requests.exceptions.ConnectionError:
        return False, "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚"
    except requests.exceptions.Timeout:
        return False, "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def format_file_size(size_mb):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’é©åˆ‡ãªå˜ä½ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if size_mb < 1:
        return f"{size_mb * 1024:.1f} KB"
    elif size_mb < 1024:
        return f"{size_mb:.1f} MB"
    else:
        return f"{size_mb / 1024:.1f} GB"

def format_timestamp(timestamp):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")

# --- UIæç”» ---
st.set_page_config(
    page_title="ASRå­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ©Ÿèƒ½ãƒãƒªã‚·ãƒ¼ã®è­¦å‘Šã‚’æŠ‘åˆ¶ã™ã‚‹ãŸã‚ã®HTML
st.markdown("""
<meta http-equiv="Permissions-Policy" content="accelerometer=(), ambient-light-sensor=(), autoplay=(), battery=(), clipboard-write=(), document-domain=(), encrypted-media=(), gyroscope=(), layout-animations=(), legacy-image-formats=(), magnetometer=(), midi=(), oversized-images=(), payment=(), picture-in-picture=(), sync-xhr=(), usb=(), vr=(), wake-lock=(), xr-spatial-tracking=()">
<meta http-equiv="Feature-Policy" content="accelerometer 'none'; ambient-light-sensor 'none'; autoplay 'none'; battery 'none'; clipboard-write 'none'; document-domain 'none'; encrypted-media 'none'; gyroscope 'none'; layout-animations 'none'; legacy-image-formats 'none'; magnetometer 'none'; midi 'none'; oversized-images 'none'; payment 'none'; picture-in-picture 'none'; sync-xhr 'none'; usb 'none'; vr 'none'; wake-lock 'none'; xr-spatial-tracking 'none'">
""", unsafe_allow_html=True)
init_session_state()

if not st.session_state.initial_load:
    # åˆæœŸåŒ–æ™‚ã¯è¨­å®šã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
    get_config()
    get_status()
    st.session_state.initial_load = True
elif st.session_state.is_training:
    # å­¦ç¿’ä¸­ã®å ´åˆã®ã¿ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å†ç¢ºèªï¼ˆãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã®çŠ¶æ…‹å¾©å…ƒï¼‰
    import time
    current_time = time.time()
    if "last_status_check" not in st.session_state:
        st.session_state.last_status_check = 0

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã®é »åº¦ã‚’åˆ¶é™ï¼ˆ30ç§’ã”ã¨ï¼‰
    if current_time - st.session_state.last_status_check >= 30:
        get_status()
        st.session_state.last_status_check = current_time

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ASR å­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
st.markdown("---")
col_nav1, col_nav2, col_nav3, col_nav4 = st.columns(4)
with col_nav1:
    if st.button("ğŸ  ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", use_container_width=True, key="nav_main_top"):
        st.session_state.current_page = "main"
        st.rerun()
with col_nav2:
    if st.button("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç®¡ç†", use_container_width=True, key="nav_model_top"):
        st.session_state.current_page = "model_management"
        st.rerun()
with col_nav3:
    if st.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†", use_container_width=True, key="nav_dataset_top"):
        st.session_state.current_page = "dataset_management"
        st.rerun()
with col_nav4:
    if st.button("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–", use_container_width=True, key="nav_realtime_top"):
        st.session_state.current_page = "realtime"
        st.rerun()

# ç¾åœ¨ã®ãƒšãƒ¼ã‚¸è¡¨ç¤º
current_page = st.session_state.get("current_page", "main")
if current_page == "main":
    page_name = "ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
elif current_page == "model_management":
    page_name = "ãƒ¢ãƒ‡ãƒ«ç®¡ç†"
elif current_page == "checkpoint_management":
    page_name = "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†"
elif current_page == "dataset_management":
    page_name = "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†"
elif current_page == "realtime":
    page_name = "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–"
else:
    page_name = "ä¸æ˜"
st.markdown(f"### ğŸ“Š ç¾åœ¨ã®ãƒšãƒ¼ã‚¸: {page_name}")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - å­¦ç¿’åˆ¶å¾¡
with st.sidebar:
    st.header("ğŸ“‹ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")

    # ãƒšãƒ¼ã‚¸é–“ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    current_page = st.session_state.get("current_page", "main")
    if st.button("ğŸ  ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", use_container_width=True, disabled=(current_page == "main"), key="nav_main_sidebar"):
        st.session_state.current_page = "main"
        st.rerun()
    if st.button("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç®¡ç†", use_container_width=True, disabled=(current_page == "model_management"), key="nav_model_sidebar"):
        st.session_state.current_page = "model_management"
        st.rerun()
    if st.button("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†", use_container_width=True, disabled=(current_page == "checkpoint_management"), key="nav_checkpoint_sidebar"):
        st.session_state.current_page = "checkpoint_management"
        st.rerun()
    if st.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†", use_container_width=True, disabled=(current_page == "dataset_management"), key="nav_dataset_sidebar"):
        st.session_state.current_page = "dataset_management"
        st.rerun()
    if st.button("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–", use_container_width=True, disabled=(current_page == "realtime"), key="nav_realtime_sidebar"):
        st.session_state.current_page = "realtime"
        st.rerun()

    st.markdown("---")
    st.header("ğŸ¯ å­¦ç¿’åˆ¶å¾¡")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    dataset_name = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
        st.session_state.available_datasets,
        index=0 if st.session_state.available_datasets else None
    )

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if st.button("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", disabled=st.session_state.is_training):
        if dataset_name:
            with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                success = download_dataset(dataset_name)
                if success:
                    st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    # è¨­å®šã‚’å†å–å¾—ã—ã¦æœ€æ–°ã®çŠ¶æ…‹ã‚’åæ˜ 
                    get_config()
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    # å­¦ç¿’ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    training_model_name = st.selectbox(
        "å­¦ç¿’ç”¨ãƒ¢ãƒ‡ãƒ«",
        st.session_state.available_models,
        index=0 if st.session_state.available_models else None,
        key="training_model_selector"
    )

    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epochs = st.number_input("ã‚¨ãƒãƒƒã‚¯æ•°", min_value=1, value=10)
    batch_size = st.number_input("ãƒãƒƒãƒã‚µã‚¤ã‚º", min_value=1, value=4)
    lightweight = st.checkbox("è»½é‡(å…ˆé ­10ä»¶)ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", value=True)
    limit_samples = st.number_input("ä½¿ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ (0ã§ç„¡åŠ¹)", min_value=0, value=0)

    # å­¦ç¿’å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ”„ å­¦ç¿’å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    resume_from_checkpoint = st.checkbox("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹", value=True, help="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã€è‡ªå‹•çš„ã«å†é–‹ã—ã¾ã™")

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠ
    specific_checkpoint = None
    if resume_from_checkpoint and training_model_name and dataset_name:
        checkpoints = get_checkpoints(training_model_name, dataset_name)
        if checkpoints:
            checkpoint_options = ["æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹"] + [f"{cp['name']} (Epoch {cp['epoch']})" for cp in checkpoints]
            selected_checkpoint = st.selectbox(
                "å†é–‹ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ",
                checkpoint_options,
                help="ç‰¹å®šã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„"
            )
            if selected_checkpoint != "æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹":
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆåã‚’æŠ½å‡º
                for cp in checkpoints:
                    if f"{cp['name']} (Epoch {cp['epoch']})" == selected_checkpoint:
                        specific_checkpoint = cp['name']
                        break
        else:
            st.info("åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

    # å­¦ç¿’åˆ¶å¾¡ãƒœã‚¿ãƒ³
    st.subheader("ğŸ® å­¦ç¿’åˆ¶å¾¡")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ†• æ–°è¦å­¦ç¿’é–‹å§‹", disabled=st.session_state.is_training, help="æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™"):
            if training_model_name and dataset_name:
                success = start_training(training_model_name, dataset_name, epochs, batch_size,
                                       lightweight=lightweight, limit_samples=limit_samples,
                                       resume_from_checkpoint=False)
                if not success:
                    st.error("å­¦ç¿’ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    with col2:
        if st.button("ğŸ”„ å­¦ç¿’å†é–‹", disabled=st.session_state.is_training, help="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã‚’å†é–‹ã—ã¾ã™"):
            if training_model_name and dataset_name:
                if resume_from_checkpoint:
                    success = resume_training(training_model_name, dataset_name, epochs, batch_size,
                                            specific_checkpoint=specific_checkpoint,
                                            lightweight=lightweight, limit_samples=limit_samples)
                else:
                    success = start_training(training_model_name, dataset_name, epochs, batch_size,
                                           lightweight=lightweight, limit_samples=limit_samples,
                                           resume_from_checkpoint=True, specific_checkpoint=specific_checkpoint)
                if not success:
                    st.error("å­¦ç¿’ã®å†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    with col3:
        if st.button("ğŸ›‘ å­¦ç¿’åœæ­¢", disabled=not st.session_state.is_training, help="ç¾åœ¨ã®å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã™"):
            stop_training()

    # é€²æ—è¡¨ç¤º
    if st.session_state.is_training:
        st.progress(st.session_state.current_progress)
        st.text(st.session_state.progress_text)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
current_page = st.session_state.get("current_page", "main")
if current_page == "main":
    col1, col2 = st.columns(2)

    # æ¨è«–ãƒ†ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰")

    # æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ“‹ æ¨è«–è¨­å®š")
    col_model_select, col_model_info = st.columns([1, 2])

    with col_model_select:
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        available_models = st.session_state.available_models
        if available_models:
            selected_inference_model = st.selectbox(
                "æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«:",
                available_models,
                index=0,
                key="inference_model_selector",
                help="æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        else:
            st.warning("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            selected_inference_model = None

    with col_model_info:
        if selected_inference_model:
            st.info(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{selected_inference_model}**")
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«–å®Ÿè¡Œ
    st.subheader("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    inf_col1, inf_col2 = st.columns([2, 1])

    with inf_col1:
        uploaded = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (WAV/FLAC/MP3/M4A/OGG)",
            type=["wav", "flac", "mp3", "m4a", "ogg"],
            key="inference_file_uploader",
            help="æ¨è«–å¯¾è±¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        if uploaded is not None:
            st.audio(uploaded, format="audio/wav")
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {uploaded.name}")

    with inf_col2:
        st.subheader("ğŸš€ æ¨è«–å®Ÿè¡Œ")
        inference_disabled = uploaded is None or selected_inference_model is None
        if st.button(
            "æ¨è«–ã‚’å®Ÿè¡Œ",
            disabled=inference_disabled,
            type="primary",
            key="inference_execute_button",
            use_container_width=True
        ):
            if uploaded is None:
                st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            elif selected_inference_model is None:
                st.warning("æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else:
                with st.spinner("æ¨è«–ã‚’å®Ÿè¡Œä¸­..."):
                    result = run_inference(uploaded.getvalue(), uploaded.name, selected_inference_model)
                    transcription = result.get("transcription", "")
                    first_token_ms = result.get("first_token_time_ms")
                    inference_ms = result.get("inference_time_ms")
                    total_ms = result.get("total_time_ms")

                    # æ¨è«–ãŒå®Œäº†ã—ãŸå ´åˆï¼ˆç©ºã®çµæœã‚‚å«ã‚€ï¼‰
                    st.success("æ¨è«–å®Œäº†")

                    # ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                    st.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: **{selected_inference_model}**")

                    # 3ç¨®é¡ã®æ™‚é–“ã‚’è¡¨ç¤º
                    st.subheader("â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±")
                    col_time1, col_time2, col_time3 = st.columns(3)
                    with col_time1:
                        if first_token_ms is not None:
                            st.metric(label="æœ€åˆã®å‡ºåŠ›ã¾ã§", value=f"{first_token_ms:.0f} ms")
                    with col_time2:
                        if inference_ms is not None:
                            st.metric(label="æ¨è«–æ™‚é–“", value=f"{inference_ms:.0f} ms")
                    with col_time3:
                        if total_ms is not None:
                            st.metric(label="ç·æ™‚é–“", value=f"{total_ms:.0f} ms")

                    # æ–‡å­—èµ·ã“ã—çµæœ
                    st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
                    if transcription:
                        # æ­£å¸¸ãªæ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚‹å ´åˆ
                        st.text_area(
                            "æ–‡å­—èµ·ã“ã—çµæœ",
                            value=transcription,
                            height=120,
                            key="inference_result_text",
                            help="éŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™"
                        )

                        # çµæœã®ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³
                        if st.button("ğŸ“‹ çµæœã‚’ã‚³ãƒ”ãƒ¼", key="copy_result_button"):
                            st.write("çµæœã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼ˆæ‰‹å‹•ã§ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ï¼‰")
                    else:
                        # ç©ºã®æ¨è«–çµæœã®å ´åˆ
                        st.warning("âš ï¸ æ¨è«–çµæœãŒç©ºã§ã™")
                        st.text_area(
                            "æ–‡å­—èµ·ã“ã—çµæœ",
                            value="ï¼ˆéŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ï¼‰",
                            height=120,
                            key="inference_result_text_empty",
                            help="éŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°ã®å“è³ªã‚„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                        )
                        st.info("ğŸ’¡ **æ¨å¥¨äº‹é …**: éŸ³å£°ã®å“è³ªã‚’ç¢ºèªã™ã‚‹ã‹ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")

    # ä¸Šéƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆå­¦ç¿’ä¸­ã®ã¿ï¼‰
    if st.session_state.is_training:
        m1, m2, m3 = st.columns(3)
        with m1:
            st.metric(label="Epoch", value=f"{st.session_state.current_epoch}/{st.session_state.total_epochs}")
        with m2:
            st.metric(label="Step", value=f"{st.session_state.current_step}/{st.session_state.total_steps}")
        with m3:
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’è¡¨ç¤º
            if "resume_info" in st.session_state:
                st.metric(label="å†é–‹å…ƒ", value=st.session_state.resume_info)
            else:
                st.metric(label="å­¦ç¿’çŠ¶æ…‹", value="å®Ÿè¡Œä¸­")

    with col1:
        st.header("å­¦ç¿’ãƒ­ã‚¹")
        if not st.session_state.progress_df.empty:
            loss_data = st.session_state.progress_df.rename(columns={"loss": "train_loss"})
            if not st.session_state.validation_df.empty:
                # ã‚¨ãƒãƒƒã‚¯ã®æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã«æ¤œè¨¼ãƒ­ã‚¹ã‚’ç´ä»˜ã‘ã‚‹
                last_step_per_epoch = loss_data.groupby("epoch")["step"].max().reset_index()
                merged_val = pd.merge(st.session_state.validation_df, last_step_per_epoch, on="epoch")
                loss_data = pd.merge(loss_data, merged_val, on=["epoch", "step"], how="left")

            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’æç”»å¯¾è±¡ã«ã™ã‚‹
            plot_cols = [c for c in ["train_loss", "val_loss"] if c in loss_data.columns]
            st.line_chart(loss_data.set_index("step")[plot_cols])
        else:
            st.info("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    with col2:
        st.header("å­¦ç¿’ç‡")
        if not st.session_state.lr_df.empty:
            st.line_chart(st.session_state.lr_df.set_index("step")["learning_rate"])
        else:
            st.info("å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    # ãƒ­ã‚°è¡¨ç¤º
    st.header("ãƒ­ã‚°")
    log_container = st.container()
    with log_container:
        for log in st.session_state.logs[-50:]:  # æœ€æ–°50ä»¶ã‚’è¡¨ç¤º
            st.text(log)

# å­¦ç¿’ä¸­ã®é€²æ—æ›´æ–°
if st.session_state.is_training:
    # ç›´è¿‘ã®ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°/å¯è¦–åŒ–ï¼‰
    import time
    last_polled = st.session_state.get("last_poll_at")
    if last_polled:
        st.caption(f"æœ€çµ‚ãƒãƒ¼ãƒªãƒ³ã‚°: {time.strftime('%H:%M:%S', time.localtime(last_polled))}")
    # é€²æ—æ›´æ–°ã®é »åº¦ã‚’åˆ¶é™ï¼ˆ1ç§’ã”ã¨ï¼‰
    import time
    current_time = time.time()
    if "last_progress_update" not in st.session_state:
        st.session_state.last_progress_update = 0

    # é€²æ—æ›´æ–°ã®å®Ÿè¡Œ
    progress_updated = False
    if current_time - st.session_state.last_progress_update >= 1:
        progress_updated = update_progress_from_backend()
        st.session_state.last_progress_update = current_time

    # ç¢ºå®Ÿãª1ç§’ã”ã¨ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¹ãƒªãƒ¼ãƒ—â†’å†å®Ÿè¡Œï¼‰
    time.sleep(1)
    st.rerun()

# --- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
current_page = st.session_state.get("current_page", "main")
if current_page == "checkpoint_management":
    st.markdown("---")
    st.header("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†")

    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€å­¦ç¿’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¸€è¦§è¡¨ç¤ºã¨ç®¡ç†ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    """)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    col_filter1, col_filter2 = st.columns(2)

    with col_filter1:
        filter_model = st.selectbox(
            "ãƒ¢ãƒ‡ãƒ«åã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["å…¨ã¦"] + st.session_state.available_models,
            key="checkpoint_filter_model"
        )

    with col_filter2:
        filter_dataset = st.selectbox(
            "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["å…¨ã¦"] + st.session_state.available_datasets,
            key="checkpoint_filter_dataset"
        )

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—
    with st.spinner("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—ä¸­..."):
        try:
            checkpoints = get_checkpoints(
                model_name=filter_model if filter_model != "å…¨ã¦" else None,
                dataset_name=filter_dataset if filter_dataset != "å…¨ã¦" else None
            )
        except Exception as e:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            checkpoints = []

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®è¡¨ç¤º
    if checkpoints:
        st.subheader(f"ğŸ“‹ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ ({len(checkpoints)}ä»¶)")
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        checkpoint_data = []
        for cp in checkpoints:
            checkpoint_data.append({
                "åå‰": cp["name"],
                "ãƒ¢ãƒ‡ãƒ«": cp["model_name"],
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": cp["dataset_name"],
                "ã‚¨ãƒãƒƒã‚¯": cp["epoch"],
                "ã‚µã‚¤ã‚º": f"{cp['size_mb']:.1f} MB",
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": cp["file_count"],
                "ä½œæˆæ—¥æ™‚": format_timestamp(cp["created_at"])
            })
        
        df = pd.DataFrame(checkpoint_data)
        st.dataframe(df, use_container_width=True)
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°è¡¨ç¤º
        if checkpoints:
            st.subheader("ğŸ” ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè©³ç´°")
            selected_checkpoint = st.selectbox(
                "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ",
                [cp["name"] for cp in checkpoints],
                key="checkpoint_detail_selector"
            )
            
            if selected_checkpoint:
                selected_cp = next(cp for cp in checkpoints if cp["name"] == selected_checkpoint)
                
                col_detail1, col_detail2 = st.columns(2)
                
                with col_detail1:
                    st.write("**åŸºæœ¬æƒ…å ±:**")
                    st.write(f"- åå‰: {selected_cp['name']}")
                    st.write(f"- ãƒ¢ãƒ‡ãƒ«: {selected_cp['model_name']}")
                    st.write(f"- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {selected_cp['dataset_name']}")
                    st.write(f"- ã‚¨ãƒãƒƒã‚¯: {selected_cp['epoch']}")
                
                with col_detail2:
                    st.write("**ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:**")
                    st.write(f"- ã‚µã‚¤ã‚º: {selected_cp['size_mb']:.1f} MB")
                    st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {selected_cp['file_count']}")
                    st.write(f"- ä½œæˆæ—¥æ™‚: {format_timestamp(selected_cp['created_at'])}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
                if selected_cp.get("files"):
                    st.write("**ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:**")
                    for file in selected_cp["files"]:
                        st.write(f"- {file}")
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ“ä½œ
                st.subheader("âš™ï¸ æ“ä½œ")
                col_action1, col_action2 = st.columns(2)
                
                with col_action1:
                    if st.button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"download_{selected_checkpoint}"):
                        st.info("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
                
                with col_action2:
                    if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"delete_{selected_checkpoint}"):
                        if st.session_state.get(f"confirm_delete_{selected_checkpoint}", False):
                            with st.spinner("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­..."):
                                try:
                                    import shutil
                                    import os
                                    checkpoint_path = selected_cp["path"]
                                    shutil.rmtree(checkpoint_path)
                                    st.success("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                    st.balloons()
                                    time.sleep(1)
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        else:
                            st.session_state[f"confirm_delete_{selected_checkpoint}"] = True
                            st.warning("âš ï¸ å‰Šé™¤ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚‚ã†ä¸€åº¦å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
                            st.rerun()
    else:
        st.info("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè‡ªå‹•çš„ã«ä½œæˆã•ã‚Œã¾ã™ã€‚")

# --- ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
elif current_page == "model_management":
    st.markdown("---")
    st.header("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç®¡ç†")

    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§è¡¨ç¤ºã¨ç®¡ç†ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    """)

    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—
    with st.spinner("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­..."):
        try:
            models = get_models()
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            models = []

    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®è¡¨ç¤º
    if models:
        st.subheader(f"ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ ({len(models)}ä»¶)")
        
        # ä¸€æ‹¬æ“ä½œã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("### ğŸ”§ ä¸€æ‹¬æ“ä½œ")
        
        # é¸æŠçŠ¶æ…‹ã®åˆæœŸåŒ–
        if "selected_models" not in st.session_state:
            st.session_state.selected_models = []
        if "model_selection_df" not in st.session_state:
            st.session_state.model_selection_df = None
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§æº–å‚™ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åˆ—ã‚’å«ã‚€ï¼‰
        model_data = []
        for model in models:
            is_selected = model["name"] in st.session_state.selected_models
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            dataset_stats = ""
            if model.get("training_metadata") and model["training_metadata"].get("dataset_statistics"):
                stats = model["training_metadata"]["dataset_statistics"]
                total_samples = stats.get("total_samples", 0)
                if total_samples > 0:
                    dataset_stats = f"{total_samples:,} samples"
            
            model_data.append({
                "é¸æŠ": is_selected,
                "åå‰": model["name"],
                "ã‚¨ãƒãƒƒã‚¯": model["epoch"] or "ä¸æ˜",
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": model.get("dataset_name") or "ä¸æ˜",
                "ã‚µãƒ³ãƒ—ãƒ«æ•°": dataset_stats or "ä¸æ˜",
                "ã‚µã‚¤ã‚º": f"{model['size_mb']:.1f} MB",
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": model["file_count"],
                "ä½œæˆæ—¥æ™‚": format_timestamp(model["created_at"])
            })
        
        df = pd.DataFrame(model_data)
        
        # å…¨é¸æŠ/å…¨è§£é™¤ãƒœã‚¿ãƒ³
        col_select_all, col_deselect_all, col_bulk_actions = st.columns([1, 1, 2])
        with col_select_all:
            if st.button("âœ… ã™ã¹ã¦é¸æŠ", key="select_all_models"):
                st.session_state.selected_models = [model["name"] for model in models]
                st.rerun()
        with col_deselect_all:
            if st.button("âŒ ã™ã¹ã¦è§£é™¤", key="deselect_all_models"):
                st.session_state.selected_models = []
                st.rerun()
        
        # ç·¨é›†å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã§ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º
        edited_df = st.data_editor(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "é¸æŠ": st.column_config.CheckboxColumn(
                    "é¸æŠ",
                    help="ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
                    default=False,
                ),
                "åå‰": st.column_config.TextColumn(
                    "åå‰",
                    help="ãƒ¢ãƒ‡ãƒ«å",
                ),
                "ã‚¨ãƒãƒƒã‚¯": st.column_config.TextColumn(
                    "ã‚¨ãƒãƒƒã‚¯",
                    help="ã‚¨ãƒãƒƒã‚¯ç•ªå·",
                ),
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": st.column_config.TextColumn(
                    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
                    help="å­¦ç¿’ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
                ),
                "ã‚µãƒ³ãƒ—ãƒ«æ•°": st.column_config.TextColumn(
                    "ã‚µãƒ³ãƒ—ãƒ«æ•°",
                    help="å­¦ç¿’ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°",
                ),
                "ã‚µã‚¤ã‚º": st.column_config.TextColumn(
                    "ã‚µã‚¤ã‚º",
                    help="ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚º",
                ),
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": st.column_config.NumberColumn(
                    "ãƒ•ã‚¡ã‚¤ãƒ«æ•°",
                    help="ãƒ¢ãƒ‡ãƒ«ã«å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°",
                ),
                "ä½œæˆæ—¥æ™‚": st.column_config.TextColumn(
                    "ä½œæˆæ—¥æ™‚",
                    help="ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ—¥æ™‚",
                ),
            },
            disabled=["åå‰", "ã‚¨ãƒãƒƒã‚¯", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "ã‚µãƒ³ãƒ—ãƒ«æ•°", "ã‚µã‚¤ã‚º", "ãƒ•ã‚¡ã‚¤ãƒ«æ•°", "ä½œæˆæ—¥æ™‚"],
            key="model_selection_table"
        )
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®é¸æŠçŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åæ˜ 
        if edited_df is not None:
            selected_models_from_table = edited_df[edited_df["é¸æŠ"] == True]["åå‰"].tolist()
            if set(selected_models_from_table) != set(st.session_state.selected_models):
                st.session_state.selected_models = selected_models_from_table
                st.rerun()
        
        # ä¸€æ‹¬æ“ä½œãƒœã‚¿ãƒ³
        with col_bulk_actions:
            st.write(f"**é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«: {len(st.session_state.selected_models)}ä»¶**")
            
            col_download, col_delete = st.columns(2)
            
            with col_download:
                # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                if st.button("ğŸ“¥ ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", 
                            disabled=len(st.session_state.selected_models) == 0,
                            key="bulk_download_models",
                            use_container_width=True):
                    if st.session_state.selected_models:
                        with st.spinner("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­..."):
                            success, result = download_models_bulk(st.session_state.selected_models)
                            if success and isinstance(result, requests.Response):
                                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—
                                zip_content = result.content
                                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                                from datetime import datetime
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"models_{timestamp}.zip"
                                
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                                st.session_state["bulk_download_zip"] = {
                                    "content": zip_content,
                                    "filename": filename,
                                    "model_count": len(st.session_state.selected_models)
                                }
                                st.success(f"{len(st.session_state.selected_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
                                st.rerun()
                            else:
                                st.error(result)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                if "bulk_download_zip" in st.session_state:
                    zip_data = st.session_state["bulk_download_zip"]
                    st.download_button(
                        label=f"ğŸ“¥ ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({zip_data['filename']})",
                        data=zip_data["content"],
                        file_name=zip_data["filename"],
                        mime="application/zip",
                        key="download_bulk_zip",
                        use_container_width=True
                    )
            
            with col_delete:
                # ä¸€æ‹¬å‰Šé™¤ãƒœã‚¿ãƒ³
                if st.button("ğŸ—‘ï¸ ä¸€æ‹¬å‰Šé™¤", 
                            disabled=len(st.session_state.selected_models) == 0,
                            key="bulk_delete_models",
                            use_container_width=True,
                            type="primary"):
                    if st.session_state.selected_models:
                        # ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°
                        if st.session_state.get(f"confirm_bulk_delete", False):
                            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ä¸­..."):
                                success, message = delete_models_bulk(st.session_state.selected_models)
                                if success:
                                    st.success(message)
                                    st.balloons()
                                    st.session_state.selected_models = []
                                    st.session_state[f"confirm_bulk_delete"] = False
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    st.error(message)
                        else:
                            st.session_state[f"confirm_bulk_delete"] = True
                            st.warning(f"âš ï¸ {len(st.session_state.selected_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã—ã‚ˆã†ã¨ã—ã¦ã„ã¾ã™ã€‚å‰Šé™¤ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚‚ã†ä¸€åº¦å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
                            st.rerun()
        
        st.markdown("---")
        
        # ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°è¡¨ç¤º
        if models:
            st.subheader("ğŸ” ãƒ¢ãƒ‡ãƒ«è©³ç´°")
            selected_model = st.selectbox(
                "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
                [model["name"] for model in models],
                key="model_detail_selector"
            )
            
            if selected_model:
                selected_model_info = next(model for model in models if model["name"] == selected_model)
                
                col_detail1, col_detail2 = st.columns(2)
                
                with col_detail1:
                    st.write("**åŸºæœ¬æƒ…å ±:**")
                    st.write(f"- åå‰: {selected_model_info['name']}")
                    st.write(f"- ã‚¨ãƒãƒƒã‚¯: {selected_model_info['epoch'] or 'ä¸æ˜'}")
                    st.write(f"- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {selected_model_info.get('dataset_name') or 'ä¸æ˜'}")
                    st.write(f"- ã‚µã‚¤ã‚º: {selected_model_info['size_mb']:.1f} MB")
                
                with col_detail2:
                    st.write("**ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:**")
                    st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {selected_model_info['file_count']}")
                    st.write(f"- ä½œæˆæ—¥æ™‚: {format_timestamp(selected_model_info['created_at'])}")
                
                # å­¦ç¿’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
                if selected_model_info.get("training_metadata"):
                    st.markdown("---")
                    st.subheader("ğŸ“Š å­¦ç¿’è©³ç´°æƒ…å ±")
                    metadata = selected_model_info["training_metadata"]
                    
                    col_meta1, col_meta2 = st.columns(2)
                    
                    with col_meta1:
                        st.write("**å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**")
                        if metadata.get("training_params"):
                            params = metadata["training_params"]
                            st.write(f"- ã‚¨ãƒãƒƒã‚¯æ•°: {params.get('epochs', 'ä¸æ˜')}")
                            st.write(f"- ãƒãƒƒãƒã‚µã‚¤ã‚º: {params.get('batch_size', 'ä¸æ˜')}")
                            st.write(f"- å­¦ç¿’ç‡: {params.get('learning_rate', 'ä¸æ˜')}")
                            st.write(f"- ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {params.get('optimizer', 'ä¸æ˜')}")
                            st.write(f"- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©: {params.get('scheduler', 'ãªã—')}")
                            st.write(f"- ãƒ‡ãƒã‚¤ã‚¹: {params.get('device', 'ä¸æ˜')}")
                    
                    with col_meta2:
                        st.write("**å­¦ç¿’æ™‚é–“:**")
                        if selected_model_info.get("training_start_time"):
                            st.write(f"- é–‹å§‹æ™‚åˆ»: {selected_model_info['training_start_time']}")
                        if selected_model_info.get("training_end_time"):
                            st.write(f"- çµ‚äº†æ™‚åˆ»: {selected_model_info['training_end_time']}")
                        if metadata.get("training_status"):
                            st.write(f"- çŠ¶æ…‹: {metadata['training_status']}")
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    if metadata.get("dataset_statistics"):
                        st.markdown("---")
                        st.write("**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆæƒ…å ±:**")
                        stats = metadata["dataset_statistics"]
                        col_stats1, col_stats2 = st.columns(2)
                        with col_stats1:
                            st.write(f"- å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {stats.get('train_samples', 'ä¸æ˜'):,}")
                            st.write(f"- æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«æ•°: {stats.get('validation_samples', 'ä¸æ˜'):,}")
                        with col_stats2:
                            st.write(f"- åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {stats.get('total_samples', 'ä¸æ˜'):,}")
                            train_ratio = stats.get('train_ratio', 0)
                            val_ratio = stats.get('validation_ratio', 0)
                            st.write(f"- å­¦ç¿’/æ¤œè¨¼æ¯”ç‡: {train_ratio:.1%} / {val_ratio:.1%}")
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã®è¡¨ç¤º
                    if metadata.get("dataset_config"):
                        st.markdown("---")
                        with st.expander("**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã‚’è¡¨ç¤º**"):
                            dataset_config = metadata["dataset_config"]
                            st.json(dataset_config)
                    
                    # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®è¡¨ç¤ºï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
                    if metadata.get("model_config"):
                        with st.expander("**ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’è¡¨ç¤º**"):
                            st.json(metadata["model_config"])
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
                if selected_model_info.get("files"):
                    st.markdown("---")
                    st.write("**ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:**")
                    for file in selected_model_info["files"]:
                        st.write(f"- {file}")
                
                # ãƒ¢ãƒ‡ãƒ«ã®æ“ä½œ
                st.subheader("âš™ï¸ æ“ä½œ")
                col_action1, col_action2 = st.columns(2)
                
                with col_action1:
                    if st.button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"download_model_{selected_model}"):
                        st.info("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
                
                with col_action2:
                    if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"delete_model_{selected_model}"):
                        if st.session_state.get(f"confirm_delete_model_{selected_model}", False):
                            with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ä¸­..."):
                                success, message = delete_model(selected_model)

                                if success:
                                    st.success(message)
                                    st.balloons()
                                    # å‰Šé™¤å¾Œã€ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    st.error(message)
                        else:
                            st.session_state[f"confirm_delete_model_{selected_model}"] = True
                            st.warning("âš ï¸ å‰Šé™¤ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚‚ã†ä¸€åº¦å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
                            st.rerun()
    else:
        st.info("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        st.write("å­¦ç¿’ã‚’å®Œäº†ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«ä½œæˆã•ã‚Œã¾ã™ã€‚")

# --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
elif current_page == "dataset_management":
    st.markdown("---")
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†")

    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€è¦§è¡¨ç¤ºã¨ç®¡ç†ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€çŠ¶æ…‹ç¢ºèªã€å‰Šé™¤ãªã©ãŒå¯èƒ½ã§ã™ã€‚
    """)

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã®å–å¾—
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—ä¸­..."):
        try:
            datasets = get_datasets()
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            datasets = []

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã®è¡¨ç¤º
    if datasets:
        st.subheader(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ ({len(datasets)}ä»¶)")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        dataset_data = []
        for dataset in datasets:
            status_icon = "âœ…" if dataset["status"] == "downloaded" else "âŒ"
            status_text = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿" if dataset["status"] == "downloaded" else "æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
            
            dataset_data.append({
                "åå‰": dataset["name"],
                "çŠ¶æ…‹": f"{status_icon} {status_text}",
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": f"{dataset['num_files']:,}" if dataset["num_files"] > 0 else "-",
                "ã‚µã‚¤ã‚º": f"{dataset['size_mb']:.1f} MB" if dataset["size_mb"] > 0 else "-",
                "ãƒ‘ã‚¹": dataset["path"] or "-"
            })
        
        df = pd.DataFrame(dataset_data)
        st.dataframe(df, use_container_width=True)
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°è¡¨ç¤ºã¨æ“ä½œ
        if datasets:
            st.subheader("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°ãƒ»æ“ä½œ")
            selected_dataset = st.selectbox(
                "æ“ä½œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠ",
                [ds["name"] for ds in datasets],
                key="dataset_detail_selector"
            )
            
            if selected_dataset:
                selected_ds = next(ds for ds in datasets if ds["name"] == selected_dataset)
                
                col_detail1, col_detail2 = st.columns(2)
                
                with col_detail1:
                    st.write("**åŸºæœ¬æƒ…å ±:**")
                    st.write(f"- åå‰: {selected_ds['name']}")
                    status_icon = "âœ…" if selected_ds["status"] == "downloaded" else "âŒ"
                    status_text = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿" if selected_ds["status"] == "downloaded" else "æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                    st.write(f"- çŠ¶æ…‹: {status_icon} {status_text}")
                    st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {selected_ds['num_files']:,}" if selected_ds["num_files"] > 0 else "- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: -")
                    st.write(f"- ã‚µã‚¤ã‚º: {selected_ds['size_mb']:.1f} MB" if selected_ds["size_mb"] > 0 else "- ã‚µã‚¤ã‚º: -")
                
                with col_detail2:
                    st.write("**ãƒ‘ã‚¹æƒ…å ±:**")
                    st.write(f"- ãƒ‘ã‚¹: {selected_ds['path'] or 'æœªè¨­å®š'}")
                    if selected_ds.get("config"):
                        config = selected_ds["config"]
                        st.write(f"- ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {config.get('sample_rate', 'ä¸æ˜')}")
                        st.write(f"- æ¤œè¨¼ã‚»ãƒƒãƒˆå‰²åˆ: {config.get('validation_size', 0.05) * 100:.1f}%")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã®è¡¨ç¤º
                if selected_ds.get("config"):
                    st.markdown("---")
                    with st.expander("**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã‚’è¡¨ç¤º**"):
                        st.json(selected_ds["config"])
                
                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ“ä½œ
                st.markdown("---")
                st.subheader("âš™ï¸ æ“ä½œ")
                col_action1, col_action2 = st.columns(2)
                
                with col_action1:
                    if st.button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"download_{selected_dataset}", use_container_width=True):
                        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                            success = download_dataset(selected_dataset)
                            if success:
                                st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                                st.balloons()
                                # ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦æœ€æ–°ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
                                import time
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
                with col_action2:
                    if selected_ds["status"] == "downloaded":
                        if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"delete_{selected_dataset}", use_container_width=True, type="primary"):
                            if st.session_state.get(f"confirm_delete_dataset_{selected_dataset}", False):
                                with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã‚’å‰Šé™¤ä¸­..."):
                                    try:
                                        import shutil
                                        if selected_ds["path"] and os.path.exists(selected_ds["path"]):
                                            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆä¾‹: /app/data/ljspeech å…¨ä½“ï¼‰
                                            parent_dir = os.path.dirname(selected_ds["path"])
                                            if os.path.exists(parent_dir):
                                                shutil.rmtree(parent_dir)
                                                st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                                st.balloons()
                                                import time
                                                time.sleep(1)
                                                st.rerun()
                                            else:
                                                st.error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                                        else:
                                            st.error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                                    except Exception as e:
                                        st.error(f"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                            else:
                                st.session_state[f"confirm_delete_dataset_{selected_dataset}"] = True
                                st.warning("âš ï¸ å‰Šé™¤ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚‚ã†ä¸€åº¦å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
                                st.rerun()
                    else:
                        st.info("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å‰Šé™¤ã§ãã¾ã›ã‚“")
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        st.write("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconfig.yamlï¼‰ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
elif current_page == "realtime":
    st.markdown("---")
    st.header("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜")
    
    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—ã§ãã¾ã™ã€‚
    ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™ã€‚
    """)
    
    # æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ“‹ æ¨è«–è¨­å®š")
    col_model_select, col_model_info = st.columns([1, 2])
    
    with col_model_select:
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        available_models = st.session_state.available_models
        if available_models:
            selected_realtime_model = st.selectbox(
                "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«:",
                available_models,
                index=0,
                key="realtime_model_selector",
                help="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        else:
            st.warning("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            selected_realtime_model = None
    
    with col_model_info:
        if selected_realtime_model:
            st.info(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{selected_realtime_model}**")
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
    st.subheader("ğŸ® ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–åˆ¶å¾¡")
    
    col_control1, col_control2, col_control3 = st.columns(3)
    
    with col_control1:
        if st.button("ğŸ¤ é–‹å§‹", key="realtime_start", type="primary", disabled=not selected_realtime_model):
            st.session_state.realtime_running = True
            st.session_state.realtime_partial = ""
            st.session_state.realtime_final = ""
            st.session_state.realtime_status = "æ¥ç¶šä¸­..."
            st.rerun()
    
    with col_control2:
        if st.button("â¹ï¸ åœæ­¢", key="realtime_stop", disabled=not st.session_state.get("realtime_running", False)):
            st.session_state.realtime_running = False
            st.session_state.realtime_status = "åœæ­¢ä¸­..."
            st.rerun()
    
    with col_control3:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="realtime_clear"):
            st.session_state.realtime_partial = ""
            st.session_state.realtime_final = ""
            st.rerun()
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã®çŠ¶æ…‹è¡¨ç¤º
    if st.session_state.get("realtime_running", False):
        st.success("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ãŒå®Ÿè¡Œä¸­ã§ã™")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status = st.session_state.get("realtime_status", "ä¸æ˜")
        st.info(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        st.subheader("ğŸµ éŸ³å£°èªè­˜çµæœ")
        
        # éƒ¨åˆ†çš„ãªçµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ï¼‰
        st.write("**éƒ¨åˆ†çš„ãªçµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰:**")
        partial_text = st.session_state.get("realtime_partial", "")
        st.text_area(
            "éƒ¨åˆ†çš„ãªèªè­˜çµæœ",
            value=partial_text,
            height=100,
            key="realtime_partial_display",
            help="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°ã•ã‚Œã‚‹éƒ¨åˆ†çš„ãªèªè­˜çµæœ"
        )
        
        # æœ€çµ‚çš„ãªçµæœ
        st.write("**æœ€çµ‚çš„ãªçµæœ:**")
        final_text = st.session_state.get("realtime_final", "")
        st.text_area(
            "æœ€çµ‚çš„ãªèªè­˜çµæœ",
            value=final_text,
            height=150,
            key="realtime_final_display",
            help="ç¢ºå®šã•ã‚ŒãŸèªè­˜çµæœ"
        )
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        error_msg = st.session_state.get("realtime_error", "")
        if error_msg:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {error_msg}")
        
        # JavaScriptã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åŸ‹ã‚è¾¼ã¿
        st.components.v1.html("""
        <script>
        // ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦å®šç¾©
        window.realtimeAudioRecognition = null;
        
        class RealtimeAudioRecognition {
            constructor() {
                this.websocket = null;
                this.mediaRecorder = null;
                this.audioContext = null;
                this.isRecording = false;
                this.audioChunks = [];
            }
            
            async start() {
                console.log('Starting realtime audio recognition...');
                try {
                    // WebSocketæ¥ç¶šã‚’å…ˆã«ç¢ºç«‹
                    this.connectWebSocket();
                    
                    // å°‘ã—å¾…ã£ã¦ã‹ã‚‰ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
                    await new Promise(resolve => setTimeout(resolve, 1000));
                    
                    // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    // MediaRecorderã§éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.sendAudioChunk(event.data);
                        }
                    };
                    
                    // 1ç§’ã”ã¨ã«éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡
                    this.mediaRecorder.start(1000);
                    this.isRecording = true;
                    
                    console.log('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã—ãŸ');
                    
                } catch (error) {
                    console.error('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
                    this.showError('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: ' + error.message);
                }
            }
            
            connectWebSocket() {
                // æ—¢å­˜ã®WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«æ¥ç¶š
                const wsUrl = 'ws://localhost:58081/ws';
                
                console.log('=== WebSocket Connection Debug ===');
                console.log('Connecting to WebSocket:', wsUrl);
                console.log('Current time:', new Date().toISOString());
                
                try {
                    this.websocket = new WebSocket(wsUrl);
                    console.log('WebSocket object created:', this.websocket);
                    console.log('WebSocket readyState:', this.websocket.readyState);
                } catch (error) {
                    console.error('Failed to create WebSocket:', error);
                    this.showError('WebSocketä½œæˆã‚¨ãƒ©ãƒ¼: ' + error.message);
                    return;
                }
                
                // æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                const connectionTimeout = setTimeout(() => {
                    if (this.websocket.readyState === WebSocket.CONNECTING) {
                        console.error('WebSocket connection timeout');
                        this.showError('WebSocketæ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ');
                        this.websocket.close();
                    }
                }, 10000); // 10ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                
                this.websocket.onopen = () => {
                    console.log('=== WebSocket Connected ===');
                    console.log('WebSocketæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸ');
                    console.log('WebSocket readyState:', this.websocket.readyState);
                    clearTimeout(connectionTimeout); // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
                    this.updateStatus('æ¥ç¶šæ¸ˆã¿');
                    
                    // æ—¢å­˜ã®WebSocketãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«åˆã‚ã›ã¦é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
                    const startMessage = {
                        type: 'start',
                        model_name: 'conformer',
                        sample_rate: 16000,
                        format: 'i16'
                    };
                    console.log('Sending start message:', startMessage);
                    this.websocket.send(JSON.stringify(startMessage));
                    console.log('Start message sent successfully');
                    
                    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
                    this.updateStatus('ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...');
                };
                
                this.websocket.onmessage = (event) => {
                    console.log('WebSocket message received:', event.data);
                    try {
                        const data = JSON.parse(event.data);
                        this.handleMessage(data);
                    } catch (error) {
                        console.error('Failed to parse WebSocket message:', error);
                    }
                };
                
                this.websocket.onclose = (event) => {
                    console.log('WebSocketæ¥ç¶šãŒé–‰ã˜ã‚‰ã‚Œã¾ã—ãŸ:', event.code, event.reason);
                    clearTimeout(connectionTimeout); // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
                    this.updateStatus('æ¥ç¶šåˆ‡æ–­');
                };
                
                this.websocket.onerror = (error) => {
                    console.error('WebSocketã‚¨ãƒ©ãƒ¼:', error);
                    clearTimeout(connectionTimeout); // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
                    this.showError('WebSocketæ¥ç¶šã‚¨ãƒ©ãƒ¼: ' + error.message);
                };
            }
            
            async sendAudioChunk(audioBlob) {
                if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
                    console.log('WebSocket not ready, skipping audio chunk');
                    return;
                }
                
                try {
                    // Blobã‚’ArrayBufferã«å¤‰æ›
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    
                    // æ—¢å­˜ã®WebSocketãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«åˆã‚ã›ã¦ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥é€ä¿¡
                    console.log('Sending audio chunk, size:', arrayBuffer.byteLength);
                    this.websocket.send(arrayBuffer);
                    
                } catch (error) {
                    console.error('éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
                    this.showError('éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚¨ãƒ©ãƒ¼: ' + error.message);
                }
            }
            
            handleMessage(data) {
                console.log('Handling message:', data);
                switch (data.type) {
                    case 'partial':
                        console.log('Partial result:', data.payload.text);
                        this.updatePartialResult(data.payload.text);
                        break;
                    case 'final':
                        console.log('Final result:', data.payload.text);
                        this.updateFinalResult(data.payload.text);
                        break;
                    case 'error':
                        console.log('Error:', data.payload.message);
                        this.showError(data.payload.message);
                        break;
                    case 'status':
                        console.log('Status update:', data.payload.status);
                        this.updateStatus(data.payload.status);
                        break;
                    default:
                        console.log('Unknown message type:', data.type);
                }
            }
            
            updatePartialResult(text) {
                // Streamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                const event = new CustomEvent('realtime-update', {
                    detail: { type: 'partial', text: text }
                });
                window.dispatchEvent(event);
            }
            
            updateFinalResult(text) {
                // Streamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                const event = new CustomEvent('realtime-update', {
                    detail: { type: 'final', text: text }
                });
                window.dispatchEvent(event);
            }
            
            updateStatus(status) {
                console.log('Status update:', status);
                const event = new CustomEvent('realtime-update', {
                    detail: { type: 'status', status: status }
                });
                window.dispatchEvent(event);
            }
            
            showError(message) {
                const event = new CustomEvent('realtime-update', {
                    detail: { type: 'error', message: message }
                });
                window.dispatchEvent(event);
            }
            
            stop() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                }
                
                if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    // æ—¢å­˜ã®WebSocketãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«åˆã‚ã›ã¦åœæ­¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
                    const stopMessage = {
                        type: 'stop'
                    };
                    this.websocket.send(JSON.stringify(stopMessage));
                    console.log('Sent stop message:', stopMessage);
                }
                
                if (this.websocket) {
                    this.websocket.close();
                }
                
                console.log('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã—ãŸ');
            }
        }
        
        // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        window.realtimeAudio = new RealtimeAudioRecognition();
        
        // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
        window.addEventListener('realtime-update', (event) => {
            const { type, text, status, message } = event.detail;
            
            // Streamlitã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ™ãƒ³ãƒˆ
            const updateEvent = new CustomEvent('streamlit:update', {
                detail: { 
                    type: type,
                    text: text,
                    status: status,
                    message: message
                }
            });
            window.parent.dispatchEvent(updateEvent);
        });
        
                // è‡ªå‹•é–‹å§‹ï¼ˆãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰æ™‚ï¼‰
                if (window.location.hash === '#realtime') {
                    setTimeout(() => {
                        console.log('Auto-starting realtime audio recognition...');
                        window.realtimeAudio.start();
                    }, 1000);
                }
                
                // ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ã‚’è¿½åŠ 
                window.testWebSocket = function() {
                    console.log('Testing WebSocket connection...');
                    window.realtimeAudio.connectWebSocket();
                };
                
                window.testStart = function() {
                    console.log('Testing start function...');
                    window.realtimeAudio.start();
                };
                
                // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
                window.realtimeAudioRecognition = new RealtimeAudioRecognition();
                
                // ãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰æ™‚ã®ãƒ†ã‚¹ãƒˆ
                console.log('=== JavaScript loaded ===');
                console.log('RealtimeAudioRecognition class:', typeof RealtimeAudioRecognition);
                console.log('window.realtimeAudioRecognition:', window.realtimeAudioRecognition);
                
                // ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
                setTimeout(() => {
                    console.log('=== Auto-test after 2 seconds ===');
                    console.log('Testing basic functionality...');
                    console.log('Available methods:', Object.getOwnPropertyNames(RealtimeAudioRecognition.prototype));
                }, 2000);
        </script>
        """, height=0)
        
    else:
        st.info("ğŸ¤ ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
        
        # ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
        st.subheader("ğŸ“– ä½¿ç”¨æ–¹æ³•")
        st.markdown("""
        1. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: ä¸Šè¨˜ã§æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„
        2. **é–‹å§‹ãƒœã‚¿ãƒ³**: ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™
        3. **ãƒã‚¤ã‚¯è¨±å¯**: ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®è¨±å¯ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€Œè¨±å¯ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„
        4. **éŸ³å£°èªè­˜**: ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã™ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™
        5. **åœæ­¢**: ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ã§æ¨è«–ã‚’åœæ­¢ã§ãã¾ã™
        6. **ã‚¯ãƒªã‚¢**: ã€Œã‚¯ãƒªã‚¢ã€ãƒœã‚¿ãƒ³ã§çµæœã‚’ã‚¯ãƒªã‚¢ã§ãã¾ã™
        """)
        
        st.subheader("âš ï¸ æ³¨æ„äº‹é …")
        st.markdown("""
        - ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™
        - HTTPSç’°å¢ƒã§ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™
        - éŸ³å£°ã®å“è³ªã«ã‚ˆã£ã¦èªè­˜ç²¾åº¦ãŒå¤‰ã‚ã‚Šã¾ã™
        - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãŒå¿…è¦ã§ã™
        """)
