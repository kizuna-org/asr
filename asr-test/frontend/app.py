import streamlit as st
import pandas as pd
import requests
import asyncio
import websockets
import json
from typing import Dict, Any
import traceback
import os
import threading

# --- è¨­å®š ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰URLã‚’å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆ
BACKEND_HOST = os.getenv("BACKEND_HOST", "localhost")
BACKEND_PORT = os.getenv("BACKEND_PORT", "58081")
BACKEND_URL = f"http://{BACKEND_HOST}:{BACKEND_PORT}/api"
WEBSOCKET_URL = f"ws://{BACKEND_HOST}:{BACKEND_PORT}/ws"

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
HTTP_PROXY = os.getenv("HTTP_PROXY")
HTTPS_PROXY = os.getenv("HTTPS_PROXY")
NO_PROXY = os.getenv("NO_PROXY", "localhost,127.0.0.1,asr-api")

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’è¾æ›¸å½¢å¼ã§æº–å‚™
proxies = {}
if HTTP_PROXY:
    proxies["http"] = HTTP_PROXY
if HTTPS_PROXY:
    proxies["https"] = HTTPS_PROXY

# NO_PROXYã®å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def should_use_proxy(url):
    """URLãŒãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not proxies:
        return False
    
    no_proxy_hosts = [host.strip() for host in NO_PROXY.split(",")]
    for host in no_proxy_hosts:
        if host in url:
            return False
    return True

# --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– ---
def init_session_state():
    defaults = {
        "logs": ["ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¸ã‚ˆã†ã“ãï¼"],
        "progress_df": pd.DataFrame(columns=["epoch", "step", "loss"]).astype({"epoch": int, "step": int, "loss": float}),
        "validation_df": pd.DataFrame(columns=["epoch", "val_loss"]).astype({"epoch": int, "val_loss": float}),
        "lr_df": pd.DataFrame(columns=["step", "learning_rate"]).astype({"step": int, "learning_rate": float}),
        "is_training": False,
        "available_models": [],
        "available_datasets": [],
        "current_progress": 0,
        "progress_text": "å¾…æ©Ÿä¸­",
        "current_epoch": 0,
        "current_step": 0,
        "total_epochs": 0,
        "total_steps": 0,
        "last_progress_update": 0,
        "initial_load": False,
        "last_rerun_time": 0,
        "consecutive_errors": 0,
        "max_consecutive_errors": 3
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- æ¨è«–APIå‘¼ã³å‡ºã— ---
def run_inference(file_bytes: bytes, filename: str, model_name: str) -> Dict[str, Any]:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã€çµæœã¨æ¨è«–æ™‚é–“(ms)ã‚’è¿”ã™"""
    try:
        import time
        st.session_state.logs.append(f"ğŸ§ª æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/inference")
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        files = {
            "file": (filename, file_bytes, "application/octet-stream"),
        }
        params = {"model_name": model_name} if model_name else None
        start_time = time.perf_counter()
        response = requests.post(
            f"{BACKEND_URL}/inference",
            files=files,
            params=params,
            timeout=120,
            proxies=request_proxies,
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000.0
        response.raise_for_status()
        data = response.json()
        transcription = data.get("transcription", "")
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒæ™‚é–“ã‚’è¿”ã—ã¦ã„ã‚‹å ´åˆã¯å„ªå…ˆ
        server_elapsed_ms = data.get("inference_time_ms") or data.get("elapsed_ms")
        total_ms = float(server_elapsed_ms) if server_elapsed_ms is not None else elapsed_ms
        st.session_state.logs.append(f"âœ… æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸ (â± {total_ms:.0f} ms)")
        return {"transcription": transcription, "inference_time_ms": total_ms}
    except requests.exceptions.RequestException as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e, getattr(e, "response", None))
        return {"transcription": "", "inference_time_ms": None}
    except Exception as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e)
        return {"transcription": "", "inference_time_ms": None}

# --- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°é–¢æ•° ---
def log_detailed_error(operation: str, error: Exception, response=None):
    """è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    error_msg = f"âŒ {operation} ã‚¨ãƒ©ãƒ¼:"
    
    # åŸºæœ¬ã‚¨ãƒ©ãƒ¼æƒ…å ±
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(error).__name__}"
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(error)}"
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æƒ…å ±ãŒã‚ã‚‹å ´åˆ
    if response is not None:
        error_msg += f"\n   - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}"
        error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {dict(response.headers)}"
        try:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: {response.text}"
        except:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: èª­ã¿å–ã‚Šä¸å¯"
    
    # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è©³ç´°
    if isinstance(error, requests.exceptions.ConnectionError):
        error_msg += f"\n   - æ¥ç¶šå…ˆ: {BACKEND_URL}"
        error_msg += f"\n   - æ¥ç¶šã‚¨ãƒ©ãƒ¼è©³ç´°: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“"
        error_msg += f"\n   - ç¢ºèªäº‹é …:"
        error_msg += f"\n     * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * Dockerã‚³ãƒ³ãƒ†ãƒŠãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šãŒæ­£ã—ã„ã‹"
    elif isinstance(error, requests.exceptions.Timeout):
        error_msg += f"\n   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè©³ç´°: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
    elif isinstance(error, requests.exceptions.HTTPError):
        error_msg += f"\n   - HTTPã‚¨ãƒ©ãƒ¼è©³ç´°: HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼"
    
    # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆé–‹ç™ºç”¨ï¼‰
    error_msg += f"\n   - ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}"
    
    st.session_state.logs.append(error_msg)

# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIé€šä¿¡ ---
def get_config():
    """è¨­å®šæƒ…å ±ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” è¨­å®šæƒ…å ±ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/config")
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/config", timeout=10, proxies=request_proxies)
        
        if response.status_code == 200:
            config = response.json()
            st.session_state.available_models = config.get("available_models", [])
            st.session_state.available_datasets = config.get("available_datasets", [])
            st.session_state.logs.append("âœ… è¨­å®šæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        else:
            log_detailed_error("è¨­å®šå–å¾—", Exception(f"HTTP {response.status_code}"), response)
            
    except requests.exceptions.ConnectionError as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.Timeout as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.RequestException as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except Exception as e:
        log_detailed_error("è¨­å®šå–å¾—", e)

def get_status():
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/status")
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/status", timeout=10, proxies=request_proxies)
        
        if response.status_code == 200:
            status = response.json()
            st.session_state.is_training = status.get("is_training", False)
            st.session_state.logs.append("âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸ")
            # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.consecutive_errors = 0
        else:
            log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", Exception(f"HTTP {response.status_code}"), response)
            st.session_state.consecutive_errors += 1
            
    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.Timeout as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.RequestException as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except Exception as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1

def start_training(model_name: str, dataset_name: str, epochs: int, batch_size: int, lightweight: bool = False, limit_samples: int = 0):
    """å­¦ç¿’ã‚’é–‹å§‹"""
    try:
        params = {
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": epochs,
            "batch_size": batch_size
        }
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰/ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™ã®ä»˜ä¸
        if lightweight:
            params["lightweight"] = True
        if isinstance(limit_samples, int) and limit_samples > 0:
            params["limit_samples"] = int(limit_samples)
        st.session_state.logs.append(f"ğŸš€ å­¦ç¿’é–‹å§‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/start")
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/start", json=params, timeout=30, proxies=request_proxies)
        
        if response.status_code == 200:
            st.session_state.is_training = True
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’é–‹å§‹", Exception(f"HTTP {response.status_code}"), response)
            return False
            
    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False

def stop_training():
    """å­¦ç¿’ã‚’åœæ­¢"""
    try:
        st.session_state.logs.append(f"ğŸ›‘ å­¦ç¿’åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/stop")
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/stop", timeout=10, proxies=request_proxies)
        
        if response.status_code == 200:
            st.session_state.is_training = False
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’åœæ­¢", Exception(f"HTTP {response.status_code}"), response)
            return False
            
    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False

def download_dataset(dataset_name: str):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        st.session_state.logs.append(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {dataset_name}")
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/dataset/download", json={"dataset_name": dataset_name}, timeout=300, proxies=request_proxies)
        
        if response.status_code == 200:
            result = response.json()
            st.session_state.logs.append(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°ã«è¿½åŠ 
            if "stdout" in result and result["stdout"]:
                st.session_state.logs.append(f"ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©³ç´°:\n{result['stdout']}")
            if "stderr" in result and result["stderr"]:
                st.session_state.logs.append(f"âš ï¸ è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{result['stderr']}")
            
            return True
        else:
            # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
            try:
                error_detail = response.json()
                if "detail" in error_detail:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{error_detail['detail']}")
                else:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {response.text}")
            except:
                st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
            
            log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", Exception(f"HTTP {response.status_code}"), response)
            return False
            
    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except Exception as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False

# --- é€²æ—å–å¾—é–¢æ•° ---
def get_training_progress():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰å­¦ç¿’é€²æ—ã‚’å–å¾—"""
    try:
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/progress", timeout=5, proxies=request_proxies)
        
        if response.status_code == 200:
            progress_data = response.json()
            return progress_data
        elif response.status_code == 404:
            # 404ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§
            st.session_state.logs.append(f"âš ï¸ é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {response.status_code}")
            return None
        else:
            st.session_state.logs.append(f"âš ï¸ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
            return None
    except requests.exceptions.ConnectionError as e:
        # ä¸€æ™‚çš„ãªæ¥ç¶šã‚¨ãƒ©ãƒ¼ã§ã¯å­¦ç¿’çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„
        st.session_state.logs.append(f"âŒ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except requests.exceptions.Timeout as e:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ãŒã€å­¦ç¿’çŠ¶æ…‹ã¯ç¶­æŒ
        st.session_state.logs.append(f"â° é€²æ—å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")
        return None
    except Exception as e:
        st.session_state.logs.append(f"âŒ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_progress_from_backend():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€²æ—ã‚’å–å¾—ã—ã¦æ›´æ–°"""
    # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯é€²æ—æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if st.session_state.consecutive_errors >= st.session_state.max_consecutive_errors:
        st.session_state.logs.append("âš ï¸ é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹ãŸã‚ã€é€²æ—æ›´æ–°ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã™")
        return False
    
    progress_data = get_training_progress()
    # ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
    import time
    st.session_state["last_poll_at"] = time.time()
    if progress_data:
        # é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        if "current_epoch" in progress_data and "current_step" in progress_data:
            st.session_state.current_epoch = progress_data.get("current_epoch", 0)
            st.session_state.current_step = progress_data.get("current_step", 0)
            st.session_state.total_epochs = progress_data.get("total_epochs", 0)
            st.session_state.total_steps = progress_data.get("total_steps", 0)
            st.session_state.current_progress = progress_data.get("progress", 0)
            st.session_state.progress_text = f"Epoch {progress_data['current_epoch']}/{progress_data.get('total_epochs', '?')}, Step {progress_data['current_step']}/{progress_data.get('total_steps', '?')}"
        
        # ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_loss" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.progress_df.empty:
                last_step = st.session_state.progress_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                        "epoch": progress_data.get("current_epoch", 0),
                        "step": current_step,
                        "loss": progress_data["current_loss"]
                    }
            else:
                st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                    "epoch": progress_data.get("current_epoch", 0),
                    "step": current_step,
                    "loss": progress_data["current_loss"]
                }
        
        # å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_learning_rate" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.lr_df.empty:
                last_step = st.session_state.lr_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                        "step": current_step,
                        "learning_rate": progress_data["current_learning_rate"]
                    }
            else:
                st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                    "step": current_step,
                    "learning_rate": progress_data["current_learning_rate"]
                }
        
        # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
        if "latest_logs" in progress_data:
            for log in progress_data["latest_logs"]:
                if log not in st.session_state.logs:
                    st.session_state.logs.append(log)
        
        # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.consecutive_errors = 0
        return True
    else:
        st.session_state.consecutive_errors += 1
        return False

# --- UIæç”» ---
st.set_page_config(layout="wide")
init_session_state()

if not st.session_state.initial_load:
    # åˆæœŸåŒ–æ™‚ã¯è¨­å®šã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
    get_config()
    get_status()
    st.session_state.initial_load = True
elif st.session_state.is_training:
    # å­¦ç¿’ä¸­ã®å ´åˆã®ã¿ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å†ç¢ºèªï¼ˆãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã®çŠ¶æ…‹å¾©å…ƒï¼‰
    import time
    current_time = time.time()
    if "last_status_check" not in st.session_state:
        st.session_state.last_status_check = 0
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã®é »åº¦ã‚’åˆ¶é™ï¼ˆ30ç§’ã”ã¨ï¼‰
    if current_time - st.session_state.last_status_check >= 30:
        get_status()
        st.session_state.last_status_check = current_time

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ASR å­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - å­¦ç¿’åˆ¶å¾¡
with st.sidebar:
    st.header("å­¦ç¿’åˆ¶å¾¡")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_name = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«",
        st.session_state.available_models,
        index=0 if st.session_state.available_models else None
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    dataset_name = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
        st.session_state.available_datasets,
        index=0 if st.session_state.available_datasets else None
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if st.button("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", disabled=st.session_state.is_training):
        if dataset_name:
            with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                success = download_dataset(dataset_name)
                if success:
                    st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    # è¨­å®šã‚’å†å–å¾—ã—ã¦æœ€æ–°ã®çŠ¶æ…‹ã‚’åæ˜ 
                    get_config()
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epochs = st.number_input("ã‚¨ãƒãƒƒã‚¯æ•°", min_value=1, value=10)
    batch_size = st.number_input("ãƒãƒƒãƒã‚µã‚¤ã‚º", min_value=1, value=4)
    lightweight = st.checkbox("è»½é‡(å…ˆé ­10ä»¶)ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", value=True)
    limit_samples = st.number_input("ä½¿ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ (0ã§ç„¡åŠ¹)", min_value=0, value=0)
    
    # å­¦ç¿’é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        if st.button("å­¦ç¿’é–‹å§‹", disabled=st.session_state.is_training):
            if model_name and dataset_name:
                success = start_training(model_name, dataset_name, epochs, batch_size, lightweight=lightweight, limit_samples=limit_samples)
                if not success:
                    st.error("å­¦ç¿’ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    with col2:
        if st.button("å­¦ç¿’åœæ­¢", disabled=not st.session_state.is_training):
            stop_training()
    
    # é€²æ—è¡¨ç¤º
    if st.session_state.is_training:
        st.progress(st.session_state.current_progress)
        st.text(st.session_state.progress_text)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
col1, col2 = st.columns(2)

# æ¨è«–ãƒ†ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.header("æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰")
inf_col1, inf_col2 = st.columns([2, 1])
with inf_col1:
    uploaded = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (WAV/FLACãªã©)", type=["wav", "flac", "mp3", "m4a", "ogg"])
    if uploaded is not None:
        st.audio(uploaded, format="audio/wav")
with inf_col2:
    if st.button("æ¨è«–ã‚’å®Ÿè¡Œ", disabled=uploaded is None):
        if uploaded is None:
            st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
        else:
            with st.spinner("æ¨è«–ã‚’å®Ÿè¡Œä¸­..."):
                result = run_inference(uploaded.getvalue(), uploaded.name, model_name)
                transcription = result.get("transcription", "")
                infer_ms = result.get("inference_time_ms")
                if transcription:
                    st.success("æ¨è«–å®Œäº†")
                    if infer_ms is not None:
                        st.metric(label="æ¨è«–æ™‚é–“", value=f"{infer_ms:.0f} ms")
                    st.text_area("æ–‡å­—èµ·ã“ã—çµæœ", value=transcription, height=120)
                else:
                    st.error("æ¨è«–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ä¸Šéƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆå­¦ç¿’ä¸­ã®ã¿ï¼‰
if st.session_state.is_training:
    m1, m2 = st.columns(2)
    with m1:
        st.metric(label="Epoch", value=f"{st.session_state.current_epoch}/{st.session_state.total_epochs}")
    with m2:
        st.metric(label="Step", value=f"{st.session_state.current_step}/{st.session_state.total_steps}")

with col1:
    st.header("å­¦ç¿’ãƒ­ã‚¹")
    if not st.session_state.progress_df.empty:
        loss_data = st.session_state.progress_df.rename(columns={"loss": "train_loss"})
        if not st.session_state.validation_df.empty:
            # ã‚¨ãƒãƒƒã‚¯ã®æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã«æ¤œè¨¼ãƒ­ã‚¹ã‚’ç´ä»˜ã‘ã‚‹
            last_step_per_epoch = loss_data.groupby("epoch")["step"].max().reset_index()
            merged_val = pd.merge(st.session_state.validation_df, last_step_per_epoch, on="epoch")
            loss_data = pd.merge(loss_data, merged_val, on=["epoch", "step"], how="left")
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’æç”»å¯¾è±¡ã«ã™ã‚‹
        plot_cols = [c for c in ["train_loss", "val_loss"] if c in loss_data.columns]
        st.line_chart(loss_data.set_index("step")[plot_cols])
    else:
        st.info("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

with col2:
    st.header("å­¦ç¿’ç‡")
    if not st.session_state.lr_df.empty:
        st.line_chart(st.session_state.lr_df.set_index("step")["learning_rate"])
    else:
        st.info("å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# ãƒ­ã‚°è¡¨ç¤º
st.header("ãƒ­ã‚°")
log_container = st.container()
with log_container:
    for log in st.session_state.logs[-50:]:  # æœ€æ–°50ä»¶ã‚’è¡¨ç¤º
        st.text(log)

# å­¦ç¿’ä¸­ã®é€²æ—æ›´æ–°
if st.session_state.is_training:
    # ç›´è¿‘ã®ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°/å¯è¦–åŒ–ï¼‰
    import time
    last_polled = st.session_state.get("last_poll_at")
    if last_polled:
        st.caption(f"æœ€çµ‚ãƒãƒ¼ãƒªãƒ³ã‚°: {time.strftime('%H:%M:%S', time.localtime(last_polled))}")
    # é€²æ—æ›´æ–°ã®é »åº¦ã‚’åˆ¶é™ï¼ˆ1ç§’ã”ã¨ï¼‰
    import time
    current_time = time.time()
    if "last_progress_update" not in st.session_state:
        st.session_state.last_progress_update = 0
    
    # é€²æ—æ›´æ–°ã®å®Ÿè¡Œ
    progress_updated = False
    if current_time - st.session_state.last_progress_update >= 1:
        progress_updated = update_progress_from_backend()
        st.session_state.last_progress_update = current_time
    
    # ç¢ºå®Ÿãª1ç§’ã”ã¨ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¹ãƒªãƒ¼ãƒ—â†’å†å®Ÿè¡Œï¼‰
    time.sleep(1)
    st.rerun()
