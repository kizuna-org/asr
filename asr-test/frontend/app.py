import streamlit as st
import pandas as pd
import requests
import asyncio
import websockets
import json
from typing import Dict, Any
import traceback
import os
import threading
import queue
import numpy as np
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import logging
import sys
from datetime import datetime

# --- ãƒ­ã‚°è¨­å®š ---
class StructuredFormatter(logging.Formatter):
    """æ§‹é€ åŒ–ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰"""

    def format(self, record):
        log_entry = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }

        # ä¾‹å¤–æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if record.exc_info:
            log_entry["exception"] = self.formatException(record.exc_info)

        # è¿½åŠ ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if hasattr(record, 'extra_fields'):
            log_entry.update(record.extra_fields)

        return json.dumps(log_entry, ensure_ascii=False)

def setup_frontend_logging():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–"""
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®è¨­å®š
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(StructuredFormatter())
    root_logger.addHandler(console_handler)

    # ç‰¹å®šã®ãƒ­ã‚¬ãƒ¼ã®ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger("ui-rt").setLevel(logging.INFO)
    logging.getLogger("audio_puller").setLevel(logging.INFO)
    logging.getLogger("websocket_loop").setLevel(logging.INFO)
    logging.getLogger("websocket_sender").setLevel(logging.INFO)

# ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–
setup_frontend_logging()

# --- è¨­å®š ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰URLã‚’å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆ
BACKEND_HOST = os.getenv("BACKEND_HOST", "localhost")
BACKEND_PORT = os.getenv("BACKEND_PORT", "58081")
BACKEND_URL = f"http://{BACKEND_HOST}:{BACKEND_PORT}/api"
WEBSOCKET_URL = f"ws://{BACKEND_HOST}:{BACKEND_PORT}/ws"

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
HTTP_PROXY = os.getenv("HTTP_PROXY")
HTTPS_PROXY = os.getenv("HTTPS_PROXY")
NO_PROXY = os.getenv("NO_PROXY", "localhost,127.0.0.1,asr-api")

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’è¾æ›¸å½¢å¼ã§æº–å‚™
proxies = {}
if HTTP_PROXY:
    proxies["http"] = HTTP_PROXY
if HTTPS_PROXY:
    proxies["https"] = HTTPS_PROXY

# NO_PROXYã®å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def should_use_proxy(url):
    """URLãŒãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not proxies:
        return False

    no_proxy_hosts = [host.strip() for host in NO_PROXY.split(",")]
    for host in no_proxy_hosts:
        if host in url:
            return False
    return True

# --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– ---
def init_session_state():
    defaults = {
        "logs": ["ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¸ã‚ˆã†ã“ãï¼"],
        "progress_df": pd.DataFrame(columns=["epoch", "step", "loss"]).astype({"epoch": int, "step": int, "loss": float}),
        "validation_df": pd.DataFrame(columns=["epoch", "val_loss"]).astype({"epoch": int, "val_loss": float}),
        "lr_df": pd.DataFrame(columns=["step", "learning_rate"]).astype({"step": int, "learning_rate": float}),
        "is_training": False,
        "available_models": [],
        "available_datasets": [],
        "current_progress": 0,
        "progress_text": "å¾…æ©Ÿä¸­",
        "current_epoch": 0,
        "current_step": 0,
        "total_epochs": 0,
        "total_steps": 0,
        "last_progress_update": 0,
        "initial_load": False,
        "last_rerun_time": 0,
        "consecutive_errors": 0,
        "max_consecutive_errors": 3
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- æ¨è«–APIå‘¼ã³å‡ºã— ---
def run_inference(file_bytes: bytes, filename: str, model_name: str) -> Dict[str, Any]:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã€çµæœã¨3ç¨®é¡ã®æ™‚é–“(ms)ã‚’è¿”ã™"""
    try:
        import time
        st.session_state.logs.append(f"ğŸ§ª æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/inference")
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        files = {
            "file": (filename, file_bytes, "application/octet-stream"),
        }
        params = {"model_name": model_name} if model_name else None
        start_time = time.perf_counter()
        response = requests.post(
            f"{BACKEND_URL}/inference",
            files=files,
            params=params,
            timeout=120,
            proxies=request_proxies,
        )
        elapsed_ms = (time.perf_counter() - start_time) * 1000.0
        response.raise_for_status()
        data = response.json()
        transcription = data.get("transcription", "")

        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰3ç¨®é¡ã®æ™‚é–“ã‚’å–å¾—
        first_token_time_ms = data.get("first_token_time_ms")
        inference_time_ms = data.get("inference_time_ms")
        total_time_ms = data.get("total_time_ms")

        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒæ™‚é–“ã‚’è¿”ã—ã¦ã„ãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if first_token_time_ms is None:
            first_token_time_ms = elapsed_ms * 0.1  # ä»®ã®å€¤
        if inference_time_ms is None:
            inference_time_ms = elapsed_ms * 0.8  # ä»®ã®å€¤
        if total_time_ms is None:
            total_time_ms = elapsed_ms

        st.session_state.logs.append(f"âœ… æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸ")
        st.session_state.logs.append(f"   ğŸ“Š æ™‚é–“è¨ˆæ¸¬çµæœ:")
        st.session_state.logs.append(f"   - æœ€åˆã®å‡ºåŠ›ã¾ã§: {first_token_time_ms:.0f} ms")
        st.session_state.logs.append(f"   - æ¨è«–æ™‚é–“: {inference_time_ms:.0f} ms")
        st.session_state.logs.append(f"   - ç·æ™‚é–“: {total_time_ms:.0f} ms")

        return {
            "transcription": transcription,
            "first_token_time_ms": first_token_time_ms,
            "inference_time_ms": inference_time_ms,
            "total_time_ms": total_time_ms
        }
    except requests.exceptions.RequestException as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e, getattr(e, "response", None))
        return {"transcription": "", "first_token_time_ms": None, "inference_time_ms": None, "total_time_ms": None}
    except Exception as e:
        log_detailed_error("æ¨è«–å®Ÿè¡Œ", e)
        return {"transcription": "", "first_token_time_ms": None, "inference_time_ms": None, "total_time_ms": None}

# --- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°é–¢æ•° ---
def log_detailed_error(operation: str, error: Exception, response=None):
    """è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    error_msg = f"âŒ {operation} ã‚¨ãƒ©ãƒ¼:"

    # åŸºæœ¬ã‚¨ãƒ©ãƒ¼æƒ…å ±
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(error).__name__}"
    error_msg += f"\n   - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(error)}"

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æƒ…å ±ãŒã‚ã‚‹å ´åˆ
    if response is not None:
        error_msg += f"\n   - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}"
        error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {dict(response.headers)}"
        try:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: {response.text}"
        except:
            error_msg += f"\n   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£: èª­ã¿å–ã‚Šä¸å¯"

    # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è©³ç´°
    if isinstance(error, requests.exceptions.ConnectionError):
        error_msg += f"\n   - æ¥ç¶šå…ˆ: {BACKEND_URL}"
        error_msg += f"\n   - æ¥ç¶šã‚¨ãƒ©ãƒ¼è©³ç´°: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“"
        error_msg += f"\n   - ç¢ºèªäº‹é …:"
        error_msg += f"\n     * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * Dockerã‚³ãƒ³ãƒ†ãƒŠãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹"
        error_msg += f"\n     * ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šãŒæ­£ã—ã„ã‹"
    elif isinstance(error, requests.exceptions.Timeout):
        error_msg += f"\n   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè©³ç´°: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
    elif isinstance(error, requests.exceptions.HTTPError):
        error_msg += f"\n   - HTTPã‚¨ãƒ©ãƒ¼è©³ç´°: HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼"

    # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆé–‹ç™ºç”¨ï¼‰
    error_msg += f"\n   - ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}"

    st.session_state.logs.append(error_msg)

# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIé€šä¿¡ ---
def get_config():
    """è¨­å®šæƒ…å ±ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” è¨­å®šæƒ…å ±ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/config")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/config", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            config = response.json()
            st.session_state.available_models = config.get("available_models", [])
            st.session_state.available_datasets = config.get("available_datasets", [])
            st.session_state.logs.append("âœ… è¨­å®šæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        else:
            log_detailed_error("è¨­å®šå–å¾—", Exception(f"HTTP {response.status_code}"), response)

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.Timeout as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except requests.exceptions.RequestException as e:
        log_detailed_error("è¨­å®šå–å¾—", e)
    except Exception as e:
        log_detailed_error("è¨­å®šå–å¾—", e)

def get_status():
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    try:
        st.session_state.logs.append(f"ğŸ” ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ä¸­... URL: {BACKEND_URL}/status")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/status", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            status = response.json()
            st.session_state.is_training = status.get("is_training", False)
            st.session_state.logs.append("âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸ")
            # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.consecutive_errors = 0
        else:
            log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", Exception(f"HTTP {response.status_code}"), response)
            st.session_state.consecutive_errors += 1

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.Timeout as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except requests.exceptions.RequestException as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1
    except Exception as e:
        log_detailed_error("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—", e)
        st.session_state.consecutive_errors += 1

def start_training(model_name: str, dataset_name: str, epochs: int, batch_size: int, lightweight: bool = False, limit_samples: int = 0, resume_from_checkpoint: bool = True, specific_checkpoint: str = None):
    """å­¦ç¿’ã‚’é–‹å§‹"""
    try:
        params = {
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": epochs,
            "batch_size": batch_size,
            "resume_from_checkpoint": resume_from_checkpoint
        }
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰/ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™ã®ä»˜ä¸
        if lightweight:
            params["lightweight"] = True
        if isinstance(limit_samples, int) and limit_samples > 0:
            params["limit_samples"] = int(limit_samples)
        if specific_checkpoint:
            params["specific_checkpoint"] = specific_checkpoint

        st.session_state.logs.append(f"ğŸš€ å­¦ç¿’é–‹å§‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/start")
        if resume_from_checkpoint:
            if specific_checkpoint:
                st.session_state.logs.append(f"ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: {specific_checkpoint}")
            else:
                st.session_state.logs.append("ğŸ“‚ æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹")
        else:
            st.session_state.logs.append("ğŸ†• æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/start", json=params, timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = True
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ä¿å­˜
            if resume_from_checkpoint:
                if specific_checkpoint:
                    st.session_state.resume_info = f"Epoch {specific_checkpoint.split('-epoch-')[1].replace('.pt', '')}"
                else:
                    st.session_state.resume_info = "æœ€æ–°"
            else:
                st.session_state.resume_info = "æ–°è¦"
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’é–‹å§‹", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’é–‹å§‹", e)
        return False

def resume_training(model_name: str, dataset_name: str, epochs: int, batch_size: int, specific_checkpoint: str = None, lightweight: bool = False, limit_samples: int = 0):
    """å­¦ç¿’ã‚’å†é–‹"""
    try:
        params = {
            "model_name": model_name,
            "dataset_name": dataset_name,
            "epochs": epochs,
            "batch_size": batch_size
        }
        if specific_checkpoint:
            params["specific_checkpoint"] = specific_checkpoint
        if lightweight:
            params["lightweight"] = True
        if isinstance(limit_samples, int) and limit_samples > 0:
            params["limit_samples"] = int(limit_samples)

        st.session_state.logs.append(f"ğŸ”„ å­¦ç¿’å†é–‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/resume")
        if specific_checkpoint:
            st.session_state.logs.append(f"ğŸ“‚ æŒ‡å®šã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: {specific_checkpoint}")
        else:
            st.session_state.logs.append("ğŸ“‚ æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/resume", json=params, timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = True
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ä¿å­˜
            if specific_checkpoint:
                st.session_state.resume_info = f"Epoch {specific_checkpoint.split('-epoch-')[1].replace('.pt', '')}"
            else:
                st.session_state.resume_info = "æœ€æ–°"
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’å†é–‹ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’å†é–‹", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’å†é–‹", e)
        return False

def stop_training():
    """å­¦ç¿’ã‚’åœæ­¢"""
    try:
        st.session_state.logs.append(f"ğŸ›‘ å­¦ç¿’åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­... URL: {BACKEND_URL}/train/stop")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/train/stop", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            st.session_state.is_training = False
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
            if "resume_info" in st.session_state:
                del st.session_state.resume_info
            st.session_state.logs.append("âœ… å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã—ãŸ")
            return True
        else:
            log_detailed_error("å­¦ç¿’åœæ­¢", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False
    except Exception as e:
        log_detailed_error("å­¦ç¿’åœæ­¢", e)
        return False

def download_dataset(dataset_name: str):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        st.session_state.logs.append(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {dataset_name}")

        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.post(f"{BACKEND_URL}/dataset/download", json={"dataset_name": dataset_name}, timeout=300, proxies=request_proxies)

        if response.status_code == 200:
            result = response.json()
            st.session_state.logs.append(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")

            # ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°ã«è¿½åŠ 
            if "stdout" in result and result["stdout"]:
                st.session_state.logs.append(f"ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©³ç´°:\n{result['stdout']}")
            if "stderr" in result and result["stderr"]:
                st.session_state.logs.append(f"âš ï¸ è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{result['stderr']}")

            return True
        else:
            # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
            try:
                error_detail = response.json()
                if "detail" in error_detail:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{error_detail['detail']}")
                else:
                    st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {response.text}")
            except:
                st.session_state.logs.append(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")

            log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", Exception(f"HTTP {response.status_code}"), response)
            return False

    except requests.exceptions.ConnectionError as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.Timeout as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except requests.exceptions.RequestException as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False
    except Exception as e:
        log_detailed_error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", e)
        return False

# --- é€²æ—å–å¾—é–¢æ•° ---
def get_training_progress():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰å­¦ç¿’é€²æ—ã‚’å–å¾—"""
    try:
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/progress", timeout=5, proxies=request_proxies)

        if response.status_code == 200:
            progress_data = response.json()
            return progress_data
        elif response.status_code == 404:
            # 404ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§
            st.session_state.logs.append(f"âš ï¸ é€²æ—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {response.status_code}")
            return None
        else:
            st.session_state.logs.append(f"âš ï¸ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
            return None
    except requests.exceptions.ConnectionError as e:
        # ä¸€æ™‚çš„ãªæ¥ç¶šã‚¨ãƒ©ãƒ¼ã§ã¯å­¦ç¿’çŠ¶æ…‹ã¯å¤‰æ›´ã—ãªã„
        st.session_state.logs.append(f"âŒ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except requests.exceptions.Timeout as e:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ãŒã€å­¦ç¿’çŠ¶æ…‹ã¯ç¶­æŒ
        st.session_state.logs.append(f"â° é€²æ—å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")
        return None
    except Exception as e:
        st.session_state.logs.append(f"âŒ é€²æ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_progress_from_backend():
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€²æ—ã‚’å–å¾—ã—ã¦æ›´æ–°"""
    # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯é€²æ—æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if st.session_state.consecutive_errors >= st.session_state.max_consecutive_errors:
        st.session_state.logs.append("âš ï¸ é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹ãŸã‚ã€é€²æ—æ›´æ–°ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã™")
        return False

    progress_data = get_training_progress()
    # ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
    import time
    st.session_state["last_poll_at"] = time.time()
    if progress_data:
        # é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        if "current_epoch" in progress_data and "current_step" in progress_data:
            st.session_state.current_epoch = progress_data.get("current_epoch", 0)
            st.session_state.current_step = progress_data.get("current_step", 0)
            st.session_state.total_epochs = progress_data.get("total_epochs", 0)
            st.session_state.total_steps = progress_data.get("total_steps", 0)
            st.session_state.current_progress = progress_data.get("progress", 0)
            st.session_state.progress_text = f"Epoch {progress_data['current_epoch']}/{progress_data.get('total_epochs', '?')}, Step {progress_data['current_step']}/{progress_data.get('total_steps', '?')}"

        # ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_loss" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.progress_df.empty:
                last_step = st.session_state.progress_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                        "epoch": progress_data.get("current_epoch", 0),
                        "step": current_step,
                        "loss": progress_data["current_loss"]
                    }
            else:
                st.session_state.progress_df.loc[len(st.session_state.progress_df)] = {
                    "epoch": progress_data.get("current_epoch", 0),
                    "step": current_step,
                    "loss": progress_data["current_loss"]
                }

        # å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
        if "current_learning_rate" in progress_data and progress_data.get("current_step", 0) > 0:
            current_step = progress_data.get("current_step", 0)
            # æ—¢ã«åŒã˜ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not st.session_state.lr_df.empty:
                last_step = st.session_state.lr_df.iloc[-1]["step"]
                if current_step > last_step:
                    st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                        "step": current_step,
                        "learning_rate": progress_data["current_learning_rate"]
                    }
            else:
                st.session_state.lr_df.loc[len(st.session_state.lr_df)] = {
                    "step": current_step,
                    "learning_rate": progress_data["current_learning_rate"]
                }

        # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
        if "latest_logs" in progress_data:
            for log in progress_data["latest_logs"]:
                if log not in st.session_state.logs:
                    st.session_state.logs.append(log)

        # æˆåŠŸæ™‚ã¯é€£ç¶šã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.consecutive_errors = 0
        return True
    else:
        st.session_state.consecutive_errors += 1
        return False

# --- ãƒ¢ãƒ‡ãƒ«ç®¡ç†æ©Ÿèƒ½ ---
def get_checkpoints(model_name: str = None, dataset_name: str = None):
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—"""
    try:
        params = {}
        if model_name:
            params["model_name"] = model_name
        if dataset_name:
            params["dataset_name"] = dataset_name

        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/checkpoints", params=params, timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            return response.json().get("checkpoints", [])
        else:
            st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {response.status_code}")
            return []
    except requests.exceptions.ConnectionError:
        st.error("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []
    except requests.exceptions.Timeout:
        st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        return []
    except Exception as e:
        st.error(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def get_models():
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.get(f"{BACKEND_URL}/models", timeout=10, proxies=request_proxies)

        if response.status_code == 200:
            return response.json().get("models", [])
        else:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {response.status_code}")
            return []
    except requests.exceptions.ConnectionError:
        st.error("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []
    except requests.exceptions.Timeout:
        st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
        return []
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def delete_model(model_name):
    """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤"""
    try:
        request_proxies = proxies if should_use_proxy(BACKEND_URL) else None
        response = requests.delete(f"{BACKEND_URL}/models/{model_name}", timeout=30, proxies=request_proxies)

        if response.status_code == 200:
            return True, "ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚"
        else:
            error_detail = response.json().get("detail", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            return False, f"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_detail}"
    except requests.exceptions.ConnectionError:
        return False, "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚"
    except requests.exceptions.Timeout:
        return False, "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return False, f"å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def format_file_size(size_mb):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’é©åˆ‡ãªå˜ä½ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if size_mb < 1:
        return f"{size_mb * 1024:.1f} KB"
    elif size_mb < 1024:
        return f"{size_mb:.1f} MB"
    else:
        return f"{size_mb / 1024:.1f} GB"

def format_timestamp(timestamp):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")

# --- UIæç”» ---
st.set_page_config(
    page_title="ASRå­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)
init_session_state()

if not st.session_state.initial_load:
    # åˆæœŸåŒ–æ™‚ã¯è¨­å®šã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
    get_config()
    get_status()
    st.session_state.initial_load = True
elif st.session_state.is_training:
    # å­¦ç¿’ä¸­ã®å ´åˆã®ã¿ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å†ç¢ºèªï¼ˆãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã®çŠ¶æ…‹å¾©å…ƒï¼‰
    import time
    current_time = time.time()
    if "last_status_check" not in st.session_state:
        st.session_state.last_status_check = 0

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã®é »åº¦ã‚’åˆ¶é™ï¼ˆ30ç§’ã”ã¨ï¼‰
    if current_time - st.session_state.last_status_check >= 30:
        get_status()
        st.session_state.last_status_check = current_time

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ASR å­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
st.markdown("---")
col_nav1, col_nav2, col_nav3 = st.columns(3)
with col_nav1:
    if st.button("ğŸ  ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", use_container_width=True, key="nav_main_top"):
        st.session_state.current_page = "main"
        st.rerun()
with col_nav2:
    if st.button("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç®¡ç†", use_container_width=True, key="nav_model_top"):
        st.session_state.current_page = "model_management"
        st.rerun()
with col_nav3:
    current_page = st.session_state.get("current_page", "main")
    if current_page == "main":
        page_name = "ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
    elif current_page == "model_management":
        page_name = "ãƒ¢ãƒ‡ãƒ«ç®¡ç†"
    elif current_page == "checkpoint_management":
        page_name = "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†"
    else:
        page_name = "ä¸æ˜"
    st.markdown(f"### ğŸ“Š ç¾åœ¨ã®ãƒšãƒ¼ã‚¸: {page_name}")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - å­¦ç¿’åˆ¶å¾¡
with st.sidebar:
    st.header("ğŸ“‹ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")

    # ãƒšãƒ¼ã‚¸é–“ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    current_page = st.session_state.get("current_page", "main")
    if st.button("ğŸ  ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", use_container_width=True, disabled=(current_page == "main"), key="nav_main_sidebar"):
        st.session_state.current_page = "main"
        st.rerun()
    if st.button("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç®¡ç†", use_container_width=True, disabled=(current_page == "model_management"), key="nav_model_sidebar"):
        st.session_state.current_page = "model_management"
        st.rerun()
    if st.button("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†", use_container_width=True, disabled=(current_page == "checkpoint_management"), key="nav_checkpoint_sidebar"):
        st.session_state.current_page = "checkpoint_management"
        st.rerun()

    st.markdown("---")
    st.header("ğŸ¯ å­¦ç¿’åˆ¶å¾¡")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    dataset_name = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
        st.session_state.available_datasets,
        index=0 if st.session_state.available_datasets else None
    )

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if st.button("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", disabled=st.session_state.is_training):
        if dataset_name:
            with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                success = download_dataset(dataset_name)
                if success:
                    st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    # è¨­å®šã‚’å†å–å¾—ã—ã¦æœ€æ–°ã®çŠ¶æ…‹ã‚’åæ˜ 
                    get_config()
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    # å­¦ç¿’ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    training_model_name = st.selectbox(
        "å­¦ç¿’ç”¨ãƒ¢ãƒ‡ãƒ«",
        st.session_state.available_models,
        index=0 if st.session_state.available_models else None,
        key="training_model_selector"
    )

    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epochs = st.number_input("ã‚¨ãƒãƒƒã‚¯æ•°", min_value=1, value=10)
    batch_size = st.number_input("ãƒãƒƒãƒã‚µã‚¤ã‚º", min_value=1, value=4)
    lightweight = st.checkbox("è»½é‡(å…ˆé ­10ä»¶)ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", value=True)
    limit_samples = st.number_input("ä½¿ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ (0ã§ç„¡åŠ¹)", min_value=0, value=0)

    # å­¦ç¿’å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ”„ å­¦ç¿’å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    resume_from_checkpoint = st.checkbox("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹", value=True, help="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã€è‡ªå‹•çš„ã«å†é–‹ã—ã¾ã™")

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠ
    specific_checkpoint = None
    if resume_from_checkpoint and training_model_name and dataset_name:
        checkpoints = get_checkpoints(training_model_name, dataset_name)
        if checkpoints:
            checkpoint_options = ["æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹"] + [f"{cp['name']} (Epoch {cp['epoch']})" for cp in checkpoints]
            selected_checkpoint = st.selectbox(
                "å†é–‹ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ",
                checkpoint_options,
                help="ç‰¹å®šã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã™ã‚‹å ´åˆã¯é¸æŠã—ã¦ãã ã•ã„"
            )
            if selected_checkpoint != "æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹":
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆåã‚’æŠ½å‡º
                for cp in checkpoints:
                    if f"{cp['name']} (Epoch {cp['epoch']})" == selected_checkpoint:
                        specific_checkpoint = cp['name']
                        break
        else:
            st.info("åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

    # å­¦ç¿’åˆ¶å¾¡ãƒœã‚¿ãƒ³
    st.subheader("ğŸ® å­¦ç¿’åˆ¶å¾¡")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ†• æ–°è¦å­¦ç¿’é–‹å§‹", disabled=st.session_state.is_training, help="æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™"):
            if training_model_name and dataset_name:
                success = start_training(training_model_name, dataset_name, epochs, batch_size,
                                       lightweight=lightweight, limit_samples=limit_samples,
                                       resume_from_checkpoint=False)
                if not success:
                    st.error("å­¦ç¿’ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    with col2:
        if st.button("ğŸ”„ å­¦ç¿’å†é–‹", disabled=st.session_state.is_training, help="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã‚’å†é–‹ã—ã¾ã™"):
            if training_model_name and dataset_name:
                if resume_from_checkpoint:
                    success = resume_training(training_model_name, dataset_name, epochs, batch_size,
                                            specific_checkpoint=specific_checkpoint,
                                            lightweight=lightweight, limit_samples=limit_samples)
                else:
                    success = start_training(training_model_name, dataset_name, epochs, batch_size,
                                           lightweight=lightweight, limit_samples=limit_samples,
                                           resume_from_checkpoint=True, specific_checkpoint=specific_checkpoint)
                if not success:
                    st.error("å­¦ç¿’ã®å†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")

    with col3:
        if st.button("ğŸ›‘ å­¦ç¿’åœæ­¢", disabled=not st.session_state.is_training, help="ç¾åœ¨ã®å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã™"):
            stop_training()

    # é€²æ—è¡¨ç¤º
    if st.session_state.is_training:
        st.progress(st.session_state.current_progress)
        st.text(st.session_state.progress_text)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
current_page = st.session_state.get("current_page", "main")
if current_page == "main":
    col1, col2 = st.columns(2)

    # æ¨è«–ãƒ†ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰")

    # æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ“‹ æ¨è«–è¨­å®š")
    col_model_select, col_model_info = st.columns([1, 2])

    with col_model_select:
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        available_models = st.session_state.available_models
        if available_models:
            selected_inference_model = st.selectbox(
                "æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«:",
                available_models,
                index=0,
                key="inference_model_selector",
                help="æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        else:
            st.warning("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            selected_inference_model = None

    with col_model_info:
        if selected_inference_model:
            st.info(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{selected_inference_model}**")
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«–å®Ÿè¡Œ
    st.subheader("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    inf_col1, inf_col2 = st.columns([2, 1])

    with inf_col1:
        uploaded = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (WAV/FLAC/MP3/M4A/OGG)",
            type=["wav", "flac", "mp3", "m4a", "ogg"],
            key="inference_file_uploader",
            help="æ¨è«–å¯¾è±¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        if uploaded is not None:
            st.audio(uploaded, format="audio/wav")
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {uploaded.name}")

    with inf_col2:
        st.subheader("ğŸš€ æ¨è«–å®Ÿè¡Œ")
        inference_disabled = uploaded is None or selected_inference_model is None
        if st.button(
            "æ¨è«–ã‚’å®Ÿè¡Œ",
            disabled=inference_disabled,
            type="primary",
            key="inference_execute_button",
            use_container_width=True
        ):
            if uploaded is None:
                st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            elif selected_inference_model is None:
                st.warning("æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else:
                with st.spinner("æ¨è«–ã‚’å®Ÿè¡Œä¸­..."):
                    result = run_inference(uploaded.getvalue(), uploaded.name, selected_inference_model)
                    transcription = result.get("transcription", "")
                    first_token_ms = result.get("first_token_time_ms")
                    inference_ms = result.get("inference_time_ms")
                    total_ms = result.get("total_time_ms")

                    # æ¨è«–ãŒå®Œäº†ã—ãŸå ´åˆï¼ˆç©ºã®çµæœã‚‚å«ã‚€ï¼‰
                    st.success("æ¨è«–å®Œäº†")

                    # ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                    st.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: **{selected_inference_model}**")

                    # 3ç¨®é¡ã®æ™‚é–“ã‚’è¡¨ç¤º
                    st.subheader("â±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±")
                    col_time1, col_time2, col_time3 = st.columns(3)
                    with col_time1:
                        if first_token_ms is not None:
                            st.metric(label="æœ€åˆã®å‡ºåŠ›ã¾ã§", value=f"{first_token_ms:.0f} ms")
                    with col_time2:
                        if inference_ms is not None:
                            st.metric(label="æ¨è«–æ™‚é–“", value=f"{inference_ms:.0f} ms")
                    with col_time3:
                        if total_ms is not None:
                            st.metric(label="ç·æ™‚é–“", value=f"{total_ms:.0f} ms")

                    # æ–‡å­—èµ·ã“ã—çµæœ
                    st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
                    if transcription:
                        # æ­£å¸¸ãªæ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚‹å ´åˆ
                        st.text_area(
                            "æ–‡å­—èµ·ã“ã—çµæœ",
                            value=transcription,
                            height=120,
                            key="inference_result_text",
                            help="éŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™"
                        )

                        # çµæœã®ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³
                        if st.button("ğŸ“‹ çµæœã‚’ã‚³ãƒ”ãƒ¼", key="copy_result_button"):
                            st.write("çµæœã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼ˆæ‰‹å‹•ã§ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ï¼‰")
                    else:
                        # ç©ºã®æ¨è«–çµæœã®å ´åˆ
                        st.warning("âš ï¸ æ¨è«–çµæœãŒç©ºã§ã™")
                        st.text_area(
                            "æ–‡å­—èµ·ã“ã—çµæœ",
                            value="ï¼ˆéŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ï¼‰",
                            height=120,
                            key="inference_result_text_empty",
                            help="éŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°ã®å“è³ªã‚„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                        )
                        st.info("ğŸ’¡ **æ¨å¥¨äº‹é …**: éŸ³å£°ã®å“è³ªã‚’ç¢ºèªã™ã‚‹ã‹ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")

    # ä¸Šéƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆå­¦ç¿’ä¸­ã®ã¿ï¼‰
    if st.session_state.is_training:
        m1, m2, m3 = st.columns(3)
        with m1:
            st.metric(label="Epoch", value=f"{st.session_state.current_epoch}/{st.session_state.total_epochs}")
        with m2:
            st.metric(label="Step", value=f"{st.session_state.current_step}/{st.session_state.total_steps}")
        with m3:
            # å­¦ç¿’å†é–‹æƒ…å ±ã‚’è¡¨ç¤º
            if "resume_info" in st.session_state:
                st.metric(label="å†é–‹å…ƒ", value=st.session_state.resume_info)
            else:
                st.metric(label="å­¦ç¿’çŠ¶æ…‹", value="å®Ÿè¡Œä¸­")

    with col1:
        st.header("å­¦ç¿’ãƒ­ã‚¹")
        if not st.session_state.progress_df.empty:
            loss_data = st.session_state.progress_df.rename(columns={"loss": "train_loss"})
            if not st.session_state.validation_df.empty:
                # ã‚¨ãƒãƒƒã‚¯ã®æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã«æ¤œè¨¼ãƒ­ã‚¹ã‚’ç´ä»˜ã‘ã‚‹
                last_step_per_epoch = loss_data.groupby("epoch")["step"].max().reset_index()
                merged_val = pd.merge(st.session_state.validation_df, last_step_per_epoch, on="epoch")
                loss_data = pd.merge(loss_data, merged_val, on=["epoch", "step"], how="left")

            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’æç”»å¯¾è±¡ã«ã™ã‚‹
            plot_cols = [c for c in ["train_loss", "val_loss"] if c in loss_data.columns]
            st.line_chart(loss_data.set_index("step")[plot_cols])
        else:
            st.info("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    with col2:
        st.header("å­¦ç¿’ç‡")
        if not st.session_state.lr_df.empty:
            st.line_chart(st.session_state.lr_df.set_index("step")["learning_rate"])
        else:
            st.info("å­¦ç¿’ç‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    # ãƒ­ã‚°è¡¨ç¤º
    st.header("ãƒ­ã‚°")
    log_container = st.container()
    with log_container:
        for log in st.session_state.logs[-50:]:  # æœ€æ–°50ä»¶ã‚’è¡¨ç¤º
            st.text(log)

# å­¦ç¿’ä¸­ã®é€²æ—æ›´æ–°
# Note: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ä¸­ã¾ãŸã¯å®Ÿè¡Œä¸­ã¯è‡ªå‹•ãƒãƒ¼ãƒªãƒ³ã‚°ã‚’åœæ­¢ï¼ˆWebRTCã®å®‰å®šæ€§ã®ãŸã‚ï¼‰
if st.session_state.is_training and not st.session_state.get("realtime_running", False) and not st.session_state.get("_should_start_realtime", False):
    # ç›´è¿‘ã®ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚åˆ»ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°/å¯è¦–åŒ–ï¼‰
    import time
    last_polled = st.session_state.get("last_poll_at")
    if last_polled:
        st.caption(f"æœ€çµ‚ãƒãƒ¼ãƒªãƒ³ã‚°: {time.strftime('%H:%M:%S', time.localtime(last_polled))}")
    # é€²æ—æ›´æ–°ã®é »åº¦ã‚’åˆ¶é™ï¼ˆ1ç§’ã”ã¨ï¼‰
    import time
    current_time = time.time()
    if "last_progress_update" not in st.session_state:
        st.session_state.last_progress_update = 0

    # é€²æ—æ›´æ–°ã®å®Ÿè¡Œ
    progress_updated = False
    if current_time - st.session_state.last_progress_update >= 1:
        progress_updated = update_progress_from_backend()
        st.session_state.last_progress_update = current_time

    # ç¢ºå®Ÿãª1ç§’ã”ã¨ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¹ãƒªãƒ¼ãƒ—â†’å†å®Ÿè¡Œï¼‰
    # Note: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã¯è‡ªå‹•ãƒãƒ¼ãƒªãƒ³ã‚°ã‚’åœæ­¢ï¼ˆWebRTCã®å®‰å®šæ€§ã®ãŸã‚ï¼‰
    time.sleep(1)
    st.rerun()

# --- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ï¼‰ ---
if current_page == "main":
    st.header("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ï¼‰")

class MicAudioProcessor(AudioProcessorBase):
    def __init__(self) -> None:
        self.frame_queue = None  # type: queue.Queue
        self.logger = logging.getLogger("ui-rt")
        self.msg_queue = None  # optional queue to report stats
        self._frames_sent = 0

        self.logger.info("MicAudioProcessor initialized",
                        extra={"extra_fields": {"component": "audio_processor", "action": "init"}})

    def recv_audio(self, frames, **kwargs):
        # frames: list of av.AudioFrame
        self.logger.debug("Audio frames received",
                         extra={"extra_fields": {"component": "audio_processor", "action": "frames_received",
                                               "frame_count": len(frames), "has_queue": self.frame_queue is not None}})

        if self.frame_queue is None:
            self.logger.debug("Frame queue is None, returning frames without processing",
                             extra={"extra_fields": {"component": "audio_processor", "action": "no_queue"}})
            return frames

        for frame in frames:
            # 32-bit float PCM, shape: (channels, samples)
            pcm = frame.to_ndarray(format="flt")

            # ãƒ¢ãƒãƒ©ãƒ«åŒ–
            if pcm.ndim == 2 and pcm.shape[0] > 1:
                pcm_mono = pcm.mean(axis=0)
            else:
                pcm_mono = pcm[0] if pcm.ndim == 2 else pcm

            # é€ä¿¡ã¯ float32 little-endian bytesï¼ˆã‚µãƒ¼ãƒã¯ f32 ã‚’ã‚µãƒãƒ¼ãƒˆï¼‰
            pcm_f32 = pcm_mono.astype(np.float32)

            try:
                self.frame_queue.put(pcm_f32.tobytes(), timeout=0.1)
                self._frames_sent += 1

                # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰

                if self.msg_queue and (self._frames_sent % 25 == 0):
                    # ãŠãŠã‚ˆãå®šæœŸçš„ã«çµ±è¨ˆã‚’é€ã‚‹
                    self.msg_queue.put({"type": "stats", "payload": {"frames_sent": self._frames_sent}})
            except queue.Full:
                self.logger.warning("Frame queue is full, dropping audio chunk",
                                  extra={"extra_fields": {"component": "audio_processor", "action": "queue_full"}})
        return frames

async def stream_audio_to_ws(q: "queue.Queue[bytes]", model_name: str, sample_rate: int, running_event: threading.Event, msg_queue_ref=None):
    import websockets
    logger = logging.getLogger("websocket_sender")

    # æ¥ç¶šãƒªãƒˆãƒ©ã‚¤ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã‚’æ­£ã—ãä½¿ç”¨ï¼‰
    retries = 0
    while True:
        try:
            async with websockets.connect(
                WEBSOCKET_URL,
                ping_interval=30,
                ping_timeout=30,
                open_timeout=10,
                close_timeout=10,
            ) as ws:
                # æ¥ç¶šé–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
                start_msg = {"type": "start", "model_name": model_name, "sample_rate": sample_rate, "format": "f32"}
                await ws.send(json.dumps(start_msg))

                logger.info("WebSocket start message sent",
                           extra={"extra_fields": {"component": "websocket", "action": "start_sent",
                                                 "model_name": model_name, "sample_rate": sample_rate}})

                # å—ä¿¡ã‚¿ã‚¹ã‚¯
                async def receiver():
                    try:
                        while True:
                            msg = await ws.recv()
                            try:
                                data = json.loads(msg)
                                logger.debug("WebSocket message received",
                                           extra={"extra_fields": {"component": "websocket", "action": "message_received",
                                                                 "message_type": data.get("type")}})
                                # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‡¦ç†ã™ã‚‹ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€
                                try:
                                    if msg_queue_ref is not None:
                                        msg_queue_ref.put(data)
                                except Exception:
                                    pass
                            except Exception as e:
                                logger.error("Error parsing WebSocket message",
                                           extra={"extra_fields": {"component": "websocket", "action": "parse_error",
                                                                 "error": str(e), "message": msg}})
                                try:
                                    if msg_queue_ref is not None:
                                        msg_queue_ref.put({"type": "error", "payload": {"message": f"invalid message: {msg}"}})
                                except Exception:
                                    pass
                                pass
                    except Exception as e:
                        logger.error("WebSocket receiver error",
                                   extra={"extra_fields": {"component": "websocket", "action": "receiver_error",
                                                         "error": str(e)}})
                        return

                recv_task = asyncio.create_task(receiver())

                try:
                    while running_event.is_set():
                        try:
                            chunk = q.get(timeout=0.1)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ç¸®
                            # éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
                            await ws.send(chunk)
                            # éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡å®Œäº†ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
                            # é€ä¿¡ã‚«ã‚¦ãƒ³ã‚¿ã®UIæ›´æ–°ã¯ã‚¹ãƒ¬ãƒƒãƒ‰å¤–ã§å®Ÿæ–½ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ãƒ­ã‚°ã®ã¿
                        except queue.Empty:
                            # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆæ™‚ã‚‚æ¥ç¶šç¶­æŒ
                            await asyncio.sleep(0.01)  # å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ç¸®
                            continue
                        except Exception as e:
                            logger.error("Error sending audio chunk",
                                       extra={"extra_fields": {"component": "websocket", "action": "chunk_send_error",
                                                             "error": str(e)}})
                            break
                except asyncio.CancelledError:
                    pass
                finally:
                    try:
                        await ws.send(json.dumps({"type": "stop"}))
                        logger.info("WebSocket stop message sent",
                                   extra={"extra_fields": {"component": "websocket", "action": "stop_sent"}})
                    except Exception:
                        pass
                    recv_task.cancel()
                    with contextlib.suppress(Exception):
                        await recv_task
                return
        except Exception as e:
            retries += 1
            logger.error("WebSocket connection error",
                        extra={"extra_fields": {"component": "websocket", "action": "connection_error",
                                              "retry_count": retries, "error": str(e)}})
            try:
                if msg_queue_ref is not None:
                    msg_queue_ref.put({"type": "error", "payload": {"message": f"ws session error (retry {retries}): {e}"}})
            except Exception:
                pass
            if retries >= 5:
                logger.error("Max retries reached, giving up",
                            extra={"extra_fields": {"component": "websocket", "action": "max_retries_reached"}})
                return
            await asyncio.sleep(min(1.0 * retries, 5.0))

import contextlib

st.session_state.setdefault("realtime_running", False)
st.session_state.setdefault("realtime_partial", "")
st.session_state.setdefault("realtime_final", "")
st.session_state.setdefault("realtime_status", {})
st.session_state.setdefault("realtime_error", "")
st.session_state.setdefault("realtime_msg_queue", queue.Queue())

col_rt1, col_rt2 = st.columns([2, 1])
with col_rt1:
    # WebRTCè¨­å®š - ICEæ¥ç¶šã®å®‰å®šæ€§ã‚’å‘ä¸Š
    rtc_configuration = {
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},  # Google STUN server
        ],
        "iceTransportPolicy": "all",  # ã™ã¹ã¦ã®ICEå€™è£œã‚’ä½¿ç”¨
    }

    # CRITICAL: Cache the webrtc context in session state to avoid recreating it
    # Recreating webrtc_streamer on every rerun closes the ICE connection
    if "_rtc_ctx" not in st.session_state or not st.session_state.get("realtime_running", False):
        # Only create/update webrtc_streamer when NOT actively streaming
        rtc_ctx = webrtc_streamer(
            key="asr-audio",
            mode=WebRtcMode.SENDONLY,
            audio_receiver_size=2048,
            media_stream_constraints={"audio": True, "video": False},
            async_processing=True,
            rtc_configuration=rtc_configuration,  # ICEè¨­å®šã‚’è¿½åŠ 
        )
        st.session_state["_rtc_ctx"] = rtc_ctx
    else:
        # During streaming, reuse the cached context - DON'T call webrtc_streamer again!
        rtc_ctx = st.session_state["_rtc_ctx"]

with col_rt2:
    st.subheader("ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–è¨­å®š")

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    if st.session_state.available_models:
        selected_realtime_model = st.selectbox(
            "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ãƒ¢ãƒ‡ãƒ«",
            st.session_state.available_models,
            index=0,
            key="realtime_model_selector",
            help="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        st.info(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{selected_realtime_model}**")
    else:
        st.warning("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        selected_realtime_model = None

    # éŸ³å£°è¨­å®š
    st.subheader("ğŸ”Š éŸ³å£°è¨­å®š")
    sample_rate = st.number_input(
        "é€ä¿¡ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ",
        min_value=16000,
        max_value=48000,
        value=48000,
        step=1000,
        key="realtime_sample_rate",
        help="ãƒã‚¤ã‚¯ã‹ã‚‰é€ä¿¡ã™ã‚‹éŸ³å£°ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ"
    )

    # åˆ¶å¾¡ãƒœã‚¿ãƒ³
    st.subheader("ğŸ® åˆ¶å¾¡")

    # ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹ã«ã™ã‚‹æ¡ä»¶ã‚’ã‚ˆã‚Šå³å¯†ã«
    can_start = (
        not st.session_state.get("realtime_running", False) and
        rtc_ctx.state.playing and
        rtc_ctx.audio_receiver is not None and
        selected_realtime_model is not None
    )

    start_btn = st.button(
        "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é–‹å§‹",
        disabled=not can_start,
        key="realtime_start_button",
        use_container_width=True,
        help="ãƒã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ã‹ã‚‰ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„"
    )
    stop_btn = st.button(
        "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åœæ­¢",
        disabled=not st.session_state.get("realtime_running", False),
        key="realtime_stop_button",
        use_container_width=True
    )

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
    with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
        st.write(f"- start_btn: {start_btn}")
        st.write(f"- rtc_ctx: {rtc_ctx is not None}")
        st.write(f"- rtc_ctx.state.playing: {rtc_ctx.state.playing if rtc_ctx else 'N/A'}")
        st.write(f"- rtc_ctx.audio_receiver: {rtc_ctx.audio_receiver is not None if rtc_ctx else 'N/A'}")
        st.write(f"- realtime_running: {st.session_state.get('realtime_running', False)}")

    # é‡è¦ãªæ³¨æ„äº‹é …ã‚’è¡¨ç¤º
    if not st.session_state.get('realtime_running', False):
        if rtc_ctx.state.playing:
            st.success("âœ… ãƒã‚¤ã‚¯ãŒæœ‰åŠ¹ã§ã™ã€‚'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é–‹å§‹'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            st.info("ğŸ’¡ **é‡è¦:** ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«ç´„15ç§’ã‹ã‹ã‚Šã¾ã™ã€‚ãã®é–“ãƒã‚¤ã‚¯ã‚’ONã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.warning("âš ï¸ å…ˆã«ä¸Šã®'START'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚")

    # æ—¢ã«å®Ÿè¡Œä¸­ã®å ´åˆã®è­¦å‘Šã¨è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
    if st.session_state.get('realtime_running', False):
        if not rtc_ctx.state.playing:
            st.error("âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã«WebRTCãŒåœæ­¢ã—ã¾ã—ãŸã€‚è‡ªå‹•çš„ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™...")
            # è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
            st.session_state["realtime_running"] = False
            # Clear the running event to stop threads
            running_event = st.session_state.get("_running_event")
            if running_event:
                running_event.clear()
            st.info("ğŸ’¡ 'START'ãƒœã‚¿ãƒ³ã‚’ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‹ã‚‰ã€'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é–‹å§‹'ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            st.rerun()

    if start_btn:
        if not rtc_ctx:
            st.error("âŒ WebRTCã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        elif not rtc_ctx.state.playing:
            st.error("âŒ ãƒã‚¤ã‚¯ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã›ã‚“ã€‚ä¸Šã®'START'ãƒœã‚¿ãƒ³ã‚’å…ˆã«ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
        elif not rtc_ctx.audio_receiver:
            st.error("âŒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ã‚·ãƒ¼ãƒãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
        elif st.session_state.get("realtime_running", False):
            st.warning("âš ï¸ ã™ã§ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã§ã™ã€‚")
        else:
            # START THREADS IMMEDIATELY - don't defer to next rerun!
            # é€ä¿¡ã‚­ãƒ¥ãƒ¼ã¨ã‚¹ãƒ¬ãƒƒãƒ‰/ã‚¿ã‚¹ã‚¯ã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’å¤§å¹…ã«å¢—åŠ ï¼‰
            send_queue = queue.Queue(maxsize=1000)
            # å…ˆã«ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ•ãƒ©ã‚°ã¨ã‚«ã‚¦ãƒ³ã‚¿ã‚’ç«‹ã¦ã¦ã‹ã‚‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
            st.session_state["realtime_running"] = True
            st.session_state["_rt_chunks_sent"] = 0
            st.session_state["_model_loading_start_time"] = __import__('time').time()
            # æ—¢å­˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state["realtime_error"] = ""
            st.session_state["realtime_partial"] = ""
            st.session_state["realtime_final"] = ""

            # ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§å…±æœ‰ã™ã‚‹ãŸã‚ã®ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°
            msg_queue = st.session_state["realtime_msg_queue"]
            # threading.Eventã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§runningçŠ¶æ…‹ã‚’å…±æœ‰
            running_event = threading.Event()
            running_event.set()  # Start as running
            st.session_state["_running_event"] = running_event

            # audio_receiverã‹ã‚‰ç›´æ¥ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰
            def pull_audio_frames():
                import time as _time
                import logging
                import sys
                frames_sent = 0

                # ãƒ­ã‚°è¨­å®š
                logging.basicConfig(level=logging.INFO, stream=sys.stderr, force=True)
                logger = logging.getLogger("audio_puller")

                # Force flush to stderr
                sys.stderr.write("[FRONTEND] ğŸ™ï¸ Audio puller thread started!\n")
                sys.stderr.write(f"[FRONTEND] WebRTC state: {rtc_ctx.state if rtc_ctx else 'No context'}\n")
                sys.stderr.write(f"[FRONTEND] Has receiver: {rtc_ctx.audio_receiver is not None if rtc_ctx else False}\n")
                sys.stderr.write(f"[FRONTEND] Running event is set: {running_event.is_set()}\n")
                sys.stderr.flush()

                logger.info("Starting audio puller thread",
                           extra={"extra_fields": {"component": "audio_puller", "action": "thread_start"}})
                logger.info("Audio puller context info",
                           extra={"extra_fields": {"component": "audio_puller", "action": "context_info",
                                                 "rtc_state": str(rtc_ctx.state), "has_receiver": rtc_ctx.audio_receiver is not None}})

                consecutive_errors = 0
                max_consecutive_errors = 50  # 50å›é€£ç¶šã‚¨ãƒ©ãƒ¼ã§åœæ­¢
                loop_count = 0

                sys.stderr.write("[FRONTEND] ğŸ”„ Entering while loop...\n")
                sys.stderr.flush()

                while running_event.is_set():
                    if loop_count == 0:  # First iteration
                        sys.stderr.write(f"[FRONTEND] ğŸ”„ First loop iteration! rtc_ctx.state.playing = {rtc_ctx.state.playing}\n")
                        sys.stderr.flush()

                    loop_count += 1
                    if loop_count % 100 == 0:  # Every 100 iterations
                        sys.stderr.write(f"[FRONTEND] Audio puller loop iteration {loop_count}\n")
                        sys.stderr.flush()

                    # WebRTCæ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                    if not rtc_ctx.state.playing:
                        sys.stderr.write(f"[FRONTEND] âŒ WebRTC NOT playing! Stopping puller. (iteration {loop_count})\n")
                        sys.stderr.flush()
                        logger.warning("WebRTC connection lost (not playing), stopping puller",
                                     extra={"extra_fields": {"component": "audio_puller", "action": "connection_lost"}})
                        if msg_queue:
                            try:
                                msg_queue.put({"type": "error", "payload": {"message": "WebRTCæ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ"}})
                            except Exception:
                                pass
                        break

                    if rtc_ctx.audio_receiver:
                        try:
                            # streamlit-webrtcã®æ­£ã—ã„ä½¿ç”¨æ–¹æ³•ã«ä¿®æ­£
                            frames = []
                            try:
                                # streamlit-webrtcã§ã¯å¼•æ•°ãªã—ã§get_frames()ã‚’å‘¼ã³å‡ºã™
                                frames = rtc_ctx.audio_receiver.get_frames()
                                if frames:
                                    sys.stderr.write(f"[FRONTEND] ğŸ¤ Got {len(frames)} frames from WebRTC!\n")
                                    sys.stderr.flush()
                                    logger.info(f"ğŸ¤ Got {len(frames)} audio frames from WebRTC",
                                              extra={"extra_fields": {"component": "audio_puller", "action": "frames_received",
                                                                    "frame_count": len(frames)}})
                                elif loop_count % 500 == 0:  # Log every 500 empty iterations
                                    sys.stderr.write(f"[FRONTEND] âš ï¸ get_frames() returned empty (iteration {loop_count})\n")
                                    sys.stderr.flush()
                            except Exception as get_frames_error:
                                # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã¦ã€é »ç¹ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æŠ‘åˆ¶
                                logger.debug("get_frames() failed, trying alternative approach",
                                             extra={"extra_fields": {"component": "audio_puller", "action": "get_frames_alternative",
                                                                   "error": str(get_frames_error), "error_type": type(get_frames_error).__name__}})
                                # ä»£æ›¿æ–¹æ³•: å¼•æ•°ãªã—ã§å†è©¦è¡Œ
                                try:
                                    frames = rtc_ctx.audio_receiver.get_frames()
                                except Exception as alt_error:
                                    logger.debug("Alternative frame getting failed",
                                               extra={"extra_fields": {"component": "audio_puller", "action": "alt_get_frames_error",
                                                                     "error": str(alt_error), "error_type": type(alt_error).__name__}})
                                    _time.sleep(0.1)
                                    continue
                            if frames:
                                # ãƒ•ãƒ¬ãƒ¼ãƒ å—ä¿¡ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰

                                for frame in frames:
                                    try:
                                        pcm = frame.to_ndarray(format="flt")

                                        if pcm.ndim == 2 and pcm.shape[0] > 1:
                                            pcm_mono = pcm.mean(axis=0)
                                        else:
                                            pcm_mono = pcm[0] if pcm.ndim == 2 else pcm

                                        pcm_f32 = pcm_mono.astype(np.float32)

                                        # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
                                        # ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€æº€æ¯ã®å ´åˆã¯å¤ã„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ‰ãƒ­ãƒƒãƒ—
                                        if send_queue.qsize() > 800:  # 80%ä»¥ä¸Šã®å ´åˆ
                                            try:
                                                send_queue.get_nowait()  # å¤ã„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’1ã¤å‰Šé™¤
                                                # å¤ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‰ãƒ­ãƒƒãƒ—ï¼ˆãƒ­ã‚°å‰Šé™¤ï¼‰
                                            except queue.Empty:
                                                pass

                                        # é€ä¿¡ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€ï¼ˆæº€æ¯æ™‚ã¯ä¾‹å¤–å‡¦ç†ï¼‰
                                        try:
                                            send_queue.put(pcm_f32.tobytes(), timeout=0.05)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ç¸®
                                            frames_sent += 1
                                            consecutive_errors = 0  # æˆåŠŸã—ãŸã‚‰ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆ
                                        except queue.Full:
                                            logger.warning("Send queue is full, dropping frame",
                                                         extra={"extra_fields": {"component": "audio_puller", "action": "queue_full",
                                                                               "queue_size": send_queue.qsize()}})
                                            consecutive_errors += 1

                                        # çµ±è¨ˆæƒ…å ±ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
                                        try:
                                            if msg_queue is not None:
                                                msg_queue.put({"type": "stats", "payload": {
                                                    "frames_sent": frames_sent,
                                                    "queue_size": send_queue.qsize(),
                                                    "queue_capacity": send_queue.maxsize
                                                }})
                                        except Exception:
                                            pass
                                    except Exception as e:
                                        consecutive_errors += 1
                                        logger.debug("Error processing audio frame",
                                                   extra={"extra_fields": {"component": "audio_puller", "action": "frame_error",
                                                                         "error": str(e), "consecutive_errors": consecutive_errors}})

                                        # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯åœæ­¢
                                        if consecutive_errors >= max_consecutive_errors:
                                            logger.error("Too many consecutive errors, stopping puller",
                                                       extra={"extra_fields": {"component": "audio_puller", "action": "error_threshold",
                                                                             "consecutive_errors": consecutive_errors}})
                                            if msg_queue:
                                                try:
                                                    msg_queue.put({"type": "error", "payload": {"message": "éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒå¤šç™ºã—ã¦ã„ã¾ã™"}})
                                                except Exception:
                                                    pass
                                            break
                                        continue
                            else:
                                # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå–å¾—ã§ããªã„å ´åˆã¯çŸ­ã„é–“éš”ã§å¾…æ©Ÿ
                                _time.sleep(0.02)  # å¾…æ©Ÿæ™‚é–“ã‚’å°‘ã—é•·ãã—ã¦è² è·è»½æ¸›
                        except Exception as e:
                            # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã¦ã€é »ç¹ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æŠ‘åˆ¶
                            logger.debug("Error getting frames from audio_receiver",
                                       extra={"extra_fields": {"component": "audio_puller", "action": "get_frames_error",
                                                             "error": str(e), "error_type": type(e).__name__, "traceback": traceback.format_exc()}})
                            _time.sleep(0.1)
                    else:
                        logger.debug("No audio_receiver available, waiting",
                                   extra={"extra_fields": {"component": "audio_puller", "action": "no_receiver"}})
                        _time.sleep(0.05)

            # WebSocket sender thread - use asyncio.run() instead of managing event loop manually
            def run_websocket_sender():
                import logging
                logger = logging.getLogger("websocket_loop")

                try:
                    logger.info("Starting WebSocket loop",
                               extra={"extra_fields": {"component": "websocket_loop", "action": "loop_start",
                                                     "model": selected_realtime_model or "conformer", "sample_rate": int(sample_rate)}})
                    # Use asyncio.run() which properly manages the event loop
                    asyncio.run(stream_audio_to_ws(send_queue, selected_realtime_model or "conformer", int(sample_rate), running_event, msg_queue))
                except Exception as e:
                    logger.error("WebSocket loop error",
                               extra={"extra_fields": {"component": "websocket_loop", "action": "loop_error",
                                                     "error": str(e), "traceback": traceback.format_exc()}})

            # Start threads WITHOUT triggering Streamlit reruns (no st.write after starting threads!)
            t = threading.Thread(target=run_websocket_sender, daemon=True)
            p = threading.Thread(target=pull_audio_frames, daemon=True)

            # Start both threads
            t.start()
            p.start()

            # Save to session state (note: we don't save 'loop' anymore since asyncio.run manages it)
            st.session_state["realtime_thread"] = t
            st.session_state["realtime_puller"] = p

            # Set a flag to indicate threads just started - DON'T check WebRTC state yet
            st.session_state["_threads_just_started"] = True

            # CRITICAL: After starting threads, rerun immediately to refresh UI
            # This prevents the status monitoring code below from running with stale rtc_ctx
            st.rerun()

    # Show streaming status
    if st.session_state.get("realtime_running", False):
        # Clear the "just started" flag after first status display
        if st.session_state.pop("_threads_just_started", False):
            # Threads just started - show status but DON'T check WebRTC state yet
            st.info("ğŸ™ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ã—ã¾ã—ãŸï¼ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            # Don't check rtc_ctx.state yet - it might be stale
        else:
            # Normal status monitoring
            st.info("ğŸ™ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œä¸­... è©±ã—ã¦ãã ã•ã„ï¼")

            # WebRTCæ¥ç¶šçŠ¶æ…‹ã‚’ç›£è¦– (only after threads have settled)
            if rtc_ctx and rtc_ctx.state:
                if not rtc_ctx.state.playing:
                    st.warning("âš ï¸ WebRTCæ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸã€‚STARTãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å†æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
                    # è‡ªå‹•çš„ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’åœæ­¢
                    if st.session_state.get("realtime_running"):
                        logger = logging.getLogger("ui-rt")
                        logger.warning("WebRTC disconnected, stopping streaming",
                                     extra={"extra_fields": {"component": "ui", "action": "webrtc_disconnect_stop"}})
                        st.session_state["realtime_running"] = False
                        # Clear the threading event
                        running_event = st.session_state.get("_running_event")
                        if running_event:
                            running_event.clear()
                        loop = st.session_state.get("realtime_loop")
                        if loop and loop.is_running():
                            loop.call_soon_threadsafe(loop.stop)
                elif rtc_ctx.audio_receiver is None:
                    st.warning("âš ï¸ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¬ã‚·ãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    elif st.session_state.get("_should_start_realtime", False):
        # Model loading phase - show progress
        if "_model_loading_start_time" in st.session_state:
            elapsed = __import__('time').time() - st.session_state["_model_loading_start_time"]
            progress = min(elapsed / 15.0, 1.0)  # 15 seconds expected

            st.progress(progress)
            st.info(f"â³ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­... {elapsed:.1f}ç§’ / ~15ç§’ ({progress*100:.0f}%)")
            st.warning("ğŸ’¡ **é‡è¦:** ãƒã‚¤ã‚¯ã‚’ONã®ã¾ã¾å¾…ã£ã¦ãã ã•ã„ï¼")

            # Check if WebRTC is still alive
            if not rtc_ctx.state.playing:
                st.error(f"âŒ ãƒã‚¤ã‚¯ãŒ {elapsed:.1f}ç§’å¾Œã«åˆ‡æ–­ã•ã‚Œã¾ã—ãŸï¼")
                st.info("ğŸ’¡ 'START'ãƒœã‚¿ãƒ³ã‚’ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒã‚¤ã‚¯ã‚’å†åº¦ONã«ã—ã¦ãã ã•ã„ã€‚")

    if stop_btn and st.session_state.get("realtime_running", False):
        # é€ä¿¡åœæ­¢: ã‚¹ãƒ¬ãƒƒãƒ‰ã¨ãƒ«ãƒ¼ãƒ—ã‚’åœæ­¢
        logger = logging.getLogger("ui-rt")
        logger.info("Stopping realtime streaming",
                   extra={"extra_fields": {"component": "ui", "action": "stop_streaming"}})

        st.session_state["realtime_running"] = False

        # Clear the threading event to stop threads
        running_event = st.session_state.get("_running_event")
        if running_event:
            running_event.clear()

        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®åœæ­¢ã‚’å¾…ã¤
        loop = st.session_state.get("realtime_loop")
        if loop and loop.is_running():
            loop.call_soon_threadsafe(loop.stop)

        # puller ã‚¹ãƒ¬ãƒƒãƒ‰ã¯ãƒ•ãƒ©ã‚°ã§åœæ­¢ã€‚è¿½åŠ ã®æ“ä½œã¯ä¸è¦ã€‚
        st.success("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
        st.info("ğŸ’¡ æœ€çµ‚çµæœãŒä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ãƒ‰ãƒ¬ã‚¤ãƒ³ã—ã€UIçŠ¶æ…‹ã‚’æ›´æ–°
while not st.session_state["realtime_msg_queue"].empty():
    try:
        data = st.session_state["realtime_msg_queue"].get_nowait()
    except Exception:
        break
    if data.get("type") == "partial":
        st.session_state["realtime_partial"] = data["payload"].get("text", "")
    elif data.get("type") == "final":
        st.session_state["realtime_final"] = data["payload"].get("text", "")
    elif data.get("type") == "status":
        st.session_state["realtime_status"] = data.get("payload", {})
    elif data.get("type") == "error":
        st.session_state["realtime_error"] = data.get("payload", {}).get("message", "error")
    elif data.get("type") == "stats":
        st.session_state["realtime_stats"] = data.get("payload", {})

st.text_area("éƒ¨åˆ†çµæœ", value=st.session_state.get("realtime_partial", ""), height=80)
st.text_area("æœ€çµ‚çµæœ", value=st.session_state.get("realtime_final", ""), height=80)

stats = st.session_state.get("realtime_stats", {})
if stats:
    col_s1, col_s2, col_s3 = st.columns(3)
    with col_s1:
        st.metric("frames_sent", value=f"{stats.get('frames_sent', 0)}")
    with col_s2:
        st.metric("chunks_sent", value=f"{stats.get('chunks_sent', st.session_state.get('_rt_chunks_sent', 0))}")
    with col_s3:
        # ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã®è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        queue_size = stats.get('queue_size', 0)
        queue_status = "ğŸŸ¢ Normal" if queue_size < 500 else "ğŸŸ¡ High" if queue_size < 800 else "ğŸ”´ Critical"
        st.metric("Queue Size", value=f"{queue_size}/1000", help=f"Status: {queue_status}")

    if st.session_state.get("realtime_error"):
        st.error(st.session_state.get("realtime_error"))

# --- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
current_page = st.session_state.get("current_page", "main")
if current_page == "checkpoint_management":
    st.markdown("---")
    st.header("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†")

    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€å­¦ç¿’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¸€è¦§è¡¨ç¤ºã¨ç®¡ç†ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯å­¦ç¿’ä¸­ã«è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã€å­¦ç¿’ã®å†é–‹ã«ä½¿ç”¨ã§ãã¾ã™ã€‚
    """)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    col_filter1, col_filter2 = st.columns(2)

    with col_filter1:
        filter_model = st.selectbox(
            "ãƒ¢ãƒ‡ãƒ«åã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["å…¨ã¦"] + st.session_state.available_models,
            key="checkpoint_filter_model"
        )

    with col_filter2:
        filter_dataset = st.selectbox(
            "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["å…¨ã¦"] + st.session_state.available_datasets,
            key="checkpoint_filter_dataset"
        )

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã®å–å¾—
    if st.button("ğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’æ›´æ–°", type="primary", key="refresh_checkpoints_main"):
        st.rerun()

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
    model_filter = filter_model if filter_model != "å…¨ã¦" else None
    dataset_filter = filter_dataset if filter_dataset != "å…¨ã¦" else None

    checkpoints = get_checkpoints(model_filter, dataset_filter)

    if not checkpoints:
        st.info("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"{len(checkpoints)}å€‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        st.subheader("ğŸ“‹ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        checkpoint_data = []
        for checkpoint in checkpoints:
            checkpoint_data.append({
                "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå": checkpoint["name"],
                "ãƒ¢ãƒ‡ãƒ«": checkpoint["model_name"],
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": checkpoint["dataset_name"],
                "ã‚¨ãƒãƒƒã‚¯": checkpoint["epoch"],
                "ã‚µã‚¤ã‚º": format_file_size(checkpoint["size_mb"]),
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": checkpoint["file_count"],
                "ä½œæˆæ—¥æ™‚": format_timestamp(checkpoint["created_at"])
            })

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.dataframe(
            checkpoint_data,
            use_container_width=True,
            hide_index=True
        )

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè©³ç´°ã¨å­¦ç¿’å†é–‹æ©Ÿèƒ½
        st.subheader("ğŸ”„ å­¦ç¿’å†é–‹")
        st.info("ğŸ’¡ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠã—ã¦å­¦ç¿’ã‚’å†é–‹ã§ãã¾ã™ã€‚")

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠ
        checkpoint_names = [cp["name"] for cp in checkpoints]
        selected_checkpoint = st.selectbox(
            "å­¦ç¿’å†é–‹ã«ä½¿ç”¨ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:",
            checkpoint_names,
            index=None,
            placeholder="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ...",
            key="checkpoint_selector"
        )

        if selected_checkpoint:
            # é¸æŠã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°ã‚’è¡¨ç¤º
            selected_checkpoint_info = next((cp for cp in checkpoints if cp["name"] == selected_checkpoint), None)
            if selected_checkpoint_info:
                st.markdown("### é¸æŠã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå", selected_checkpoint_info["name"])
                    st.metric("ãƒ¢ãƒ‡ãƒ«", selected_checkpoint_info["model_name"])

                with col2:
                    st.metric("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", selected_checkpoint_info["dataset_name"])
                    st.metric("ã‚¨ãƒãƒƒã‚¯", selected_checkpoint_info["epoch"])

                with col3:
                    st.metric("ã‚µã‚¤ã‚º", format_file_size(selected_checkpoint_info["size_mb"]))
                    st.metric("ãƒ•ã‚¡ã‚¤ãƒ«æ•°", selected_checkpoint_info["file_count"])

                # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
                st.markdown("#### å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:")
                for file_name in selected_checkpoint_info["files"]:
                    st.text(f"â€¢ {file_name}")

                # å­¦ç¿’å†é–‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                st.markdown("### å­¦ç¿’å†é–‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                col_param1, col_param2 = st.columns(2)

                with col_param1:
                    resume_epochs = st.number_input("è¿½åŠ ã‚¨ãƒãƒƒã‚¯æ•°", min_value=1, value=5, key="resume_epochs")
                    resume_batch_size = st.number_input("ãƒãƒƒãƒã‚µã‚¤ã‚º", min_value=1, value=4, key="resume_batch_size")

                with col_param2:
                    resume_lightweight = st.checkbox("è»½é‡ãƒ¢ãƒ¼ãƒ‰", value=True, key="resume_lightweight")
                    resume_limit_samples = st.number_input("ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™", min_value=0, value=0, key="resume_limit_samples")

                # å­¦ç¿’å†é–‹ãƒœã‚¿ãƒ³
                if st.button("ğŸ”„ ã“ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã‚’å†é–‹", type="primary", disabled=st.session_state.is_training, key="resume_from_checkpoint_button"):
                    if not st.session_state.is_training:
                        with st.spinner("å­¦ç¿’ã‚’å†é–‹ä¸­..."):
                            success = resume_training(
                                selected_checkpoint_info["model_name"],
                                selected_checkpoint_info["dataset_name"],
                                resume_epochs,
                                resume_batch_size,
                                specific_checkpoint=selected_checkpoint,
                                lightweight=resume_lightweight,
                                limit_samples=resume_limit_samples
                            )

                            if success:
                                st.success("å­¦ç¿’ã‚’å†é–‹ã—ã¾ã—ãŸï¼")
                                st.balloons()
                                # ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«æˆ»ã‚‹
                                st.session_state.current_page = "main"
                                st.rerun()
                            else:
                                st.error("å­¦ç¿’ã®å†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    else:
                        st.error("æ—¢ã«å­¦ç¿’ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚ç¾åœ¨ã®å­¦ç¿’ã‚’åœæ­¢ã—ã¦ã‹ã‚‰å†é–‹ã—ã¦ãã ã•ã„ã€‚")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã‚’å†é–‹ã™ã‚‹ã“ã¨ã§ã€å­¦ç¿’æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚")

# --- ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
elif current_page == "model_management":
    st.markdown("---")
    st.header("ğŸ¤– å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ç®¡ç†")

    # èª¬æ˜
    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§è¡¨ç¤ºã¨å‰Šé™¤ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’å®Œäº†æ™‚ã«è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã€ã“ã“ã§ç®¡ç†ã§ãã¾ã™ã€‚
    """)

    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—
    if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æ›´æ–°", type="primary", key="refresh_models_main"):
        st.rerun()

    models = get_models()

    if not models:
        st.info("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"{len(models)}å€‹ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")

        # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        st.subheader("ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        model_data = []
        for model in models:
            model_data.append({
                "ãƒ¢ãƒ‡ãƒ«å": model["name"],
                "ã‚¨ãƒãƒƒã‚¯": model["epoch"] if model["epoch"] else "ä¸æ˜",
                "ã‚µã‚¤ã‚º": format_file_size(model["size_mb"]),
                "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": model["file_count"],
                "ä½œæˆæ—¥æ™‚": format_timestamp(model["created_at"]),
                "ãƒ‘ã‚¹": model["path"]
            })

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.dataframe(
            model_data,
            use_container_width=True,
            hide_index=True
        )

        # ãƒ¢ãƒ‡ãƒ«è©³ç´°ã¨å‰Šé™¤æ©Ÿèƒ½
        st.subheader("ğŸ—‘ï¸ ãƒ¢ãƒ‡ãƒ«å‰Šé™¤")
        st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ã¨å¾©å…ƒã§ãã¾ã›ã‚“ã€‚å‰Šé™¤å‰ã«ååˆ†ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_names = [model["name"] for model in models]
        selected_model = st.selectbox(
            "å‰Šé™¤ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:",
            model_names,
            index=None,
            placeholder="ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...",
            key="model_selector"
        )

        if selected_model:
            # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã‚’è¡¨ç¤º
            selected_model_info = next((m for m in models if m["name"] == selected_model), None)
            if selected_model_info:
                st.markdown("### é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ãƒ¢ãƒ‡ãƒ«å", selected_model_info["name"])
                    st.metric("ã‚¨ãƒãƒƒã‚¯", selected_model_info["epoch"] if selected_model_info["epoch"] else "ä¸æ˜")

                with col2:
                    st.metric("ã‚µã‚¤ã‚º", format_file_size(selected_model_info["size_mb"]))
                    st.metric("ãƒ•ã‚¡ã‚¤ãƒ«æ•°", selected_model_info["file_count"])

                with col3:
                    st.metric("ä½œæˆæ—¥æ™‚", format_timestamp(selected_model_info["created_at"]))

                # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
                st.markdown("#### å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:")
                for file_name in selected_model_info["files"]:
                    st.text(f"â€¢ {file_name}")

                # å‰Šé™¤ç¢ºèª
                st.markdown("### å‰Šé™¤ç¢ºèª")
                confirm_text = st.text_input(
                    f"å‰Šé™¤ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«å '{selected_model}' ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                    placeholder="ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›...",
                    key="confirm_delete"
                )

                # å‰Šé™¤ãƒœã‚¿ãƒ³
                if st.button("ğŸ—‘ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤", type="secondary", disabled=confirm_text != selected_model, key="delete_model_button_main"):
                    if confirm_text == selected_model:
                        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ä¸­..."):
                            success, message = delete_model(selected_model)

                            if success:
                                st.success(message)
                                st.balloons()
                                # å‰Šé™¤å¾Œã€ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.error(message)
                    else:
                        st.error("ãƒ¢ãƒ‡ãƒ«åãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚æ­£ç¢ºã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã™ã‚‹å‰ã«ã€å¿…è¦ã«å¿œã˜ã¦ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
