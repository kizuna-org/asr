#!/usr/bin/env python3
"""
GPU and CUDA environment check script
"""

import sys
import os
import subprocess

def check_cuda_installation():
    """Check CUDA installation"""
    print("=== CUDA Installation Check ===")
    
    # Check CUDA_HOME
    cuda_home = os.environ.get('CUDA_HOME', '/usr/local/cuda')
    print(f"CUDA_HOME: {cuda_home}")
    
    # Check if CUDA directory exists
    if os.path.exists(cuda_home):
        print(f"‚úÖ CUDA directory exists: {cuda_home}")
    else:
        print(f"‚ùå CUDA directory not found: {cuda_home}")
        return False
    
    # Check CUDA version
    try:
        result = subprocess.run([f'{cuda_home}/bin/nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ CUDA compiler (nvcc) is available")
            print(f"CUDA Version: {result.stdout.split('release ')[1].split(',')[0]}")
        else:
            print("‚ùå CUDA compiler (nvcc) failed")
            print(f"Error: {result.stderr}")
    except (FileNotFoundError, subprocess.TimeoutExpired):
        print("‚ö†Ô∏è  CUDA compiler (nvcc) not found or timeout")
    
    # Check nvidia-smi
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ nvidia-smi is available")
            print("GPU Information:")
            print(result.stdout)
        else:
            print("‚ùå nvidia-smi failed")
            print(f"Error: {result.stderr}")
            return False
    except FileNotFoundError:
        print("‚ùå nvidia-smi not found")
        return False
    except subprocess.TimeoutExpired:
        print("‚ùå nvidia-smi timeout")
        return False
    
    return True

def check_pytorch_cuda():
    """Check PyTorch CUDA support"""
    print("\n=== PyTorch CUDA Check ===")
    
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        
        if torch.cuda.is_available():
            print("‚úÖ CUDA is available in PyTorch")
            print(f"CUDA version: {torch.version.cuda}")
            print(f"Number of GPUs: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        else:
            print("‚ùå CUDA is not available in PyTorch")
            return False
            
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False
    except Exception as e:
        print(f"‚ùå Error checking PyTorch CUDA: {e}")
        return False
    
    return True

def check_tensorflow_gpu():
    """Check TensorFlow GPU support"""
    print("\n=== TensorFlow GPU Check ===")
    
    try:
        import tensorflow as tf
        print(f"TensorFlow version: {tf.__version__}")
        
        if tf.config.list_physical_devices('GPU'):
            print("‚úÖ GPU devices available in TensorFlow")
            gpus = tf.config.list_physical_devices('GPU')
            for i, gpu in enumerate(gpus):
                print(f"GPU {i}: {gpu}")
        else:
            print("‚ùå No GPU devices available in TensorFlow")
            return False
            
    except ImportError:
        print("‚ùå TensorFlow not installed")
        return False
    except Exception as e:
        print(f"‚ùå Error checking TensorFlow GPU: {e}")
        return False
    
    return True

def check_environment_variables():
    """Check CUDA-related environment variables"""
    print("\n=== Environment Variables Check ===")
    
    env_vars = [
        'CUDA_HOME',
        'LD_LIBRARY_PATH',
        'CUDA_VISIBLE_DEVICES',
        'TF_FORCE_GPU_ALLOW_GROWTH',
        'TF_GPU_ALLOCATOR'
    ]
    
    for var in env_vars:
        value = os.environ.get(var, 'Not set')
        print(f"{var}: {value}")

def main():
    """Main function"""
    print("üöÄ Starting GPU and CUDA environment check...\n")
    
    # Check environment variables
    check_environment_variables()
    
    # Check CUDA installation
    cuda_ok = check_cuda_installation()
    
    # Check PyTorch CUDA
    pytorch_ok = check_pytorch_cuda()
    
    # Check TensorFlow GPU
    tensorflow_ok = check_tensorflow_gpu()
    
    print("\n=== Summary ===")
    print(f"CUDA Installation: {'‚úÖ OK' if cuda_ok else '‚ùå FAILED'}")
    print(f"PyTorch CUDA: {'‚úÖ OK' if pytorch_ok else '‚ùå FAILED'}")
    print(f"TensorFlow GPU: {'‚úÖ OK' if tensorflow_ok else '‚ùå FAILED'}")
    
    if cuda_ok and pytorch_ok:
        print("\nüéâ GPU environment is ready for ASR tasks!")
        return 0
    else:
        print("\n‚ö†Ô∏è  GPU environment has issues. Please check the configuration.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
