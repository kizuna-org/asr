#!/usr/bin/env python3
"""
TensorFlowã§GPUã®æ¤œçŸ¥çŠ¶æ³ã‚’ç°¡æ˜“ç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import tensorflow as tf
import sys

def quick_gpu_check():
    """GPUã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ç°¡æ˜“ç¢ºèª"""
    print("ğŸ” TensorFlow GPU ç°¡æ˜“ãƒã‚§ãƒƒã‚¯")
    print("-" * 40)
    
    # TensorFlowã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
    
    # GPUæ¤œçŸ¥
    gpus = tf.config.list_physical_devices('GPU')
    gpu_count = len(gpus)
    
    if gpu_count > 0:
        print(f"âœ… GPUæ¤œçŸ¥: {gpu_count}å€‹ã®GPUãŒåˆ©ç”¨å¯èƒ½")
        for i, gpu in enumerate(gpus):
            print(f"   GPU {i}: {gpu.name}")
    else:
        print("âŒ GPUæ¤œçŸ¥: GPUãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    # CUDAç¢ºèª
    cuda_available = tf.test.is_built_with_cuda()
    print(f"ğŸ”§ CUDA Support: {'âœ… æœ‰åŠ¹' if cuda_available else 'âŒ ç„¡åŠ¹'}")
    
    # ç°¡æ˜“è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    print("ğŸ§® è¨ˆç®—ãƒ†ã‚¹ãƒˆ:", end=" ")
    try:
        if gpu_count > 0:
            with tf.device('/GPU:0'):
                result = tf.reduce_sum(tf.random.normal([1000, 1000]))
                print("âœ… GPUè¨ˆç®—æˆåŠŸ")
        else:
            result = tf.reduce_sum(tf.random.normal([1000, 1000]))
            print("âš ï¸ CPUè¨ˆç®—ã®ã¿")
    except Exception as e:
        print(f"âŒ è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("-" * 40)
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    if gpu_count > 0 and cuda_available:
        print("ğŸ‰ GPUç’°å¢ƒã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        return 0
    elif gpu_count > 0:
        print("âš ï¸ GPUã¯æ¤œçŸ¥ã•ã‚Œã¾ã—ãŸãŒã€CUDA supportã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        return 1
    else:
        print("âŒ GPUç’°å¢ƒã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        return 2

if __name__ == "__main__":
    exit_code = quick_gpu_check()
    sys.exit(exit_code) 
