#!/usr/bin/env python3
"""
Script to pre-download the M-AILABS dataset for Docker container or local use
"""

import os
import requests
import tarfile
import argparse
import sys
import time


def download_mailabs_dataset(output_dir="/opt/datasets/mailabs"):
    """Download and extract the M-AILABS dataset to a specified directory."""
    print("Pre-downloading M-AILABS dataset...")

    # Set data directory
    dataset_dir = output_dir
    os.makedirs(dataset_dir, exist_ok=True)
    
    audio_dir = os.path.join(dataset_dir, "en_US")
    dataset_path = os.path.join(dataset_dir, "en_US.tgz")
    
    # Check if already downloaded
    if os.path.exists(audio_dir) and os.listdir(audio_dir):
        print("‚úÖ M-AILABS dataset already exists")
        return True

    print(f"Downloading to: {dataset_dir}")

    try:
        # Download the dataset
        mailabs_url = "https://ics.tau-ceti.space/data/Training/stt_tts/en_US.tgz"
        print(f"üì• Downloading from: {mailabs_url}")
        
        # Check if partial file exists for resume
        resume_header = {}
        initial_pos = 0
        mode = 'wb'
        
        if os.path.exists(dataset_path):
            initial_pos = os.path.getsize(dataset_path)
            if initial_pos > 0:
                resume_header = {'Range': f'bytes={initial_pos}-'}
                mode = 'ab'  # Append mode for resume
                print(f"üìÇ Resuming download from byte {initial_pos:,}")
        
        response = requests.get(mailabs_url, headers=resume_header, stream=True)
        
        # Handle range request responses
        if response.status_code == 206:  # Partial Content
            print("‚úÖ Resume successful")
        elif response.status_code == 416:  # Range Not Satisfiable (file already complete)
            print("‚úÖ File already downloaded completely")
            # Verify the file is complete by checking if it can be extracted
            try:
                with tarfile.open(dataset_path, 'r:gz') as tar:
                    pass  # Just check if it's a valid tarfile
                print("‚úÖ Existing file is valid, skipping download")
                # Skip to extraction step
                total_size = initial_pos
                downloaded_size = total_size
            except:
                print("‚ö†Ô∏è Existing file is corrupted, restarting download")
                os.remove(dataset_path)
                initial_pos = 0
                mode = 'wb'
                response = requests.get(mailabs_url, stream=True)
        elif initial_pos > 0 and response.status_code == 200:
            print("‚ö†Ô∏è Server doesn't support resume, restarting download")
            os.remove(dataset_path)
            initial_pos = 0
            mode = 'wb'
        
        response.raise_for_status()
        
        # Get total file size
        if 'content-range' in response.headers:
            # Parse "bytes start-end/total" format
            total_size = int(response.headers['content-range'].split('/')[-1])
        else:
            content_length = response.headers.get('content-length', 0)
            total_size = int(content_length) + initial_pos
        
        downloaded_size = initial_pos
        
        # Only download if not already complete
        if downloaded_size < total_size:
            start_time = time.time()
            last_update_time = start_time
            update_interval = 1.0  # Update every 1 second
            
            with open(dataset_path, mode) as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        
                        current_time = time.time()
                        # Update progress display every interval or on last chunk
                        if current_time - last_update_time >= update_interval or downloaded_size >= total_size:
                            last_update_time = current_time
                            
                            if total_size > 0:
                                progress = (downloaded_size / total_size) * 100
                                elapsed_time = current_time - start_time
                                
                                # Calculate download speed
                                if elapsed_time > 0:
                                    bytes_downloaded_since_start = downloaded_size - initial_pos
                                    speed_bps = bytes_downloaded_since_start / elapsed_time
                                    
                                    # Format speed appropriately
                                    if speed_bps >= 1024 * 1024:
                                        speed_str = f"{speed_bps / (1024 * 1024):.1f} MB/s"
                                    elif speed_bps >= 1024:
                                        speed_str = f"{speed_bps / 1024:.1f} KB/s"
                                    else:
                                        speed_str = f"{speed_bps:.0f} B/s"
                                    
                                    # Calculate ETA
                                    remaining_bytes = total_size - downloaded_size
                                    if speed_bps > 0 and remaining_bytes > 0:
                                        eta_seconds = remaining_bytes / speed_bps
                                        eta_hours = int(eta_seconds // 3600)
                                        eta_minutes = int((eta_seconds % 3600) // 60)
                                        eta_secs = int(eta_seconds % 60)
                                        
                                        if eta_hours > 0:
                                            eta_str = f"{eta_hours:02d}:{eta_minutes:02d}:{eta_secs:02d}"
                                        else:
                                            eta_str = f"{eta_minutes:02d}:{eta_secs:02d}"
                                    else:
                                        eta_str = "--:--"
                                    
                                    print(f"\rProgress: {progress:.1f}% ({downloaded_size:,}/{total_size:,} bytes) | {speed_str} | ETA: {eta_str}", end="", flush=True)
                                else:
                                    print(f"\rProgress: {progress:.1f}% ({downloaded_size:,}/{total_size:,} bytes) | Calculating...", end="", flush=True)
        
        print(f"\nüì¶ Download completed: {dataset_path}")
        
        # Extract the dataset
        print("üìÇ Extracting dataset...")
        with tarfile.open(dataset_path, 'r:gz') as tar:
            tar.extractall(dataset_dir)
        
        print("‚úÖ Dataset extraction completed")
        
        # Clean up the tar file
        os.remove(dataset_path)
        print("üóëÔ∏è Cleaned up temporary files")

        # Count files
        total_files = 0
        speakers = set()
        for root, dirs, files in os.walk(audio_dir):
            for file in files:
                if file.endswith('.wav'):
                    total_files += 1
                    # Extract speaker from path
                    relative_path = os.path.relpath(root, audio_dir)
                    speaker = relative_path.split(os.sep)[0] if relative_path != '.' else 'unknown'
                    speakers.add(speaker)
        
        print(f"üìä Total audio files: {total_files:,}")
        print(f"üé≠ Number of speakers: {len(speakers)}")
        print(f"üé≠ Speakers: {sorted(list(speakers))}")

        return True

    except Exception as e:
        print(f"ERROR: Failed to download dataset: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Download the M-AILABS dataset for speech training",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Download to default Docker location
  python download_dataset.py

  # Download to local datasets directory
  python download_dataset.py --local

  # Download to custom directory
  python download_dataset.py --output-dir /path/to/your/datasets

  # Download to current directory
  python download_dataset.py --output-dir ./my_datasets
        """
    )
    
    parser.add_argument(
        "--local",
        action="store_true",
        help="Download to local datasets directory (./datasets/mailabs) instead of Docker default"
    )
    
    parser.add_argument(
        "--output-dir",
        type=str,
        help="Specify custom output directory for the dataset"
    )
    
    args = parser.parse_args()
    
    # Determine output directory
    if args.output_dir:
        # User specified custom directory
        output_dir = os.path.abspath(args.output_dir)
        if not output_dir.endswith("mailabs"):
            output_dir = os.path.join(output_dir, "mailabs")
    elif args.local:
        # Local mode: use ./datasets/mailabs
        output_dir = os.path.abspath("./datasets/mailabs")
    else:
        # Default Docker mode
        output_dir = "/opt/datasets/mailabs"
    
    print(f"üéØ Target directory: {output_dir}")
    
    # Create parent directory if it doesn't exist
    try:
        os.makedirs(os.path.dirname(output_dir), exist_ok=True)
    except Exception as e:
        print(f"ERROR: Cannot create directory {os.path.dirname(output_dir)}: {e}")
        sys.exit(1)
    
    success = download_mailabs_dataset(output_dir)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
